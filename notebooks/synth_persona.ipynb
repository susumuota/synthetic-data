{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Persona-Hub による事後学習データ合成\n",
    "\n",
    "Susumu Ota  2025-02-02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本ハンズオンでは、言語モデルを使って合成データを生成する方法を紹介します。\n",
    "\n",
    "まず、簡単に合成データ生成の概要を説明します。次に、[Persona-Hub](https://arxiv.org/abs/2406.20094) 手法の解説、[FinePersonas](https://huggingface.co/datasets/argilla/FinePersonas-v0.1) データセットの紹介、最後に実際にペルソナデータを使ってマルチターン事後学習データを合成する方法を説明します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 合成データ生成の概要"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 合成データの重要性\n",
    "\n",
    "本ハンズオンにおける合成データとは、\"**人間によって直接生成されたデータではなく、モデルやアルゴリズムによって生成されたデータ**\"を指します。\n",
    "\n",
    "合成データの重要性については、以下のような報告があります。\n",
    "\n",
    "- [畠山先生の 松尾研LLM開発プロジェクト “Tanuki-8x8B” 開発成果報告会 Vol.1 発表資料](https://www.docswell.com/s/matsuo-lab_llm/51R2L4-2024-9-10-Tanuki%E9%96%8B%E7%99%BA%E5%A0%B1%E5%91%8A%E4%BC%9A-vol1#p54)より\n",
    "  - Web データで継続事前学習しても JMT-Bench のスコアは横ばい\n",
    "  - 合成データの投入でスコアが向上\n",
    "  - 数学・論理推論・コードが難しい<br />\n",
    "<img src=\"https://github.com/user-attachments/assets/2eb9d26b-cddc-4c8f-b8a1-be9e6d1d3c05\" width=\"800px\">\n",
    "\n",
    "- [合成データの多様さと言語モデルの学習への影響を調べたプレプリント](https://arxiv.org/abs/2410.15226)より\n",
    "  - 合成データの多様さと、学習後のモデルの性能に正の相関がある (多様な合成データを使うほど性能が向上)\n",
    "  - モデルサイズが大きいほど、合成データの多様さが性能に与える影響が大きい<br />\n",
    "<img src=\"https://github.com/user-attachments/assets/ccdc7e34-fdfd-4810-9ef4-8c2f2145bb86\" width=\"800px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 合成データ作成の難しさ\n",
    "\n",
    "一般に、データ生成タスクにおいて、データの**質**と**多様さ**についてはトレードオフの関係があります。例えば、人手でデータを作成する場合は、予算一定では品質と多様さのどちらかを犠牲にせざるを得ません。\n",
    "\n",
    "一方、言語モデルを使った合成データ生成の場合も、データの**質**と**多様さ**については同様にトレードオフがありますが、以下のような特徴があります。\n",
    "\n",
    "<img src=\"https://github.com/user-attachments/assets/63e7a21e-ad8f-40a2-b22e-86eddef6e623\" width=\"400px\">\n",
    "\n",
    "- 品質は合成に使う言語モデルの性能が上がれば向上 (Scaling Laws に乗っかることが可能) (橙色の上矢印)\n",
    "- 多様さを向上させることが難しい (緑色の右矢印)\n",
    "\n",
    "したがって、合成データの多様さを向上させるためには、何らかのヒント・種を言語モデルに与えた上で合成データを出力する必要があります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 本ハンズオンの目的\n",
    "\n",
    "本ハンズオンの目的は、言語モデルを使った合成データの作成において、多様さを向上させるための方法を紹介することです。特に、[Persona-Hub](https://arxiv.org/abs/2406.20094) という手法を使って、事後学習用のマルチターン対話データを生成する方法を紹介します。\n",
    "\n",
    "多様な合成データを生成する方法として以下のような方法が提案されています([Persona-Hub のテクニカルレポート](https://arxiv.org/abs/2406.20094)より)。\n",
    "\n",
    "- インスタンス駆動\n",
    "  - 例: Wikipedia の記事から Q&A を生成\n",
    "- キーポイント駆動\n",
    "  - 例: 数学の学習指導要領に含まれる用語 (e.g. `三角関数`) から数学の問題を生成\n",
    "- ペルソナ駆動\n",
    "  - 例: ペルソナ (e.g. `運送会社のドライバー`) から数学の問題を生成\n",
    "\n",
    "本ハンズオンでは3つ目の**ペルソナ駆動による合成データ生成**を中心に説明します。\n",
    "\n",
    "なお、上記と直交する方法として、多様な合成データを生成するためにサンプリングを行うという方法があります。例えば、言語モデルで合成データを出力する際に、温度パラメータを高めに設定することで、多様な出力を得ることができます。しかし、温度を上げすぎるとハルシネーションや文が破綻する可能性が高まるため、品質と多様さのトレードオフが生じます。したがって、サンプリングのみで得られる多様さは限定的です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 準備\n",
    "\n",
    "ここからは、合成データ生成に必要な推論用言語モデルの準備を行います。言語モデルの推論を行うために、既存の推論 API を利用する方法と、Colab の GPU やローカルの GPU を使って推論を行う方法のどちらかを選択することができます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### トークンと API キーの設定\n",
    "\n",
    "本ハンズオンで必要となるトークンや API キーを設定します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hugging Face のトークンの取得\n",
    "\n",
    "Hugging Face からデータセットやモデルをダウンロードするためにトークンが必要となります。サインアップしてトークンを取得し `HF_TOKEN` という環境変数に設定してください。\n",
    "\n",
    "Hugging Face にサインアップしてトークンを取得する方法は、[こちら](https://zenn.dev/protoout/articles/73-hugging-face-setup)の記事を参照してください。生成する際の `role` は `read` で十分です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (オプション) 言語モデルサービスの API キーの取得\n",
    "\n",
    "Note: **Colab の GPU やローカルの GPU を使って推論する場合は、この設定は不要**です。\n",
    "\n",
    "推論 API の実行は [LiteLLM](https://docs.litellm.ai/) というモジュール経由で行います。LiteLLM の [Providers](https://docs.litellm.ai/docs/providers) ページを参照して、対応しているサービス一覧と環境変数名を確認してください。\n",
    "\n",
    "代表的な API キーの取得方法は以下です。\n",
    "- `OPENAI_API_KEY`\n",
    "  - OpenAI の API キーの取得方法は、[こちら](https://qiita.com/kurata04/items/a10bdc44cc0d1e62dad3)の記事を参照してください。\n",
    "  - 2025-02-02現在、無料枠はなく、利用開始時に $5 のクレジットが必要となります。\n",
    "- `NVIDIA_NIM_API_KEY`\n",
    "  - NVIDIA NIM の API キーの取得方法は、[こちら](https://zenn.dev/connectome/articles/eb9848241c5115)の記事のAPIキーを取得する部分までを参照してください。\n",
    "  - 2025-02-02現在、NVIDIA NIM の API は **1000 リクエストまでは無料**で利用できます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### トークンと API キーをシークレットマネージャーに保存\n",
    "\n",
    "この Notebook をローカル環境等の安全な環境で実行する場合は、OS の環境変数でトークンや API キーを保存してください。\n",
    "\n",
    "Colab 等のクラウド環境で実行する場合は、シークレットマネージャーに保存してください。**ソースコード中に API キーやトークンを直接書くとセキュリティ上のリスクが高まります**。\n",
    "\n",
    "Colab でのシークレットマネージャーによる設定方法は以下のようなコードを実行してください。詳細は[こちら](https://note.com/npaka/n/n79bb63e17685)の記事を参照してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if str(get_ipython()).startswith(\"<google.colab\"):  # if this notebook is running in Google Colab  # type: ignore\n",
    "    import os\n",
    "    from google.colab import userdata  # type: ignore\n",
    "\n",
    "    os.environ[\"HF_TOKEN\"] = userdata.get(\"HF_TOKEN\")\n",
    "    # os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
    "    # os.environ[\"NVIDIA_NIM_API_KEY\"] = userdata.get(\"NVIDIA_NIM_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モジュールのインストール\n",
    "\n",
    "`litellm` と `datasets` をインストールしてください。ローカルのGPUを使って推論する場合は `vllm` もインストールしてください(API だけを使う場合は不要です)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install litellm\n",
    "# %pip install datasets\n",
    "\n",
    "# %pip install vllm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モジュールのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ota/Documents/python/synthetic-data/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/ota/Documents/python/synthetic-data/.venv/lib/python3.11/site-packages/pydantic/_internal/_config.py:345: UserWarning: Valid config keys have changed in V2:\n",
      "* 'fields' has been removed\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No vllm module found. You can only use the LiteLLM.\n"
     ]
    }
   ],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "import json\n",
    "from logging import DEBUG, INFO, StreamHandler, getLogger  # noqa: F401\n",
    "import pprint\n",
    "import random\n",
    "import re\n",
    "\n",
    "\n",
    "from datasets import load_dataset\n",
    "from litellm import batch_completion\n",
    "\n",
    "try:\n",
    "    from vllm import LLM, SamplingParams  # type: ignore\n",
    "except ImportError:\n",
    "    print(\"No vllm module found. You can only use the LiteLLM.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ログの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging_level = DEBUG\n",
    "# logging_level = INFO  # uncomment if you want to see less output\n",
    "logger = getLogger(__name__)\n",
    "logger.setLevel(logging_level)\n",
    "handler = StreamHandler()\n",
    "handler.setLevel(logging_level)\n",
    "logger.addHandler(handler)\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 言語モデルの設定\n",
    "\n",
    "API による推論とローカル GPU を使った推論の両方を統一してコードを書くために、`LanguageModel` という抽象クラスを作り、サブクラスで個別の処理を実装します。\n",
    "\n",
    "推論 API は `LiteLLM` 経由で利用します。\n",
    "\n",
    "Colab の GPU やローカルの GPU を使って推論には `vLLM` を使います。`LiteLLM` 経由で `vLLM` を使うことも出来ますが、`LiteLLM` では `dtype` の設定が出来ない(これが出来ないと Colab T4 で動作しない)ため `vLLM` を直接使うことにしました。\n",
    "\n",
    "`LanguageModel` のメソッドの役割は以下の通りです。\n",
    "\n",
    "- `__init__`: 言語モデルの初期化。推論用のパラメータ(`temperature`等)も設定。\n",
    "- `__call__`: 推論の実行。入力は OpenAI messages 形式 (e.g. `[{\"role\": \"user\", \"content\": \"Hello!\"}]`) のリスト。出力は文字列のリスト。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModel(ABC):\n",
    "    def __init__(self, model: str, temperature=1.0, max_tokens=16, seed=None):\n",
    "        self.model = model\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.seed = seed\n",
    "        logger.debug(f\"model: {model}, temperature: {temperature}, max_tokens: {max_tokens}, seed: {seed}\")\n",
    "\n",
    "    @abstractmethod\n",
    "    def __call__(self, messages_batch: list[list[dict[str, str]]]) -> list[str]:\n",
    "        pass\n",
    "\n",
    "\n",
    "class LiteLLMModel(LanguageModel):\n",
    "    def __init__(self, model: str, temperature=1.0, max_tokens=16, seed=None):\n",
    "        super().__init__(model, temperature, max_tokens, seed)\n",
    "\n",
    "    def __call__(self, messages_batch: list[list[dict[str, str]]]) -> list[str]:\n",
    "        contents = [\n",
    "            response.choices[0].message.content or \"\"\n",
    "            for response in batch_completion(\n",
    "                model=self.model,\n",
    "                messages=messages_batch,\n",
    "                temperature=self.temperature,\n",
    "                max_tokens=self.max_tokens,\n",
    "                seed=self.seed,\n",
    "            )\n",
    "        ]\n",
    "        assert len(contents) == len(messages_batch)\n",
    "        return contents\n",
    "\n",
    "\n",
    "class VLLMModel(LanguageModel):\n",
    "    def __init__(self, model: str, temperature=1.0, max_tokens=16, seed=None, dtype=\"auto\", stop=None):\n",
    "        super().__init__(model, temperature, max_tokens, seed)\n",
    "        self.dtype = dtype\n",
    "        self.stop = stop\n",
    "        self.vllm = LLM(model, dtype=dtype)  # dtype must be \"half\" to run on Colab T4\n",
    "        self.tokenizer = self.vllm.get_tokenizer()\n",
    "\n",
    "    def __call__(self, messages_batch: list[list[dict[str, str]]]) -> list[str]:\n",
    "        sampling_params = SamplingParams(\n",
    "            temperature=self.temperature, max_tokens=self.max_tokens, seed=self.seed, stop=self.stop\n",
    "        )\n",
    "        prompts = [\n",
    "            self.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "            for messages in messages_batch\n",
    "        ]\n",
    "        outputs = self.vllm.generate(prompts, sampling_params=sampling_params, use_tqdm=False)\n",
    "        contents = [o.outputs[0].text for o in outputs]\n",
    "        assert len(contents) == len(messages_batch)\n",
    "        return contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 言語モデルの初期化\n",
    "\n",
    "推論 API を使う場合は `準備` の節を参考に API キーを設定してください。環境変数名やモデル名は、[LiteLLM の Providers ページ](https://docs.litellm.ai/docs/providers)を参照してください。性能と価格のバランスを考慮すると、本ハンズオンで行う程度の内容であれば、`gpt-4o-mini` が適切かもしれません。\n",
    "\n",
    "Colab T4 GPU を使って推論する場合は `vLLM` を使います。手元でテストした限りでは、T4 では、\n",
    "\n",
    "- 3B 前後の量子化していないモデル\n",
    "- 10B 前後の量子化したモデル\n",
    "\n",
    "が動作可能でした。\n",
    "\n",
    "本ハンズオンの内容を `google/gemma-2-9b-it` の非公式量子化版の `marcsun13/gemma-2-9b-it-GPTQ` で動作確認をしましたが、合成データの質は `gpt-4o-mini` と比べて**大幅に劣ります**。可能であれば、A100 等の GPU を使い、 `cyberagent/calm3-22b-chat` やそれと同等以上の性能を持つモデルを使うことをお勧めします。サイズの小さいモデルや品質の低いモデルでは、合成データ生成がうまくいかない場合があります。個人的な印象ですが、現状では 10B 以下の日本語モデルでは、合成データ生成は難しいかもしれません。\n",
    "\n",
    "また、モデル・API のライセンスや利用規約等を確認して、**合成データを利用する際の制限事項等を各自で確認してください**。\n",
    "\n",
    "### 推論 API を使う場合の注意点\n",
    "\n",
    "一般に API の推論速度は遅いので、予備実験を API で行い、本実験は vLLM でローカル GPU で行うという使い方が現実的かもしれません。\n",
    "\n",
    "また、API で大量のデータを生成する場合は、バッチ処理のオプションが用意されていればそれを利用することと、利用制限(rate limit等)の範囲内でリクエストの並列化を検討してください。LiteLLM は内部でマルチスレッドで並列化されていますが、バッチサイズ大きめで使うと API サービス側の rate limit を超える可能性があります。\n",
    "\n",
    "### 言語モデルの作成\n",
    "\n",
    "以下のどれかのコメントを外して言語モデルを初期化します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model: gpt-4o-mini, temperature: 0.7, max_tokens: 512, seed: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.LiteLLMModel at 0x10a982310>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = LiteLLMModel(\"gpt-4o-mini\", temperature=0.7, max_tokens=512, seed=0)  # OPENAI_API_KEY\n",
    "# llm = LiteLLMModel(\"nvidia_nim/nvidia/nemotron-4-340b-instruct\", temperature=0.7, max_tokens=512, seed=None)  # NVIDIA_NIM_API_KEY\n",
    "# llm = LiteLLMModel(\"nvidia_nim/nvidia/llama-3.1-nemotron-70b-instruct\", temperature=0.7, max_tokens=512, seed=None)  # NVIDIA_NIM_API_KEY\n",
    "# llm = LiteLLMModel(\"deepinfra/nvidia/Llama-3.1-Nemotron-70B-Instruct\", temperature=0.7, max_tokens=512, seed=0)  # DEEPINFRA_API_KEY\n",
    "# llm = VLLMModel(\"hpprc/gemma-2-2b-jpn-it\", temperature=0.7, max_tokens=512, seed=0, stop=[\"<end_of_turn>\"], dtype=\"half\")  # for Colab T4\n",
    "# llm = VLLMModel(\"marcsun13/gemma-2-9b-it-GPTQ\", temperature=0.7, max_tokens=512, seed=0)  # for Colab T4\n",
    "# llm = VLLMModel(\"cyberagent/calm3-22b-chat\", temperature=0.7, max_tokens=512, seed=0)  # for A100?\n",
    "\n",
    "llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 言語モデルの動作確認\n",
    "\n",
    "ここまで設定できれば以下の推論が動作するはずです。もしエラーが出る場合は、言語モデルの設定を見直してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello! How can I assist you today?']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm([[{\"role\": \"user\", \"content\": \"Hello?\"}]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここまでで言語モデルによる推論環境を構築することできました。\n",
    "\n",
    "次に、ペルソナ駆動による合成データ生成の方法について説明します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persona-Hub による合成データ生成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ペルソナとは\n",
    "\n",
    "[FinePersonasのREADME](https://huggingface.co/datasets/argilla/FinePersonas-v0.1) では、ペルソナについて以下のように説明されています。\n",
    "\n",
    "> - 個人の特徴、背景、目標を詳細に記述したもので、多様なアイデンティティと経験を反映するようにデザインされている\n",
    "> - ペルソナの例\n",
    ">   - A network engineer with a focus on routing protocols and preparing for Cisco certification exams, particularly CCNA.\n",
    ">   - ルーティング・プロトコルに興味があり、シスコの認定試験(特に CCNA)の準備をしているネットワーク・エンジニア\n",
    "> - 生成するコンテンツに、特定の専門知識・キャリアパス・個人的な興味を導入し、より繊細でターゲットを絞ったコンテンツが生成可能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persona-Hub とは\n",
    "\n",
    "[Persona-Hub](https://arxiv.org/abs/2406.20094) は、Tencent AI Lab が提案したペルソナ駆動型データ合成手法で、大規模言語モデル内の様々な視点を活用して多様な合成データを作成することができます。\n",
    "\n",
    "<img src=\"https://github.com/user-attachments/assets/37ce038a-7702-4398-838d-8c504ac1da07\" width=\"800px\">\n",
    "\n",
    "Persona-Hub 手法の概要は以下の通りです。\n",
    "\n",
    "- 背景: 既存の合成データ⽣成⼿法(インスタンス駆動・キーポイント駆動)では合成データの多様さをスケールアップすることが困難\n",
    "- 目的: ⼤規模なペルソナデータセットを作成し、それを使ってスケーラブルな合成データを⽣成する(ペルソナ駆動)\n",
    "- 方法\n",
    "  - Web ページのテキストからペルソナを抽出 (上図の`Compress`部分)\n",
    "    - Text-to-Persona\n",
    "    - Persona-to-Persona\n",
    "  - ペルソナを使って合成データを生成 (上図の`Decompress`部分、下図)\n",
    "    - Create **a math problem** with **a moving company driver**\n",
    "    - Create **a math problem** with **a chemical kinetics researcher**\n",
    "    - Create **a math problem** with **a musician interested in audio processing**\n",
    "- 結果: 10億件のペルソナデータセットを作成 (ただし今のところ非公開)\n",
    "\n",
    "<img src=\"https://github.com/user-attachments/assets/344b011d-b9f8-4ac3-a79a-198e3862b3cf\" width=\"800px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web ページのテキストからペルソナを抽出\n",
    "\n",
    "まず、Persona-Hub 手法を理解するために、Web ページのテキストからペルソナを抽出する方法を説明します(上図の`Compress`部分)。その後、抽出したペルソナを使って合成データを生成する方法を説明します(上図の`Decompress`部分)。\n",
    "\n",
    "ここでは、実際に [FineWeb-Edu](https://huggingface.co/datasets/HuggingFaceFW/fineweb-edu) という教育関連の品質の高い Web ページを集めたデータセットからペルソナを抽出します。\n",
    "\n",
    "まずデータセットを読み込みます。データセット全体を読み込むと時間がかかるので、ここでは `streaming=True` を指定して一部分だけ読み込みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IterableDataset({\n",
       "    features: ['text', 'id', 'dump', 'url', 'date', 'file_path', 'language', 'language_score', 'token_count', 'score', 'int_score'],\n",
       "    num_shards: 50\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fineweb_edu = load_dataset(\n",
    "    \"HuggingFaceFW/fineweb-edu\", name=\"CC-MAIN-2024-51\", split=\"train\", cache_dir=\"cache\", streaming=True\n",
    ")\n",
    "\n",
    "fineweb_edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回は実験のため、データセットの先頭の10件を取り出して `web_pages` というリストに格納します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This project is solving the Asteroid Watchers challenge. Description\\nAROs are essentially created by',\n",
       " 'Life of a Sand Grain\\nTHE LIFE OF A SAND GRAIN by Carl Bowser (Sept. 2018)\\nThey surround you almost a',\n",
       " 'The internet of things, a system of interrelated computing devices and machines that can transfer da',\n",
       " 'An archive photo of an Egyptian mummy - Reuters\\nBy Tom Perry\\nCAIRO, Jan 15 (Reuters) - Archaeologist',\n",
       " 'The faith of the Christ-God is a living paradox in the Asiatic world. Christianity has long survived',\n",
       " 'Power wound resistance is a two terminal electronic component made of\\nresistance material, which has',\n",
       " 'Pravda No. 50, March 1, 1913 |\\nPublished according to |\\nFrom V. I. Lenin, Collected Works, 4th Engli',\n",
       " '1. 03. Friend B: I look washed out. Publications Publications such as books, magazines, newspapers, ',\n",
       " 'Aerospace & Electronic Techniques Society\\nUntil 1950, this field was called “radio expertise” as a e',\n",
       " 'The Dawn of the Artificial Kidney\\nArtificial kidneys may sound like something from a science fiction']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "web_pages = [d[\"text\"] for d in fineweb_edu.take(10)]\n",
    "[p[:100] for p in web_pages]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記のように教育分野の比較的品質の高い Web ページを集めたデータセットです。特に科学技術分野のペルソナを抽出できそうです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text-to-Persona\n",
    "\n",
    "Persona-Hub では、ペルソナを抽出する手法として `Text-to-Persona` と `Persona-to-Persona` が提案されています。ここでは Text-to-Persona 手法によって、Web ページのテキストからペルソナを抽出します。\n",
    "\n",
    "効果的にペルソナを抽出するポイントは `このテキストを書きそうな人物` や `このテキストに興味がありそうな人物` を言語モデルに予測させることです。\n",
    "\n",
    "以下のようなプロンプトを実行します。\n",
    "\n",
    "Note: `system` ロールがサポートされていない言語モデルを使う場合は `user` ロールにシステムプロンプトの内容を含めてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_persona(llm: LanguageModel, text: str) -> str:\n",
    "    SYSTEM_PROMPT = \"\"\"\\\n",
    "You are an expert in analyzing the text content and assigning finding the general type of persona that could be associated with such a way of expressing. Please use one or two sentences for the definition, but try to make it as fine-grained if input texts involve many detailed elements. The persona definition must go straight to the point, be assertive. The following are starts of persona definitions:\n",
    "A machine learning researcher...\n",
    "A pedriatric nurse whose...\n",
    "An urban planner focused on...\n",
    "\"\"\"\n",
    "\n",
    "    USER_PROMPT = \"\"\"\\\n",
    "What is the likely profession, interest, or role of the person who would write or be interested in this text?\n",
    "\n",
    "## Text\n",
    "{text}\n",
    "\n",
    "Note:\n",
    "1. Your response should always start with \"ペルソナ:\".\n",
    "2. 日本語で回答してください。\n",
    "\"\"\"\n",
    "    persona = llm([[\n",
    "        # {\"role\": \"system\", \"content\": SYSTEM_PROMPT},  # if llm supports system prompt\n",
    "        # {\"role\": \"user\", \"content\": USER_PROMPT.format(text=text)},\n",
    "        {\"role\": \"user\", \"content\": SYSTEM_PROMPT + \"\\n\\n## Task\\n\" + USER_PROMPT.format(text=text)},  # if llm does not support system prompt\n",
    "    ]])[0]\n",
    "    logger.debug(f\"persona: {persona}\")\n",
    "\n",
    "    return re.sub(r\"^ペルソナ[:：]\", \"\", persona).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この関数を使って FineWeb-Edu データからペルソナを抽出します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "persona: ペルソナ: オープンソースハードウェアとソフトウェアに関心を持つ天文愛好家であり、Arduinoやスマートフォンを用いた技術的なプロジェクトを推進するエンジニアまたは研究者。\n",
      "persona: ペルソナ: 地質学者であり、特に砂や鉱物の成り立ちや成熟過程に興味を持つ研究者。\n",
      "persona: ペルソナ: IoT（モノのインターネット）とAI技術の融合に興味を持つ技術系の専門家であり、データ分析やシステム設計に関わるエンジニア、または研究者。\n",
      "persona: ペルソナ: 古代エジプトの考古学者で、歴史的な発見や文化遺産の保護に情熱を持ち、専門的な知識を駆使して研究を行っている。\n",
      "persona: ペルソナ: 宗教史や比較宗教学に精通した学者であり、特にキリスト教のアジアにおける位置づけや影響について深く考察することに興味を持つ思想家。\n",
      "persona: ペルソナ: 電子工学の研究者で、回路設計や抵抗器の特性に関心を持つ技術者。\n",
      "persona: ペルソナ: マルクス主義の理論を深く研究し、社会主義社会の建設における労働者階級の役割に関心を持つ政治理論家や歴史家。\n",
      "persona: ペルソナ: メディアプランナーであり、広告戦略や印刷メディアの効果を分析し、ターゲットオーディエンスへの適切なメッセージ配信を重視する専門家。\n",
      "persona: ペルソナ: 航空宇宙および電子工学の専門家であり、電子機器の設計や技術的な問題解決に関心を持つエンジニア。また、電子音楽やデジタルツールの応用にも興味を示す多才な技術者。\n",
      "persona: ペルソナ: 人工腎臓技術の研究者であり、医療技術の進歩に情熱を持つ科学者。患者の生活の質向上を目指し、革新的な治療法の開発に関与している。\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['オープンソースハードウェアとソフトウェアに関心を持つ天文愛好家であり、Arduinoやスマートフォンを用いた技術的なプロジェクトを推進するエンジニアまたは研究者。',\n",
       " '地質学者であり、特に砂や鉱物の成り立ちや成熟過程に興味を持つ研究者。',\n",
       " 'IoT（モノのインターネット）とAI技術の融合に興味を持つ技術系の専門家であり、データ分析やシステム設計に関わるエンジニア、または研究者。',\n",
       " '古代エジプトの考古学者で、歴史的な発見や文化遺産の保護に情熱を持ち、専門的な知識を駆使して研究を行っている。',\n",
       " '宗教史や比較宗教学に精通した学者であり、特にキリスト教のアジアにおける位置づけや影響について深く考察することに興味を持つ思想家。',\n",
       " '電子工学の研究者で、回路設計や抵抗器の特性に関心を持つ技術者。',\n",
       " 'マルクス主義の理論を深く研究し、社会主義社会の建設における労働者階級の役割に関心を持つ政治理論家や歴史家。',\n",
       " 'メディアプランナーであり、広告戦略や印刷メディアの効果を分析し、ターゲットオーディエンスへの適切なメッセージ配信を重視する専門家。',\n",
       " '航空宇宙および電子工学の専門家であり、電子機器の設計や技術的な問題解決に関心を持つエンジニア。また、電子音楽やデジタルツールの応用にも興味を示す多才な技術者。',\n",
       " '人工腎臓技術の研究者であり、医療技術の進歩に情熱を持つ科学者。患者の生活の質向上を目指し、革新的な治療法の開発に関与している。']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "personas = [text_to_persona(llm, web_page) for web_page in web_pages]\n",
    "personas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "元の Web ページのテキストと抽出したペルソナを比較してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'persona': 'オープンソースハードウェアとソフトウェアに関心を持つ天文愛好家であり、Arduinoやスマートフォンを用いた技術的なプロジェクトを推進するエンジニアまたは研究者。',\n",
      " 'web_page_ja': 'This project is solving the Asteroid Watchers challenge. Description\\n'\n",
      "                'AROs are essentially created by combining a telescope with a smartphone. If the '\n",
      "                'telescope has drive motors can be controlled via a '}\n",
      "{'persona': '地質学者であり、特に砂や鉱物の成り立ちや成熟過程に興味を持つ研究者。',\n",
      " 'web_page_ja': 'Life of a Sand Grain\\n'\n",
      "                'THE LIFE OF A SAND GRAIN by Carl Bowser (Sept. 2018)\\n'\n",
      "                'They surround you almost anywhere you are in Arizona. They cling to your shoes, '\n",
      "                'they end up in pockets and pant cuffs, they pr'}\n",
      "{'persona': 'IoT（モノのインターネット）とAI技術の融合に興味を持つ技術系の専門家であり、データ分析やシステム設計に関わるエンジニア、または研究者。',\n",
      " 'web_page_ja': 'The internet of things, a system of interrelated computing devices and machines '\n",
      "                'that can transfer data over a network without human interaction, has been used to '\n",
      "                'enable new features, better functional'}\n",
      "{'persona': '古代エジプトの考古学者で、歴史的な発見や文化遺産の保護に情熱を持ち、専門的な知識を駆使して研究を行っている。',\n",
      " 'web_page_ja': 'An archive photo of an Egyptian mummy - Reuters\\n'\n",
      "                'By Tom Perry\\n'\n",
      "                'CAIRO, Jan 15 (Reuters) - Archaeologists in Egypt believe they have discovered '\n",
      "                'the remains of a previously unknown pharaoh who reigned more'}\n",
      "{'persona': '宗教史や比較宗教学に精通した学者であり、特にキリスト教のアジアにおける位置づけや影響について深く考察することに興味を持つ思想家。',\n",
      " 'web_page_ja': 'The faith of the Christ-God is a living paradox in the Asiatic world. '\n",
      "                'Christianity has long survived in Asia’s periphery, especially in the Near East '\n",
      "                'and to a lesser extent in India, but it has never '}\n",
      "{'persona': '電子工学の研究者で、回路設計や抵抗器の特性に関心を持つ技術者。',\n",
      " 'web_page_ja': 'Power wound resistance is a two terminal electronic component made of\\n'\n",
      "                'resistance material, which has a certain structure and can limit the\\n'\n",
      "                'current passing through the circuit. A fixed resistor is one '}\n",
      "{'persona': 'マルクス主義の理論を深く研究し、社会主義社会の建設における労働者階級の役割に関心を持つ政治理論家や歴史家。',\n",
      " 'web_page_ja': 'Pravda No. 50, March 1, 1913 |\\n'\n",
      "                'Published according to |\\n'\n",
      "                'From V. I. Lenin, Collected Works, 4th English Edition,\\n'\n",
      "                'Progress Publishers, Moscow, 1968\\n'\n",
      "                'First printing 1963\\n'\n",
      "                'Second printing 1968\\n'\n",
      "                'Translated fr'}\n",
      "{'persona': 'メディアプランナーであり、広告戦略や印刷メディアの効果を分析し、ターゲットオーディエンスへの適切なメッセージ配信を重視する専門家。',\n",
      " 'web_page_ja': '1. 03. Friend B: I look washed out. Publications Publications such as books, '\n",
      "                'magazines, newspapers, blogs and research papers. Required material - includes '\n",
      "                'print material selected by staff, that must '}\n",
      "{'persona': '航空宇宙および電子工学の専門家であり、電子機器の設計や技術的な問題解決に関心を持つエンジニア。また、電子音楽やデジタルツールの応用にも興味を示す多才な技術者。',\n",
      " 'web_page_ja': 'Aerospace & Electronic Techniques Society\\n'\n",
      "                'Until 1950, this field was called “radio expertise” as a end result of its '\n",
      "                'principal application was the design and principle of radio transmitters, '\n",
      "                'receivers'}\n",
      "{'persona': '人工腎臓技術の研究者であり、医療技術の進歩に情熱を持つ科学者。患者の生活の質向上を目指し、革新的な治療法の開発に関与している。',\n",
      " 'web_page_ja': 'The Dawn of the Artificial Kidney\\n'\n",
      "                'Artificial kidneys may sound like something from a science fiction movie, but '\n",
      "                'these ground-breaking new treatments are currently being designed and tested '\n",
      "                'across the '}\n"
     ]
    }
   ],
   "source": [
    "for web_page, persona in zip(web_pages, personas):\n",
    "    pp.pprint({\"web_page_ja\": web_page[:200], \"persona\": persona})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text-to-Persona 手法によって、FineWeb-Edu データセットのテキストからペルソナを抽出することが出来ました。\n",
    "\n",
    "なお、Web ページからペルソナを抽出することは、一種の合成データ生成と考えることが出来ます。この場合は、Webページというインスタンスからペルソナという合成データを生成していますので、Text-to-Persona 手法は、**インスタンス駆動の合成データ生成**と捉えることが可能です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Persona-to-Persona\n",
    "\n",
    "Text-to-Persona だけでは抽出することが難しいペルソナがあります(例えば子供など)。そのようなペルソナをカバーするために、抽出したペルソナからさらに関連するペルソナを生成します。この手法を Persona-to-Persona と呼びます。以下のようなプロンプトを実行します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def persona_to_personas(llm: LanguageModel, persona: str) -> list[str]:\n",
    "    SYSTEM_PROMPT = \"\"\"\\\n",
    "You are an AI assistant expert in finding relationships between people. Answer directly with the the new related persona definition, don't enumerate them.\n",
    "\"\"\"\n",
    "\n",
    "    USER_PROMPT = \"\"\"\\\n",
    "Who is in close relationship with the given persona? Write just 3, each one in a different line:\n",
    "{persona}\n",
    "\n",
    "Note:\n",
    "1. Your response should always start with \"ペルソナ:\".\n",
    "2. Granularity of persona description should be similar to the input persona.\n",
    "3. The output persona should be fully described without context of the input persona.\n",
    "4. 日本語で回答してください。\n",
    "\"\"\"\n",
    "\n",
    "    persona = llm([[\n",
    "        # {\"role\": \"system\", \"content\": SYSTEM_PROMPT},  # if llm supports system prompt\n",
    "        # {\"role\": \"user\", \"content\": USER_PROMPT.format(persona=persona)},\n",
    "        {\"role\": \"user\", \"content\": SYSTEM_PROMPT + \"\\n\\n\" + USER_PROMPT.format(persona=persona)},  # if llm does not support system prompt\n",
    "    ]])[0]\n",
    "    logger.debug(f\"persona: {persona}\")\n",
    "\n",
    "    return [re.sub(r\"^ペルソナ[:：]\", \"\", p.strip()).strip() for p in persona.split(\"\\n\") if p.strip()][-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "persona: ペルソナ: オープンソースのソフトウェア開発者で、宇宙科学に熱心であり、データ解析やシミュレーションを通じて天文学の研究をサポートするプログラマー。  \n",
      "\n",
      "ペルソナ: 環境科学を専攻し、地球外生命体の探索に興味を持つ大学院生で、天文観測に関連するプロジェクトに従事する研究者。  \n",
      "\n",
      "ペルソナ: DIYエレクトロニクスに情熱を持ち、IoTデバイスを開発するスタートアップの創業者で、天文イベントを活用した教育活動を行う技術者。  \n",
      "persona: ペルソナ: 環境科学者であり、地球の持続可能性や資源管理に関心を持つ研究者。  \n",
      "ペルソナ: 地質学の学生であり、特に砂の成り立ちや鉱物の性質について学んでいる。  \n",
      "ペルソナ: 地質調査会社の技術者であり、砂や鉱物の分析と評価を専門とする。  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['オープンソースのソフトウェア開発者で、宇宙科学に熱心であり、データ解析やシミュレーションを通じて天文学の研究をサポートするプログラマー。',\n",
       "  '環境科学を専攻し、地球外生命体の探索に興味を持つ大学院生で、天文観測に関連するプロジェクトに従事する研究者。',\n",
       "  'DIYエレクトロニクスに情熱を持ち、IoTデバイスを開発するスタートアップの創業者で、天文イベントを活用した教育活動を行う技術者。'],\n",
       " ['環境科学者であり、地球の持続可能性や資源管理に関心を持つ研究者。',\n",
       "  '地質学の学生であり、特に砂の成り立ちや鉱物の性質について学んでいる。',\n",
       "  '地質調査会社の技術者であり、砂や鉱物の分析と評価を専門とする。']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_personas_list = [persona_to_personas(llm, persona) for persona in personas[:2]]\n",
    "new_personas_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'new_personas': ['オープンソースのソフトウェア開発者で、宇宙科学に熱心であり、データ解析やシミュレーションを通じて天文学の研究をサポートするプログラマー。',\n",
      "                  '環境科学を専攻し、地球外生命体の探索に興味を持つ大学院生で、天文観測に関連するプロジェクトに従事する研究者。',\n",
      "                  'DIYエレクトロニクスに情熱を持ち、IoTデバイスを開発するスタートアップの創業者で、天文イベントを活用した教育活動を行う技術者。'],\n",
      " 'org_persona': 'オープンソースハードウェアとソフトウェアに関心を持つ天文愛好家であり、Arduinoやスマートフォンを用いた技術的なプロジェクトを推進するエンジニアまたは研究者。'}\n",
      "{'new_personas': ['環境科学者であり、地球の持続可能性や資源管理に関心を持つ研究者。',\n",
      "                  '地質学の学生であり、特に砂の成り立ちや鉱物の性質について学んでいる。',\n",
      "                  '地質調査会社の技術者であり、砂や鉱物の分析と評価を専門とする。'],\n",
      " 'org_persona': '地質学者であり、特に砂や鉱物の成り立ちや成熟過程に興味を持つ研究者。'}\n"
     ]
    }
   ],
   "source": [
    "for org_persona, new_personas in zip(personas, new_personas_list):\n",
    "    pp.pprint({\"org_persona\": org_persona, \"new_personas\": new_personas})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "もうすこしプロンプトを工夫する必要があるかもしれませんが、与えられたペルソナと密接に関連するペルソナを生成することが出来ます。\n",
    "\n",
    "以上で、Web ページのテキストからペルソナを抽出する方法として以下の2つの手法を紹介しました。\n",
    "\n",
    "- Text-to-Persona\n",
    "- Persona-to-Persona"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ペルソナを使って合成データを生成\n",
    "\n",
    "ここからは、先ほど抽出したペルソナを使って合成データを生成します。今回は例として以下のような合成データを生成します。\n",
    "- インストラクション\n",
    "- 知識豊富なテキスト\n",
    "- 数学問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### インストラクションの合成\n",
    "\n",
    "まず、合成データ例として、ペルソナからインストラクション(ユーザが言語モデルに入力するプロンプト)データを合成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_instruction(llm: LanguageModel, persona: str) -> dict[str, str]:\n",
    "    SYSTEM_PROMPT = \"You are an AI assistant expert at simulating user interactions.\"\n",
    "\n",
    "    USER_PROMPT = \"\"\"\\\n",
    "Generate a prompt the persona below might ask to an AI assistant:\n",
    "\n",
    "{persona}\n",
    "\n",
    "Note:\n",
    "1. Your response should always start with \"プロンプト:\".\n",
    "2. 簡潔に日本語で回答してください。\n",
    "\"\"\"\n",
    "\n",
    "    instruction = llm([[\n",
    "        # {\"role\": \"system\", \"content\": SYSTEM_PROMPT},  # if llm supports system prompt\n",
    "        # {\"role\": \"user\", \"content\": USER_PROMPT.format(persona=persona)},\n",
    "        {\"role\": \"user\", \"content\": SYSTEM_PROMPT + \"\\n\\n\" + USER_PROMPT.format(persona=persona)},  # if llm does not support system prompt\n",
    "    ]])[0]\n",
    "    logger.debug(f\"instruction: {instruction}\")\n",
    "\n",
    "    return re.sub(r\"^プロンプト[:：]\", \"\", instruction).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "instruction: プロンプト: Arduinoを使って星空観測用のデータロガーを作りたいのですが、どのセンサーやモジュールを使うべきかおすすめはありますか？\n",
      "instruction: プロンプト: 砂の成り立ちに関する最新の研究成果や、鉱物の成熟過程についての具体的なデータを教えてください。\n",
      "instruction: プロンプト: IoTデバイスから収集したデータをAIで効果的に分析するためのベストプラクティスは何ですか？\n",
      "instruction: プロンプト: 古代エジプトの宗教儀式に関する最新の研究成果を教えてください。また、どのようにしてこれらの知識を文化遺産の保護に活かせるかも教えてください。\n",
      "instruction: プロンプト: キリスト教がアジアの文化や社会に与えた影響について、具体的な事例を挙げて教えてください。また、その影響が現代にどのように表れているのかも知りたいです。\n",
      "instruction: プロンプト: 回路設計における抵抗器の温度特性について教えてください。また、温度変化が抵抗値に与える影響を具体的に知りたいです。\n",
      "instruction: プロンプト: 労働者階級が社会主義社会の建設において果たすべき具体的な役割について、どのような理論や歴史的事例がありますか？\n",
      "instruction: プロンプト: 最新の広告戦略におけるターゲットオーディエンスの分析方法について教えてください。どのデータを重視すべきですか？\n",
      "instruction: プロンプト: 最新の航空宇宙技術における電子機器の設計に関するトレンドや技術的な課題について教えてください。また、電子音楽制作に役立つデジタルツールのおすすめも知りたいです。\n",
      "instruction: プロンプト: 人工腎臓技術の最新の研究成果について教えてください。また、患者の生活の質向上にどのように寄与できるか教えていただけますか？\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Arduinoを使って星空観測用のデータロガーを作りたいのですが、どのセンサーやモジュールを使うべきかおすすめはありますか？',\n",
       " '砂の成り立ちに関する最新の研究成果や、鉱物の成熟過程についての具体的なデータを教えてください。',\n",
       " 'IoTデバイスから収集したデータをAIで効果的に分析するためのベストプラクティスは何ですか？',\n",
       " '古代エジプトの宗教儀式に関する最新の研究成果を教えてください。また、どのようにしてこれらの知識を文化遺産の保護に活かせるかも教えてください。',\n",
       " 'キリスト教がアジアの文化や社会に与えた影響について、具体的な事例を挙げて教えてください。また、その影響が現代にどのように表れているのかも知りたいです。',\n",
       " '回路設計における抵抗器の温度特性について教えてください。また、温度変化が抵抗値に与える影響を具体的に知りたいです。',\n",
       " '労働者階級が社会主義社会の建設において果たすべき具体的な役割について、どのような理論や歴史的事例がありますか？',\n",
       " '最新の広告戦略におけるターゲットオーディエンスの分析方法について教えてください。どのデータを重視すべきですか？',\n",
       " '最新の航空宇宙技術における電子機器の設計に関するトレンドや技術的な課題について教えてください。また、電子音楽制作に役立つデジタルツールのおすすめも知りたいです。',\n",
       " '人工腎臓技術の最新の研究成果について教えてください。また、患者の生活の質向上にどのように寄与できるか教えていただけますか？']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instructions = [generate_instruction(llm, p) for p in personas]\n",
    "instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "抽出元の Web ページ、ペルソナ、インストラクションをまとめて確認してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': 'Arduinoを使って星空観測用のデータロガーを作りたいのですが、どのセンサーやモジュールを使うべきかおすすめはありますか？',\n",
      " 'persona': 'オープンソースハードウェアとソフトウェアに関心を持つ天文愛好家であり、Arduinoやスマートフォンを用いた技術的なプロジェクトを推進するエンジニアまたは研究者。',\n",
      " 'web_page': 'This project is solving the Asteroid Watchers challenge. Description\\n'\n",
      "             'AROs are essentially created by'}\n",
      "{'instruction': '砂の成り立ちに関する最新の研究成果や、鉱物の成熟過程についての具体的なデータを教えてください。',\n",
      " 'persona': '地質学者であり、特に砂や鉱物の成り立ちや成熟過程に興味を持つ研究者。',\n",
      " 'web_page': 'Life of a Sand Grain\\n'\n",
      "             'THE LIFE OF A SAND GRAIN by Carl Bowser (Sept. 2018)\\n'\n",
      "             'They surround you almost a'}\n",
      "{'instruction': 'IoTデバイスから収集したデータをAIで効果的に分析するためのベストプラクティスは何ですか？',\n",
      " 'persona': 'IoT（モノのインターネット）とAI技術の融合に興味を持つ技術系の専門家であり、データ分析やシステム設計に関わるエンジニア、または研究者。',\n",
      " 'web_page': 'The internet of things, a system of interrelated computing devices and machines that '\n",
      "             'can transfer da'}\n",
      "{'instruction': '古代エジプトの宗教儀式に関する最新の研究成果を教えてください。また、どのようにしてこれらの知識を文化遺産の保護に活かせるかも教えてください。',\n",
      " 'persona': '古代エジプトの考古学者で、歴史的な発見や文化遺産の保護に情熱を持ち、専門的な知識を駆使して研究を行っている。',\n",
      " 'web_page': 'An archive photo of an Egyptian mummy - Reuters\\n'\n",
      "             'By Tom Perry\\n'\n",
      "             'CAIRO, Jan 15 (Reuters) - Archaeologist'}\n",
      "{'instruction': 'キリスト教がアジアの文化や社会に与えた影響について、具体的な事例を挙げて教えてください。また、その影響が現代にどのように表れているのかも知りたいです。',\n",
      " 'persona': '宗教史や比較宗教学に精通した学者であり、特にキリスト教のアジアにおける位置づけや影響について深く考察することに興味を持つ思想家。',\n",
      " 'web_page': 'The faith of the Christ-God is a living paradox in the Asiatic world. Christianity '\n",
      "             'has long survived'}\n",
      "{'instruction': '回路設計における抵抗器の温度特性について教えてください。また、温度変化が抵抗値に与える影響を具体的に知りたいです。',\n",
      " 'persona': '電子工学の研究者で、回路設計や抵抗器の特性に関心を持つ技術者。',\n",
      " 'web_page': 'Power wound resistance is a two terminal electronic component made of\\n'\n",
      "             'resistance material, which has'}\n",
      "{'instruction': '労働者階級が社会主義社会の建設において果たすべき具体的な役割について、どのような理論や歴史的事例がありますか？',\n",
      " 'persona': 'マルクス主義の理論を深く研究し、社会主義社会の建設における労働者階級の役割に関心を持つ政治理論家や歴史家。',\n",
      " 'web_page': 'Pravda No. 50, March 1, 1913 |\\n'\n",
      "             'Published according to |\\n'\n",
      "             'From V. I. Lenin, Collected Works, 4th Engli'}\n",
      "{'instruction': '最新の広告戦略におけるターゲットオーディエンスの分析方法について教えてください。どのデータを重視すべきですか？',\n",
      " 'persona': 'メディアプランナーであり、広告戦略や印刷メディアの効果を分析し、ターゲットオーディエンスへの適切なメッセージ配信を重視する専門家。',\n",
      " 'web_page': '1. 03. Friend B: I look washed out. Publications Publications such as books, '\n",
      "             'magazines, newspapers, '}\n",
      "{'instruction': '最新の航空宇宙技術における電子機器の設計に関するトレンドや技術的な課題について教えてください。また、電子音楽制作に役立つデジタルツールのおすすめも知りたいです。',\n",
      " 'persona': '航空宇宙および電子工学の専門家であり、電子機器の設計や技術的な問題解決に関心を持つエンジニア。また、電子音楽やデジタルツールの応用にも興味を示す多才な技術者。',\n",
      " 'web_page': 'Aerospace & Electronic Techniques Society\\n'\n",
      "             'Until 1950, this field was called “radio expertise” as a e'}\n",
      "{'instruction': '人工腎臓技術の最新の研究成果について教えてください。また、患者の生活の質向上にどのように寄与できるか教えていただけますか？',\n",
      " 'persona': '人工腎臓技術の研究者であり、医療技術の進歩に情熱を持つ科学者。患者の生活の質向上を目指し、革新的な治療法の開発に関与している。',\n",
      " 'web_page': 'The Dawn of the Artificial Kidney\\n'\n",
      "             'Artificial kidneys may sound like something from a science fiction'}\n"
     ]
    }
   ],
   "source": [
    "for w, p, i in zip(web_pages, personas, instructions):\n",
    "    pp.pprint({\"web_page\": w[:100], \"persona\": p, \"instruction\": i})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ペルソナに該当する人物が、言語モデルに入力しそうなインストラクションを生成することが出来ました。\n",
    "\n",
    "先ほどの図を再掲します。今回行った処理は、この図のように、`web_page` から `persona` を抽出し(`Compress`)、`persona` から `instruction` という合成データを生成した(`Decompress`)、ということになります。\n",
    "\n",
    "<img src=\"https://github.com/user-attachments/assets/37ce038a-7702-4398-838d-8c504ac1da07\" width=\"800px\">\n",
    "\n",
    "もちろん `web_page` から `instruction` を直接生成することも可能ですが、一旦 `persona` に変換することで、トークン数を大幅に削減しつつ、元のテキストの情報量を残したまま多様な合成データが生成できるというのが Persona-Hub の特徴です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 知識豊富なテキストの合成\n",
    "\n",
    "次に、同様の手法でペルソナから知識豊富なテキストを合成します。\n",
    "\n",
    "Quoraは、ユーザがさまざまなトピックについて質問したり、回答を提供したりできる人気の Q&A サイトです。Quoraの記事は、様々な分野の専門家を含む知識豊富な人物によって書かれることが多く、質が高くよく調査された有益なコンテンツが確保されています。このアプローチによって、有益で知識豊富なコンテンツを得ることが出来ます。([Persona-Hub テクニカルレポート](https://arxiv.org/abs/2406.20094)より)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_quora_post(llm: LanguageModel, persona: str) -> str:\n",
    "    SYSTEM_PROMPT = \"You are an AI assistant specialized in writing posts for social media.\"\n",
    "\n",
    "    USER_PROMPT = \"\"\"\\\n",
    "Write a Quora post in the language, style, and personality of the following persona:\n",
    "\n",
    "{persona}\n",
    "\n",
    "Note:\n",
    "1. Your response should always start with \"記事:\".\n",
    "2. 簡潔に日本語で回答してください。\n",
    "\"\"\"\n",
    "\n",
    "    post = llm([[\n",
    "        # {\"role\": \"system\", \"content\": SYSTEM_PROMPT},  # if llm supports system prompt\n",
    "        # {\"role\": \"user\", \"content\": USER_PROMPT.format(persona=persona)},\n",
    "        {\"role\": \"user\", \"content\": SYSTEM_PROMPT + \"\\n\\n\" + USER_PROMPT.format(persona=persona)},  # if llm does not support system prompt\n",
    "    ]])[0]\n",
    "    logger.debug(f\"post: {post}\")\n",
    "\n",
    "    return re.sub(r\"^記事[:：]\", \"\", post).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "post: 記事:  \n",
      "こんにちは、天文愛好家の皆さん！オープンソースハードウェアとソフトウェアの魅力について、特にArduinoやスマートフォンを使ったプロジェクトの可能性についてお話ししたいと思います。\n",
      "\n",
      "最近、私が取り組んでいるプロジェクトは、Arduinoを使って自動的に星空を観測するシステムの構築です。このシステムは、スマートフォンアプリと連携して、リアルタイムでデータを収集・分析できるようにしています。オープンソースの利点は、他の愛好者と知識を共有し、改良を加えられることです。\n",
      "\n",
      "例えば、私たちのプロジェクトでは、GPSモジュールを使って観測地点の緯度経度を記録し、センサーを通じて光の強度や温度を測定しています。これらのデータを使って、星の動きや天候の変化を分析することができます。\n",
      "\n",
      "皆さんもぜひ、オープンソース技術を活用して、自分だけの天文プロジェクトに挑戦してみてください！どんな些細なアイデアでも、新しい発見につながるかもしれません。共に学び、宇宙の神秘を探求していきましょう！\n",
      "post: 記事:  \n",
      "地質学の世界では、砂や鉱物の成り立ちと成熟過程は非常に興味深いテーマです。砂は、岩石の風化や侵食によって生成され、様々な環境で形成されます。海岸や河川、砂漠など、それぞれの場所で異なる特性を持つ砂が見られます。\n",
      "\n",
      "特に、砂の粒径や成分、成熟度は、その土地の地質や気候条件を反映しています。成熟した砂は、粒径が均一で、丸みを帯びた形状を持つことが多いです。これは、長い時間をかけて風や水の作用を受けた結果です。逆に、未成熟な砂は、粗く不均一な形をしており、その成分も多様です。\n",
      "\n",
      "このように、砂や鉱物の研究は、地球の歴史や環境の変遷を理解するための鍵となります。興味がある方は、ぜひ自分の周りの砂を観察してみてください。その小さな粒の中に、地球の壮大な物語が詰まっています。\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['こんにちは、天文愛好家の皆さん！オープンソースハードウェアとソフトウェアの魅力について、特にArduinoやスマートフォンを使ったプロジェクトの可能性についてお話ししたいと思います。\\n\\n最近、私が取り組んでいるプロジェクトは、Arduinoを使って自動的に星空を観測するシステムの構築です。このシステムは、スマートフォンアプリと連携して、リアルタイムでデータを収集・分析できるようにしています。オープンソースの利点は、他の愛好者と知識を共有し、改良を加えられることです。\\n\\n例えば、私たちのプロジェクトでは、GPSモジュールを使って観測地点の緯度経度を記録し、センサーを通じて光の強度や温度を測定しています。これらのデータを使って、星の動きや天候の変化を分析することができます。\\n\\n皆さんもぜひ、オープンソース技術を活用して、自分だけの天文プロジェクトに挑戦してみてください！どんな些細なアイデアでも、新しい発見につながるかもしれません。共に学び、宇宙の神秘を探求していきましょう！',\n",
       " '地質学の世界では、砂や鉱物の成り立ちと成熟過程は非常に興味深いテーマです。砂は、岩石の風化や侵食によって生成され、様々な環境で形成されます。海岸や河川、砂漠など、それぞれの場所で異なる特性を持つ砂が見られます。\\n\\n特に、砂の粒径や成分、成熟度は、その土地の地質や気候条件を反映しています。成熟した砂は、粒径が均一で、丸みを帯びた形状を持つことが多いです。これは、長い時間をかけて風や水の作用を受けた結果です。逆に、未成熟な砂は、粗く不均一な形をしており、その成分も多様です。\\n\\nこのように、砂や鉱物の研究は、地球の歴史や環境の変遷を理解するための鍵となります。興味がある方は、ぜひ自分の周りの砂を観察してみてください。その小さな粒の中に、地球の壮大な物語が詰まっています。']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts = [generate_quora_post(llm, p) for p in personas[:2]]\n",
    "posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'persona': 'オープンソースハードウェアとソフトウェアに関心を持つ天文愛好家であり、Arduinoやスマートフォンを用いた技術的なプロジェクトを推進するエンジニアまたは研究者。',\n",
      " 'post': 'こんにちは、天文愛好家の皆さん！オープンソースハードウェアとソフトウェアの魅力について、特にArduinoやスマートフォンを使ったプロジェクトの可能性についてお話ししたいと思います。\\n'\n",
      "         '\\n'\n",
      "         '最近、私が取り',\n",
      " 'web_page': 'This project is solving the Asteroid Watchers challenge. Description\\n'\n",
      "             'AROs are essentially created by'}\n",
      "{'persona': '地質学者であり、特に砂や鉱物の成り立ちや成熟過程に興味を持つ研究者。',\n",
      " 'post': '地質学の世界では、砂や鉱物の成り立ちと成熟過程は非常に興味深いテーマです。砂は、岩石の風化や侵食によって生成され、様々な環境で形成されます。海岸や河川、砂漠など、それぞれの場所で異なる特性を持つ砂が見',\n",
      " 'web_page': 'Life of a Sand Grain\\n'\n",
      "             'THE LIFE OF A SAND GRAIN by Carl Bowser (Sept. 2018)\\n'\n",
      "             'They surround you almost a'}\n"
     ]
    }
   ],
   "source": [
    "for web_page, persona, post in zip(web_pages, personas, posts):\n",
    "    pp.pprint({\"web_page\": web_page[:100], \"persona\": persona, \"post\": post[:100]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数学問題の合成\n",
    "\n",
    "最後に、ペルソナを使って数学の問題を合成します。数学問題については、後ほどさらに詳細なプロンプトを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_math_problem(llm: LanguageModel, persona: str) -> str:\n",
    "    SYSTEM_PROMPT = \"You are an AI assistant specialized in creating diverse but specific math problems. Just answer with your problem.\"\n",
    "\n",
    "    USER_PROMPT = \"\"\"\\\n",
    "Create a challenging math problem with the following persona:\n",
    "\n",
    "{persona}\n",
    "\n",
    "Note:\n",
    "1. Your response should always start with \"問題:\".\n",
    "2. 簡潔に日本語で回答してください。\n",
    "\"\"\"\n",
    "\n",
    "    problem = llm([[\n",
    "        # {\"role\": \"system\", \"content\": SYSTEM_PROMPT},  # if llm supports system prompt\n",
    "        # {\"role\": \"user\", \"content\": USER_PROMPT.format(persona=persona)},\n",
    "        {\"role\": \"user\", \"content\": SYSTEM_PROMPT + \"\\n\\n\" + USER_PROMPT.format(persona=persona)},  # if llm does not support system prompt\n",
    "    ]])[0]\n",
    "    logger.debug(f\"problem: {problem}\")\n",
    "\n",
    "    return re.sub(r\"^問題[:：]\", \"\", problem).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "problem: 問題: 天文愛好家のあなたは、Arduinoを用いて星座の位置をリアルタイムで追跡するプロジェクトを進めています。もし、星座の位置データを毎秒60回取得し、1時間で合計いくつのデータポイントを収集できるか計算してください。また、そのデータポイントを用いて、星座の形を描くために必要な最小限の直線セグメントの本数が、データポイント数の半分である場合、必要な直線セグメントの本数は何本になりますか？\n",
      "problem: 問題: 地質学者の田中さんは、ある地域の砂粒のサイズ分布を調べています。この地域の砂は、直径が0.1mmから2mmの範囲で、対数正規分布に従っていると仮定します。田中さんが収集したデータによると、平均サイズは0.5mm、標準偏差は0.3mmです。この砂粒のサイズが1mm以上である確率を求めなさい。\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['天文愛好家のあなたは、Arduinoを用いて星座の位置をリアルタイムで追跡するプロジェクトを進めています。もし、星座の位置データを毎秒60回取得し、1時間で合計いくつのデータポイントを収集できるか計算してください。また、そのデータポイントを用いて、星座の形を描くために必要な最小限の直線セグメントの本数が、データポイント数の半分である場合、必要な直線セグメントの本数は何本になりますか？',\n",
       " '地質学者の田中さんは、ある地域の砂粒のサイズ分布を調べています。この地域の砂は、直径が0.1mmから2mmの範囲で、対数正規分布に従っていると仮定します。田中さんが収集したデータによると、平均サイズは0.5mm、標準偏差は0.3mmです。この砂粒のサイズが1mm以上である確率を求めなさい。']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problems = [generate_math_problem(llm, p) for p in personas[:2]]\n",
    "problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'persona': 'オープンソースハードウェアとソフトウェアに関心を持つ天文愛好家であり、Arduinoやスマートフォンを用いた技術的なプロジェクトを推進するエンジニアまたは研究者。',\n",
      " 'problem': '天文愛好家のあなたは、Arduinoを用いて星座の位置をリアルタイムで追跡するプロジェクトを進めています。もし、星座の位置データを毎秒60回取得し、1時間で合計いくつのデータポイントを収集できるか計算',\n",
      " 'web_page': 'This project is solving the Asteroid Watchers challenge. Description\\n'\n",
      "             'AROs are essentially created by'}\n",
      "{'persona': '地質学者であり、特に砂や鉱物の成り立ちや成熟過程に興味を持つ研究者。',\n",
      " 'problem': '地質学者の田中さんは、ある地域の砂粒のサイズ分布を調べています。この地域の砂は、直径が0.1mmから2mmの範囲で、対数正規分布に従っていると仮定します。田中さんが収集したデータによると、平均サイズは',\n",
      " 'web_page': 'Life of a Sand Grain\\n'\n",
      "             'THE LIFE OF A SAND GRAIN by Carl Bowser (Sept. 2018)\\n'\n",
      "             'They surround you almost a'}\n"
     ]
    }
   ],
   "source": [
    "for web_page, persona, problem in zip(web_pages, personas, problems):\n",
    "    pp.pprint({\"web_page\": web_page[:100], \"persona\": persona, \"problem\": problem[:100]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上で、抽出したペルソナを使って以下の3つの合成データを生成しました。\n",
    "\n",
    "- インストラクション\n",
    "- 知識豊富なテキスト\n",
    "- 数学問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persona-Hub 手法のまとめ\n",
    "\n",
    "ここまで Persona-Hub 手法を紹介しました。以下にまとめます。\n",
    "\n",
    "<img src=\"https://github.com/user-attachments/assets/344b011d-b9f8-4ac3-a79a-198e3862b3cf\" width=\"800px\">\n",
    "\n",
    "- 既存の合成データ⽣成⼿法(インスタンス駆動・キーポイント駆動)では合成データの多様さをスケールアップすることが困難\n",
    "- ⼤規模なペルソナデータセットを作成し、それを使ってスケーラブルな合成データを⽣成する(ペルソナ駆動)\n",
    "- Web ページからペルソナを抽出\n",
    "  - Text-to-Persona\n",
    "  - Persona-to-Persona\n",
    "- ペルソナを使って合成データを生成\n",
    "  - インストラクション\n",
    "  - 知識豊富なテキスト\n",
    "  - 数学問題\n",
    "- テクニカルレポート: https://arxiv.org/abs/2406.20094"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FinePersonas による事後学習データ合成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FinePersonas とは\n",
    "\n",
    "ここからは大規模なペルソナデータセットである [FinePersonas](https://huggingface.co/datasets/argilla/FinePersonas-v0.1) について説明します。\n",
    "\n",
    "<img src=\"https://cdn-uploads.huggingface.co/production/uploads/6435d564a4bd75c62cc03701/5wTHwgijTUKFI5B-N7gEg.png\" width=\"600px\">\n",
    "\n",
    "[FinePersonas](https://huggingface.co/datasets/argilla/FinePersonas-v0.1) は Argilla が2024年9月にリリースされた合成テキスト生成のためのペルソナデータセットです。以下のような特徴があります。\n",
    "\n",
    "- 2100万人の詳細なペルソナのオープンデータセット\n",
    "- 合成データの豊富さ・多様性・特異性を高めることが可能\n",
    "- [Persona-Hub](https://arxiv.org/abs/2406.20094) と同じレシピに従い、[FineWeb-Edu](https://huggingface.co/datasets/HuggingFaceFW/fineweb-edu) (教育関連Webページのデータセット)から2100万件のペルソナを抽出\n",
    "- ライセンス: Llama 3.1 Community License Agreement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FinePersonas データセットの読み込み\n",
    "\n",
    "実際のペルソナデータを読み込んで、数学の問題と解答を合成します。[FinePersonas](https://huggingface.co/datasets/argilla/FinePersonas-v0.1) データセットを利用します。\n",
    "\n",
    "FinePersonas データセットは巨大なデータセットですので、本ハンズオンでは一部分だけをダウンロードして利用します。読み込む際に `streaming=True` を必ずつけてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IterableDataset({\n",
       "    features: ['id', 'persona', 'labels'],\n",
       "    num_shards: 12\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"argilla/FinePersonas-v0.1\", split=\"train\", cache_dir=\"cache\", streaming=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回は先頭の100件を使って生成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A professional R programmer or researcher, likely a data analyst or statistician, familiar with '\n",
      " 'the intricacies of the R language and its debugging tools.',\n",
      " 'A mental health professional, likely a licensed therapist or psychologist, with expertise in '\n",
      " 'anxiety disorders and cognitive-behavioral therapy, whose work involves diagnosing and treating '\n",
      " 'patients with various types of phobias, including specific phobia, social phobia, and '\n",
      " 'agoraphobia.',\n",
      " 'A space roboticist or aerospace engineer at a research institution focused on robotic space '\n",
      " 'exploration.',\n",
      " 'A Hebrew language scholar or instructor with a focus on biblical Hebrew and Jewish studies.',\n",
      " 'A pediatrician or healthcare professional focused on educating parents about early childhood '\n",
      " 'health, or a parent-to-be who is interested in learning about vaccinations for their unborn or '\n",
      " 'newborn child.',\n",
      " 'A Montessori elementary school teacher or an education administrator responsible for curriculum '\n",
      " 'development and classroom management in a Montessori school setting.',\n",
      " 'An aerospace materials engineer focused on advanced ceramic coatings and plasma deposition '\n",
      " 'techniques for high-temperature applications.',\n",
      " 'An astrophysicist specializing in the study of planetary magnetism and aurora phenomena, likely '\n",
      " 'with a focus on exoplanetary systems and space exploration.',\n",
      " 'An elementary school teacher or educator focused on creating and compiling educational content '\n",
      " 'for young students, likely in a science, reading, or early childhood development curriculum.',\n",
      " 'A forester or park ranger concerned with forest health and pest management in the western United '\n",
      " 'States, likely working in or near national parks.']\n"
     ]
    }
   ],
   "source": [
    "personas = [data[\"persona\"] for data in dataset.take(100)]\n",
    "pp.pprint(personas[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### マルチターン対話データの合成\n",
    "\n",
    "ここからは事後学習のためのマルチターン対話データを生成します。具体的には、\n",
    "\n",
    "- 質問1 (`Q1`): ユーザが質問をする (この部分を Persona-Hub 手法で生成)\n",
    "- 解答1 (`A1`): アシスタントが解答する\n",
    "- 質問2 (`Q2`): ユーザが追加質問をする\n",
    "- 解答2 (`A2`): アシスタントが追加質問に解答する\n",
    "\n",
    "という4つの対話データを生成します。このうち `Q1` の生成に Persona-Hub 手法を適用します。それ以降の対話データは、若干の工夫をしますが基本的に言語モデルの生成に任せます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1 の生成\n",
    "\n",
    "まず、Persona-Hub 手法を使って `Q1` の生成を行います。\n",
    "\n",
    "[元論文のコード](https://github.com/tencent-ailab/persona-hub/blob/main/code/prompt_templates.py)では、数学の問題を生成するプロンプトとして以下が紹介されています。\n",
    "\n",
    "```python\n",
    "math_template = '''Create a math problem related to the following persona:\n",
    "\n",
    "{persona}\n",
    "\n",
    "Note:\n",
    "\n",
    "1. The math problem should be challenging and involve advanced mathematical skills and knowledge. Only top talents can solve it correctly.\n",
    "2. You should make full use of the persona description to create the math problem to ensure that the math problem is unique and specific to the persona.\n",
    "3. Your response should always start with \"Math problem:\". Your response should not include a solution to the created math problem.\n",
    "4. Your created math problem should include no more than 2 sub-problems.\n",
    "'''\n",
    "```\n",
    "\n",
    "これを参考に、プロンプトの一部を修正/パラメータ化して使います。修正点は以下の通りです。\n",
    "\n",
    "- 一部の単語をパラメータ化\n",
    "  - タスクの種類: `task` (e.g. \"math\", \"reasoning\", \"coding\")\n",
    "  - トピックの種類: `topic` (e.g. \"persona\", \"topic\")\n",
    "  - トピックの内容: `item` (e.g. \"SF作家\", \"経営コンサルタント\")\n",
    "  - 対象者: `target` (e.g. \"grade school student\", \"graduate student\")\n",
    "- 難易度を調整\n",
    "  - 元のプロンプトはかなり難易度の高い問題を生成するような表現(`challenging`, `advanced`, `top talents`)となっていたため、難易度を下げるように表現を修正(`simple`, `basic`, `average`)\n",
    "- 小問を生成しないよう修正\n",
    "  - 小問を生成すると対話が複雑になりすぎるため、小問を生成しないように修正(`sub-problems`の行を削除)。代わりにマルチターンで追加質問をするようにする。\n",
    "- 日本語を出力\n",
    "  - 元のプロンプトは英語を出力するようになっているため、日本語を出力するように促すプロンプトを追加\n",
    "\n",
    "上記の修正をしたプロンプトを OpenAI messages 形式で出力する関数を作成します。\n",
    "\n",
    "また、利用する言語モデルで推奨されているシステムプロンプトがある場合は、それを指定します(コメントアウトされた `{\"role\": \"system\", \"content\": \"...\"}` の部分)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_q1_prompt(task: str, topic: str, item: str, target: str) -> list[dict[str, str]]:\n",
    "    Q1_PROMPT_TEMPLATE = \"\"\"Create a {task} problem related to the following {topic}:\n",
    "\n",
    "{item}\n",
    "\n",
    "Note:\n",
    "\n",
    "1. The {task} problem should be simple and involve basic {task} skills and knowledge. Any average {target} can solve it correctly.\n",
    "2. You should make full use of the {topic} description to create the {task} problem to ensure that the {task} problem is unique and specific to the {topic}.\n",
    "3. Your response should always start with \"問題:\". Your response should not include a solution to the created {task} problem.\n",
    "4. 簡潔に日本語で回答してください。\n",
    "\"\"\"\n",
    "    return [\n",
    "        # {\"role\": \"system\", \"content\": \"あなたは親切なAIアシスタントです。日本語で回答してください。\"},\n",
    "        {\"role\": \"user\", \"content\": Q1_PROMPT_TEMPLATE.format(task=task, topic=topic, item=item, target=target)},\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実行して動作を確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': 'Create a math problem related to the following persona:\\n'\n",
      "             '\\n'\n",
      "             'A professional R programmer or researcher, likely a data analyst or statistician, '\n",
      "             'familiar with the intricacies of the R language and its debugging tools.\\n'\n",
      "             '\\n'\n",
      "             'Note:\\n'\n",
      "             '\\n'\n",
      "             '1. The math problem should be simple and involve basic math skills and knowledge. '\n",
      "             'Any average grade school student can solve it correctly.\\n'\n",
      "             '2. You should make full use of the persona description to create the math problem to '\n",
      "             'ensure that the math problem is unique and specific to the persona.\\n'\n",
      "             '3. Your response should always start with \"問題:\". Your response should not include a '\n",
      "             'solution to the created math problem.\\n'\n",
      "             '4. 簡潔に日本語で回答してください。\\n',\n",
      "  'role': 'user'}]\n"
     ]
    }
   ],
   "source": [
    "q1_prompt = get_q1_prompt(\"math\", \"persona\", personas[0], \"grade school student\")\n",
    "pp.pprint(q1_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "言語モデルで推論して Q1 を生成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['問題: '\n",
      " 'R言語を使ってデータを分析している研究者がいます。彼は、データセットの中から50個のサンプルをランダムに選びました。もし彼が全体のデータセットの中に500個のサンプルがある場合、彼が選んだサンプルが全体の何パーセントにあたるかを求めなさい。']\n"
     ]
    }
   ],
   "source": [
    "q1s = llm([get_q1_prompt(\"math\", \"persona\", personas[0], \"grade school student\")])\n",
    "pp.pprint(q1s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "引数を変更して難易度の高い問題を生成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['問題:  \\n'\n",
      " 'あるデータ分析者が、R言語を用いてあるデータセットの回帰分析を行っています。データセットには、独立変数 \\\\(X\\\\) と従属変数 \\\\(Y\\\\) '\n",
      " 'のペアが含まれています。回帰モデルの式が次のように与えられています。\\n'\n",
      " '\\n'\n",
      " '\\\\[ Y = \\\\beta_0 + \\\\beta_1 X + \\\\epsilon \\\\]\\n'\n",
      " '\\n'\n",
      " 'ここで、\\\\(\\\\beta_0\\\\) は切片、\\\\(\\\\beta_1\\\\) は傾き、\\\\(\\\\epsilon\\\\) は誤差項です。データ分析者は、\\\\(X\\\\) の平均値が 50、標準偏差が '\n",
      " '10、\\\\(Y\\\\) の平均値が 100、標準偏差が 15 であることを確認しました。\\n'\n",
      " '\\n'\n",
      " 'また、回帰分析の結果、\\\\(\\\\beta_0 = 10\\\\) と \\\\(\\\\beta_1 = 2\\\\) であることがわかりました。この回帰モデルを用いて、\\\\(X\\\\) の値が 60 '\n",
      " 'のときの予測値 \\\\(Y\\\\) を求めてください。さらに、予測値 \\\\(Y\\\\) の 95% 信頼区間を計算するために必要な標準誤差を仮定し、信頼区間の範囲を求めてください。ただし、標準誤差は '\n",
      " '2 とします。']\n"
     ]
    }
   ],
   "source": [
    "q1s = llm([get_q1_prompt(\"advanced math\", \"persona\", personas[0], \"graduate student\")])\n",
    "pp.pprint(q1s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "問題さなさそうです。\n",
    "\n",
    "次に、`問題:` など余分な部分をルールベース(正規表現)で削除します。言語モデルによっては、解答やヒントを書いてしまうものがありますので、もしそれらが出力されるのであればここで削除しておきます。\n",
    "\n",
    "**Note: この関数が複雑になり過ぎる場合は、プロンプトの見直しや言語モデルの変更を検討した方が良いかもしれません。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_q1(content: str) -> str:\n",
    "    content = content.strip()\n",
    "    content = re.sub(r\"^問題[：:]\", \"\", content, flags=re.DOTALL)\n",
    "    content = re.sub(r\"^Problem[：:]\", \"\", content, flags=re.DOTALL)\n",
    "    content = re.sub(r\"\\n答え[：:].*\", \"\", content, flags=re.DOTALL)\n",
    "    content = re.sub(r\"\\n[解回]答[：:].*\", \"\", content, flags=re.DOTALL)\n",
    "    content = re.sub(r\"\\n[Aa]nswer[：:].*\", \"\", content, flags=re.DOTALL)  # cspell: disable-line\n",
    "    content = content.strip()\n",
    "    return content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実行して動作を確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'あるデータ分析者が、R言語を用いてあるデータセットの回帰分析を行っています。データセットには、独立変数 \\\\(X\\\\) と従属変数 \\\\(Y\\\\) のペアが含まれています。回帰モデルの式が次のように与えられています。\\n\\n\\\\[ Y = \\\\beta_0 + \\\\beta_1 X + \\\\epsilon \\\\]\\n\\nここで、\\\\(\\\\beta_0\\\\) は切片、\\\\(\\\\beta_1\\\\) は傾き、\\\\(\\\\epsilon\\\\) は誤差項です。データ分析者は、\\\\(X\\\\) の平均値が 50、標準偏差が 10、\\\\(Y\\\\) の平均値が 100、標準偏差が 15 であることを確認しました。\\n\\nまた、回帰分析の結果、\\\\(\\\\beta_0 = 10\\\\) と \\\\(\\\\beta_1 = 2\\\\) であることがわかりました。この回帰モデルを用いて、\\\\(X\\\\) の値が 60 のときの予測値 \\\\(Y\\\\) を求めてください。さらに、予測値 \\\\(Y\\\\) の 95% 信頼区間を計算するために必要な標準誤差を仮定し、信頼区間の範囲を求めてください。ただし、標準誤差は 2 とします。'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_q1(q1s[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "問題なさそうです。\n",
    "\n",
    "作成した関数を組み合わせて、バッチ処理で `Q1` を生成する関数を作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_q1(\n",
    "    llm: LanguageModel, tasks: list[str], topics: list[str], items: list[str], targets: list[str]\n",
    ") -> list[str]:\n",
    "    return [\n",
    "        filter_q1(q1)\n",
    "        for q1 in llm([\n",
    "            get_q1_prompt(task, topic, item, target)\n",
    "            for task, topic, item, target in zip(tasks, topics, items, targets)\n",
    "        ])\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実行して動作を確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['R言語を使ってデータを分析している研究者がいます。彼は、データセットの中から50個のサンプルをランダムに選びました。もし彼が全体のデータセットの中に500個のサンプルがある場合、彼が選んだサンプルが全体の何パーセントにあたるかを求めてください。',\n",
      " 'ある精神健康専門家が、特定の恐怖症と社会不安障害を抱える患者の治療を行っています。彼は、10人の患者を対象にした研究を行い、その中の患者が特定の恐怖症を持つ確率は70%、社会不安障害を持つ確率は50%です。患者の中には特定の恐怖症と社会不安障害の両方を抱える者もいます。このような患者の割合が20%であると仮定します。\\n'\n",
      " '\\n'\n",
      " '1. 特定の恐怖症を持つ患者の数と社会不安障害を持つ患者の数を求めてください。\\n'\n",
      " '2. どのくらいの割合の患者が特定の恐怖症または社会不安障害を持っているかを求めてください。']\n"
     ]
    }
   ],
   "source": [
    "q1s = generate_q1(\n",
    "    llm,\n",
    "    [\"math\", \"advanced math\"],\n",
    "    [\"persona\", \"persona\"],\n",
    "    personas[:2],\n",
    "    [\"grade school student\", \"graduate student\"],\n",
    ")\n",
    "pp.pprint(q1s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "問題なさそうです。ここまでで `Q1` を生成する関数の実装が完了しました。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A1 の生成\n",
    "\n",
    "次に、`A1` の生成を行います。ここでは基本的に `Q1` を入力して、長さ指定(`簡潔に`)と、出力言語の指定(`日本語で`)をして言語モデルに生成させます。言語モデルによっては、表現を微調整する必要があるかもしれません。\n",
    "\n",
    "実行の流れは `Q1` と同様ですので、ここではコードのみ記載します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_a1_prompt(q1: str) -> list[dict]:\n",
    "    A1_PROMPT_TEMPLATE = \"{q1}\\n\\n簡潔に日本語で回答してください。\"\n",
    "    return [\n",
    "        # {\"role\": \"system\", \"content\": \"あなたは親切なAIアシスタントです。日本語で回答してください。\"},\n",
    "        {\"role\": \"user\", \"content\": A1_PROMPT_TEMPLATE.format(q1=q1)},\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': 'R言語を使ってデータを分析している研究者がいます。彼は、データセットの中から50個のサンプルをランダムに選びました。もし彼が全体のデータセットの中に500個のサンプルがある場合、彼が選んだサンプルが全体の何パーセントにあたるかを求めてください。\\n'\n",
      "             '\\n'\n",
      "             '簡潔に日本語で回答してください。',\n",
      "  'role': 'user'}]\n"
     ]
    }
   ],
   "source": [
    "a1_prompt = get_a1_prompt(q1s[0])\n",
    "pp.pprint(a1_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['彼が選んだ50個のサンプルは、全体の500個のサンプルに対して10%にあたります。計算式は以下の通りです：\\n\\n(50 / 500) × 100 = 10%']\n"
     ]
    }
   ],
   "source": [
    "a1s = llm([get_a1_prompt(q1s[0])])\n",
    "pp.pprint(a1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1. \\n'\n",
      " '- 特定の恐怖症を持つ患者の数：10人 × 70% = 7人\\n'\n",
      " '- 社会不安障害を持つ患者の数：10人 × 50% = 5人\\n'\n",
      " '\\n'\n",
      " '2. \\n'\n",
      " '特定の恐怖症と社会不安障害の両方を持つ患者は20%なので、10人の患者の中では2人です。\\n'\n",
      " '\\n'\n",
      " '特定の恐怖症または社会不安障害を持つ患者の数は次のように計算できます：\\n'\n",
      " '- 特定の恐怖症を持つ患者（7人）\\n'\n",
      " '- 社会不安障害を持つ患者（5人）\\n'\n",
      " '- 両方を持つ患者（2人）を引く。\\n'\n",
      " '\\n'\n",
      " 'したがって、特定の恐怖症または社会不安障害を持つ患者の数は：\\n'\n",
      " '7 + 5 - 2 = 10人\\n'\n",
      " '\\n'\n",
      " '割合は：\\n'\n",
      " '(10人 ÷ 10人) × 100% = 100%\\n'\n",
      " '\\n'\n",
      " 'つまり、すべての患者が特定の恐怖症または社会不安障害を持っています。']\n"
     ]
    }
   ],
   "source": [
    "a1s = llm([get_a1_prompt(q1s[1])])\n",
    "pp.pprint(a1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_a1(content: str) -> str:\n",
    "    content = content.strip()\n",
    "    content = re.sub(r\"^答え[：:]\", \"\", content, flags=re.DOTALL)\n",
    "    content = re.sub(r\"^[解回]答[：:]\", \"\", content, flags=re.DOTALL)\n",
    "    content = re.sub(r\"^[Aa]nswer[：:]\", \"\", content, flags=re.DOTALL)  # cspell: disable-line\n",
    "    content = content.strip()\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_a1(llm: LanguageModel, q1s: list[str]) -> list[str]:\n",
    "    return [filter_a1(a1) for a1 in llm([get_a1_prompt(q1) for q1 in q1s])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['彼が選んだ50個のサンプルは、全体の500個のサンプルに対して10%にあたります。計算式は以下の通りです：\\n\\n(50 / 500) × 100 = 10%',\n",
      " '1. \\n'\n",
      " '- 特定の恐怖症を持つ患者の数：10人 × 70% = 7人\\n'\n",
      " '- 社会不安障害を持つ患者の数：10人 × 50% = 5人\\n'\n",
      " '\\n'\n",
      " '2. \\n'\n",
      " '特定の恐怖症と社会不安障害の両方を持つ患者は20%なので、10人のうち2人です。この場合、特定の恐怖症または社会不安障害を持つ患者の数は次のように計算できます。\\n'\n",
      " '\\n'\n",
      " '特定の恐怖症のみ：7人 - 2人 = 5人  \\n'\n",
      " '社会不安障害のみ：5人 - 2人 = 3人  \\n'\n",
      " '両方を持つ患者：2人  \\n'\n",
      " '\\n'\n",
      " '合計：5人 + 3人 + 2人 = 10人\\n'\n",
      " '\\n'\n",
      " 'したがって、特定の恐怖症または社会不安障害を持つ患者の割合は100%です。']\n"
     ]
    }
   ],
   "source": [
    "a1s = generate_a1(llm, q1s)\n",
    "pp.pprint(a1s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2 の生成\n",
    "\n",
    "次に、追加質問 `Q2` の生成を行います。\n",
    "\n",
    "- まず `Q1` に関連する質問であることを強調します(`前述の問題をより理解するために`の部分)。これが無いと `Q2` で新たな別の質問を生成してしまうことがあります。\n",
    "- 次に `問題の一部を変更したり、条件を追加しても良いです` という部分で、`Q1` の問題の一部を変更することを促します。これにより、`Q2` が `Q1` に関連する質問となる確率を高めることができます。\n",
    "- 最後に答えを含まないように注意を促します(`決して答えを含めないでください`の部分)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_q2_prompt(q1: str, a1: str) -> list[dict[str, str]]:\n",
    "    Q2_PROMPT_TEMPLATE = \"前述の問題をより理解するために、簡潔な追加の質問を一つ作ってください。問題の一部を変更したり、条件を追加しても良いです。追加の質問だけを書き、決して答えを含めないでください。\"\n",
    "    return [\n",
    "        # {\"role\": \"system\", \"content\": \"あなたは親切なAIアシスタントです。日本語で回答してください。\"},\n",
    "        {\"role\": \"user\", \"content\": q1},\n",
    "        {\"role\": \"assistant\", \"content\": a1},\n",
    "        {\"role\": \"user\", \"content\": Q2_PROMPT_TEMPLATE},\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': 'R言語を使ってデータを分析している研究者がいます。彼は、データセットの中から50個のサンプルをランダムに選びました。もし彼が全体のデータセットの中に500個のサンプルがある場合、彼が選んだサンプルが全体の何パーセントにあたるかを求めてください。',\n",
      "  'role': 'user'},\n",
      " {'content': '彼が選んだ50個のサンプルは、全体の500個のサンプルに対して10%にあたります。計算式は以下の通りです：\\n\\n(50 / 500) × 100 = 10%',\n",
      "  'role': 'assistant'},\n",
      " {'content': '前述の問題をより理解するために、簡潔な追加の質問を一つ作ってください。問題の一部を変更したり、条件を追加しても良いです。追加の質問だけを書き、決して答えを含めないでください。',\n",
      "  'role': 'user'}]\n"
     ]
    }
   ],
   "source": [
    "q2_prompt = get_q2_prompt(q1s[0], a1s[0])\n",
    "pp.pprint(q2_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['もし彼が全体のデータセットから100個のサンプルをランダムに選んだ場合、彼が選んだサンプルが全体の何パーセントにあたるかを求めてください。']\n"
     ]
    }
   ],
   "source": [
    "q2s = llm([get_q2_prompt(q1s[0], a1s[0])])\n",
    "pp.pprint(q2s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_q2(content: str) -> str:\n",
    "    content = content.strip()\n",
    "    content = re.sub(r\"^追加の質問[：:]\", \"\", content, flags=re.DOTALL)\n",
    "    content = re.sub(r\"^質問[：:]\", \"\", content, flags=re.DOTALL)\n",
    "    content = content.strip()\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_q2(llm: LanguageModel, q1s: list[str], a1s: list[str]) -> list[str]:\n",
    "    return [filter_q2(q2) for q2 in llm([get_q2_prompt(q1, a1) for q1, a1 in zip(q1s, a1s)])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['もし彼が全体のデータセットから100個のサンプルをランダムに選んだ場合、彼が選んだサンプルが全体の何パーセントにあたるかを求めてください。',\n",
      " '特定の恐怖症を持つ患者の中で、社会不安障害を持たない患者の割合はどのくらいですか？']\n"
     ]
    }
   ],
   "source": [
    "q2s = generate_q2(llm, q1s, a1s)\n",
    "pp.pprint(q2s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A2 の生成\n",
    "\n",
    "最後に、`A2` の生成を行います。基本的に `A1` の生成と同様ですので、ここではコードのみ記載します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_a2_prompt(q1: str, a1: str, q2: str) -> list[dict[str, str]]:\n",
    "    A2_PROMPT_TEMPLATE = \"{q2}\\n\\n簡潔に日本語で回答してください。\"\n",
    "    return [\n",
    "        # {\"role\": \"system\", \"content\": \"あなたは親切なAIアシスタントです。日本語で回答してください。\"},\n",
    "        {\"role\": \"user\", \"content\": q1},\n",
    "        {\"role\": \"assistant\", \"content\": a1},\n",
    "        {\"role\": \"user\", \"content\": A2_PROMPT_TEMPLATE.format(q2=q2)},\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': 'R言語を使ってデータを分析している研究者がいます。彼は、データセットの中から50個のサンプルをランダムに選びました。もし彼が全体のデータセットの中に500個のサンプルがある場合、彼が選んだサンプルが全体の何パーセントにあたるかを求めてください。',\n",
      "  'role': 'user'},\n",
      " {'content': '彼が選んだ50個のサンプルは、全体の500個のサンプルに対して10%にあたります。計算式は以下の通りです：\\n\\n(50 / 500) × 100 = 10%',\n",
      "  'role': 'assistant'},\n",
      " {'content': 'もし彼が全体のデータセットから100個のサンプルをランダムに選んだ場合、彼が選んだサンプルが全体の何パーセントにあたるかを求めてください。\\n'\n",
      "             '\\n'\n",
      "             '簡潔に日本語で回答してください。',\n",
      "  'role': 'user'}]\n"
     ]
    }
   ],
   "source": [
    "a2_prompt = get_a2_prompt(q1s[0], a1s[0], q2s[0])\n",
    "pp.pprint(a2_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['彼が選んだ100個のサンプルは、全体の500個のサンプルに対して20%にあたります。',\n",
      " '特定の恐怖症を持つ患者の中で、社会不安障害を持たない患者の数は、特定の恐怖症を持つ患者7人から両方を持つ患者2人を引いた5人です。\\n'\n",
      " '\\n'\n",
      " 'したがって、特定の恐怖症を持つ患者の中で社会不安障害を持たない患者の割合は、5人 ÷ 7人 ≈ 71.4%です。']\n"
     ]
    }
   ],
   "source": [
    "a2s = llm([get_a2_prompt(q1, a1, q2) for q1, a1, q2 in zip(q1s, a1s, q2s)])\n",
    "pp.pprint(a2s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_a2(content: str) -> str:\n",
    "    content = content.strip()\n",
    "    content = re.sub(r\"^答え[：:]\", \"\", content, flags=re.DOTALL)\n",
    "    content = re.sub(r\"^[解回]答[：:]\", \"\", content, flags=re.DOTALL)\n",
    "    content = re.sub(r\"^[Aa]nswer[：:]\", \"\", content, flags=re.DOTALL)  # cspell: disable-line\n",
    "    content = content.strip()\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_a2(llm: LanguageModel, q1s: list[str], a1s: list[str], q2s: list[str]) -> list[str]:\n",
    "    return [filter_a2(a2) for a2 in llm([get_a2_prompt(q1, a1, q2) for q1, a1, q2 in zip(q1s, a1s, q2s)])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['彼が選んだ100個のサンプルは、全体の500個のサンプルに対して20%にあたります。',\n",
      " '特定の恐怖症を持つ患者の中で、社会不安障害を持たない患者の数は、特定の恐怖症を持つ患者7人から両方を持つ患者2人を引いた5人です。\\n'\n",
      " '\\n'\n",
      " 'したがって、特定の恐怖症を持つ患者の中で社会不安障害を持たない患者の割合は、5人 ÷ 7人 = 約71.4%です。']\n"
     ]
    }
   ],
   "source": [
    "a2s = generate_a2(llm, q1s, a1s, q2s)\n",
    "pp.pprint(a2s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここまでの対話データの流れを確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('R言語を使ってデータを分析している研究者がいます。彼は、データセットの中から50個のサンプルをランダムに選びました。もし彼が全体のデータセットの中に500個のサンプルがある場合、彼が選んだサンプルが全体の何パーセントにあたるかを求めてください。',\n",
      " '彼が選んだ50個のサンプルは、全体の500個のサンプルに対して10%にあたります。計算式は以下の通りです：\\n\\n(50 / 500) × 100 = 10%',\n",
      " 'もし彼が全体のデータセットから100個のサンプルをランダムに選んだ場合、彼が選んだサンプルが全体の何パーセントにあたるかを求めてください。',\n",
      " '彼が選んだ100個のサンプルは、全体の500個のサンプルに対して20%にあたります。')\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(list(zip(q1s, a1s, q2s, a2s))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ある精神健康専門家が、特定の恐怖症と社会不安障害を抱える患者の治療を行っています。彼は、10人の患者を対象にした研究を行い、その中の患者が特定の恐怖症を持つ確率は70%、社会不安障害を持つ確率は50%です。患者の中には特定の恐怖症と社会不安障害の両方を抱える者もいます。このような患者の割合が20%であると仮定します。\\n'\n",
      " '\\n'\n",
      " '1. 特定の恐怖症を持つ患者の数と社会不安障害を持つ患者の数を求めてください。\\n'\n",
      " '2. どのくらいの割合の患者が特定の恐怖症または社会不安障害を持っているかを求めてください。',\n",
      " '1. \\n'\n",
      " '- 特定の恐怖症を持つ患者の数：10人 × 70% = 7人\\n'\n",
      " '- 社会不安障害を持つ患者の数：10人 × 50% = 5人\\n'\n",
      " '\\n'\n",
      " '2. \\n'\n",
      " '特定の恐怖症と社会不安障害の両方を持つ患者は20%なので、10人のうち2人です。この場合、特定の恐怖症または社会不安障害を持つ患者の数は次のように計算できます。\\n'\n",
      " '\\n'\n",
      " '特定の恐怖症のみ：7人 - 2人 = 5人  \\n'\n",
      " '社会不安障害のみ：5人 - 2人 = 3人  \\n'\n",
      " '両方を持つ患者：2人  \\n'\n",
      " '\\n'\n",
      " '合計：5人 + 3人 + 2人 = 10人\\n'\n",
      " '\\n'\n",
      " 'したがって、特定の恐怖症または社会不安障害を持つ患者の割合は100%です。',\n",
      " '特定の恐怖症を持つ患者の中で、社会不安障害を持たない患者の割合はどのくらいですか？',\n",
      " '特定の恐怖症を持つ患者の中で、社会不安障害を持たない患者の数は、特定の恐怖症を持つ患者7人から両方を持つ患者2人を引いた5人です。\\n'\n",
      " '\\n'\n",
      " 'したがって、特定の恐怖症を持つ患者の中で社会不安障害を持たない患者の割合は、5人 ÷ 7人 = 約71.4%です。')\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(list(zip(q1s, a1s, q2s, a2s))[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "面白い問題かどうかはともかく、問題なさそうです。これで `A2` の生成も完了しました。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### マルチターン対話データの生成\n",
    "\n",
    "これまで作成した関数を組み合わせて、マルチターンの対話データを生成する関数を作成します。結果は OpenAI messages 形式で出力します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesis_multi_turn_qa(\n",
    "    llm: LanguageModel, tasks: list[str], topics: list[str], items: list[str], targets: list[str]\n",
    ") -> list[dict[str, str | list[dict[str, str]]]]:\n",
    "    q1s = generate_q1(llm, tasks, topics, items, targets)\n",
    "    a1s = generate_a1(llm, q1s)\n",
    "    q2s = generate_q2(llm, q1s, a1s)\n",
    "    a2s = generate_a2(llm, q1s, a1s, q2s)\n",
    "    return [\n",
    "        {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"user\", \"content\": q1},\n",
    "                {\"role\": \"assistant\", \"content\": a1},\n",
    "                {\"role\": \"user\", \"content\": q2},\n",
    "                {\"role\": \"assistant\", \"content\": a2},\n",
    "            ],\n",
    "            \"task\": task,\n",
    "            \"topic\": topic,\n",
    "            \"item\": item,\n",
    "            \"target\": target,\n",
    "        }\n",
    "        for task, topic, item, target, q1, a1, q2, a2 in zip(tasks, topics, items, targets, q1s, a1s, q2s, a2s)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実行して動作を確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'item': 'A professional R programmer or researcher, likely a data analyst or statistician, '\n",
      "          'familiar with the intricacies of the R language and its debugging tools.',\n",
      "  'messages': [{'content': 'R言語を使ってデータを分析している研究者がいます。彼は、データセットの中から50個のサンプルをランダムに選びました。もし彼が全体のデータセットの中に500個のサンプルがある場合、選ばれたサンプルが全体に占める割合は何パーセントですか？',\n",
      "                'role': 'user'},\n",
      "               {'content': '選ばれたサンプルは全体のデータセットの50個のサンプルで、全体は500個です。したがって、割合は次のように計算します。\\n'\n",
      "                           '\\n'\n",
      "                           '\\\\[\\n'\n",
      "                           '\\\\frac{50}{500} \\\\times 100 = 10\\\\%\\n'\n",
      "                           '\\\\]\\n'\n",
      "                           '\\n'\n",
      "                           'したがって、選ばれたサンプルは全体の10%を占めます。',\n",
      "                'role': 'assistant'},\n",
      "               {'content': 'データセットの中に1000個のサンプルがあり、そこから70個のサンプルをランダムに選んだ場合、選ばれたサンプルが全体に占める割合は何パーセントですか？',\n",
      "                'role': 'user'},\n",
      "               {'content': '選ばれたサンプルは70個で、全体は1000個です。したがって、割合は次のように計算します。\\n'\n",
      "                           '\\n'\n",
      "                           '\\\\[\\n'\n",
      "                           '\\\\frac{70}{1000} \\\\times 100 = 7\\\\%\\n'\n",
      "                           '\\\\]\\n'\n",
      "                           '\\n'\n",
      "                           '選ばれたサンプルは全体の7%を占めます。',\n",
      "                'role': 'assistant'}],\n",
      "  'target': 'grade school student',\n",
      "  'task': 'math',\n",
      "  'topic': 'persona'}]\n"
     ]
    }
   ],
   "source": [
    "qas = synthesis_multi_turn_qa(\n",
    "    llm,\n",
    "    [\"math\"],\n",
    "    [\"persona\"],\n",
    "    personas[:1],\n",
    "    [\"grade school student\"],\n",
    ")\n",
    "pp.pprint(qas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この関数をバッチ処理で実行し、結果を JSONL ファイルに保存する関数を作成します。`task`, `topic`, `item`, `target` は、与えられた引数からランダムに選択して、対話データを生成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_synthesis_multi_turn_qa(\n",
    "    llm: LanguageModel,\n",
    "    task_list: list[str],\n",
    "    topic_list: list[str],\n",
    "    item_list: list[str],\n",
    "    target_list: list[str],\n",
    "    num_samples: int = 1,\n",
    "    batch_size: int = 1,\n",
    "    output_jsonl: str = \"output.jsonl\",\n",
    "):\n",
    "    with open(output_jsonl, \"a\", encoding=\"utf-8\") as f:\n",
    "        for i in range(num_samples // batch_size):\n",
    "            tasks = [random.choice(task_list) for _ in range(batch_size)]\n",
    "            topics = [random.choice(topic_list) for _ in range(batch_size)]\n",
    "            items = [random.choice(item_list) for _ in range(batch_size)]\n",
    "            targets = [random.choice(target_list) for _ in range(batch_size)]\n",
    "            assert len(tasks) == len(topics) == len(items) == len(targets) == batch_size\n",
    "            qas = synthesis_multi_turn_qa(llm, tasks, topics, items, targets)\n",
    "            for qa in qas:\n",
    "                f.write(json.dumps(qa, ensure_ascii=False) + \"\\n\")\n",
    "                print(pp.pformat(qa))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ペルソナデータから対話データを生成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'item': 'A materials scientist researching nano-scale materials and liquid crystal technology, '\n",
      "         'likely with a focus on computational modeling and simulations.',\n",
      " 'messages': [{'content': 'ある材料科学者がナノスケールの材料を研究しています。彼は、液晶技術に使用される2種類のナノ材料を持っています。材料Aの体積は4立方センチメートル、材料Bの体積は6立方センチメートルです。彼はこれらの材料を混ぜて、新しいナノ材料を作る予定です。新しいナノ材料の体積は材料Aと材料Bの体積を合わせたものになります。新しいナノ材料の体積は何立方センチメートルになりますか？',\n",
      "               'role': 'user'},\n",
      "              {'content': '新しいナノ材料の体積は10立方センチメートルになります。', 'role': 'assistant'},\n",
      "              {'content': '材料Aの体積が4立方センチメートル、材料Bの体積が6立方センチメートルの場合、材料Aの体積を2立方センチメートル増やしたら、新しいナノ材料の体積は何立方センチメートルになりますか？',\n",
      "               'role': 'user'},\n",
      "              {'content': '新しいナノ材料の体積は12立方センチメートルになります。', 'role': 'assistant'}],\n",
      " 'target': 'grade school student',\n",
      " 'task': 'math',\n",
      " 'topic': 'persona'}\n"
     ]
    }
   ],
   "source": [
    "run_synthesis_multi_turn_qa(\n",
    "    llm,\n",
    "    [\"math\", \"arithmetic\", \"basic math\", \"basic arithmetic\"],\n",
    "    [\"persona\"],\n",
    "    personas,\n",
    "    [\"grade school student\"],\n",
    "    1,\n",
    "    1,\n",
    "    \"output.jsonl\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "難易度を上げて生成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'item': 'A foreign affairs analyst with a focus on international relations, geopolitics, and the '\n",
      "         \"diplomatic history of the People's Republic of China.\",\n",
      " 'messages': [{'content': '中国の外交政策に関するデータを分析している外国 affairs analyst '\n",
      "                          'がいます。彼は、過去10年間における中国の主要な貿易相手国の数と、それぞれの国との貿易額を調査しました。次の情報があります：\\n'\n",
      "                          '\\n'\n",
      "                          '- 中国が貿易を行っている国の数: \\\\( n \\\\)\\n'\n",
      "                          '- 各国との貿易額の合計: \\\\( S \\\\) 兆ドル\\n'\n",
      "                          '- 貿易相手国の平均貿易額: \\\\( A \\\\) 兆ドル\\n'\n",
      "                          '\\n'\n",
      "                          '彼は、貿易相手国の数 \\\\( n \\\\) を求めたいと思っています。以下の条件が与えられています：\\n'\n",
      "                          '\\n'\n",
      "                          '1. 貿易相手国の平均貿易額は、合計貿易額 \\\\( S \\\\) を貿易相手国の数 \\\\( n \\\\) で割った値である。\\n'\n",
      "                          '2. 過去10年間の合計貿易額 \\\\( S \\\\) は、46兆ドルであり、平均貿易額 \\\\( A \\\\) は4.6兆ドルである。\\n'\n",
      "                          '\\n'\n",
      "                          'この情報を基に、貿易相手国の数 \\\\( n \\\\) を求めなさい。',\n",
      "               'role': 'user'},\n",
      "              {'content': '貿易相手国の数 \\\\( n \\\\) は、平均貿易額 \\\\( A \\\\) と合計貿易額 \\\\( S \\\\) の関係から求めることができます。\\n'\n",
      "                          '\\n'\n",
      "                          '平均貿易額 \\\\( A \\\\) は次のように定義されています：\\n'\n",
      "                          '\\n'\n",
      "                          '\\\\[\\n'\n",
      "                          'A = \\\\frac{S}{n}\\n'\n",
      "                          '\\\\]\\n'\n",
      "                          '\\n'\n",
      "                          '与えられた情報から、合計貿易額 \\\\( S = 46 \\\\) 兆ドル、平均貿易額 \\\\( A = 4.6 \\\\) 兆ドルです。この式を \\\\( '\n",
      "                          'n \\\\) について解くと：\\n'\n",
      "                          '\\n'\n",
      "                          '\\\\[\\n'\n",
      "                          'n = \\\\frac{S}{A} = \\\\frac{46}{4.6} = 10\\n'\n",
      "                          '\\\\]\\n'\n",
      "                          '\\n'\n",
      "                          'したがって、中国の貿易相手国の数 \\\\( n \\\\) は 10 です。',\n",
      "               'role': 'assistant'},\n",
      "              {'content': '過去10年間の合計貿易額 \\\\( S \\\\) が50兆ドルに増加し、平均貿易額 \\\\( A \\\\) が5兆ドルに変更された場合、貿易相手国の数 '\n",
      "                          '\\\\( n \\\\) はいくつになりますか？',\n",
      "               'role': 'user'},\n",
      "              {'content': '新しい合計貿易額 \\\\( S = 50 \\\\) 兆ドル、平均貿易額 \\\\( A = 5 \\\\) 兆ドルです。貿易相手国の数 \\\\( n \\\\) '\n",
      "                          'は次のように計算できます：\\n'\n",
      "                          '\\n'\n",
      "                          '\\\\[\\n'\n",
      "                          'n = \\\\frac{S}{A} = \\\\frac{50}{5} = 10\\n'\n",
      "                          '\\\\]\\n'\n",
      "                          '\\n'\n",
      "                          'したがって、貿易相手国の数 \\\\( n \\\\) は 10 です。',\n",
      "               'role': 'assistant'}],\n",
      " 'target': 'graduate student',\n",
      " 'task': 'advanced math',\n",
      " 'topic': 'persona'}\n"
     ]
    }
   ],
   "source": [
    "run_synthesis_multi_turn_qa(\n",
    "    llm,\n",
    "    [\"advanced math\"],\n",
    "    [\"persona\"],\n",
    "    personas,\n",
    "    [\"graduate student\"],\n",
    "    1,\n",
    "    1,\n",
    "    \"output.jsonl\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同様に、論理推論の問題も生成してみましょう。論理推論の問題生成は難易度が高いため、性能の低い言語モデルではうまくいかないかもしれません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'item': 'A physics professor teaching introductory electromagnetism classes, familiar with '\n",
      "         'condensed matter physics and having experience in explaining complex concepts to '\n",
      "         'first-year students.',\n",
      " 'messages': [{'content': 'ある物理学の教授が、初級電磁気学の授業で3つの異なる実験を行うことに決めました。実験Aは静電気の性質を示すもので、実験Bは電流の流れを示し、実験Cは磁場の影響を示します。教授は次のように言いました。「実験Bは実験Aよりも簡単で、実験Cは実験Bよりも難しい。」この時、どの実験が最も簡単で、どの実験が最も難しいでしょうか？',\n",
      "               'role': 'user'},\n",
      "              {'content': '実験Aが最も簡単で、実験Cが最も難しいです。', 'role': 'assistant'},\n",
      "              {'content': '教授が「実験Aは実験Cよりも簡単で、実験Bは実験Aと同じくらいの難しさだ」と言った場合、どの実験が最も簡単で、どの実験が最も難しいでしょうか？',\n",
      "               'role': 'user'},\n",
      "              {'content': '最も簡単なのは実験Aで、最も難しいのは実験Cです。実験Bは実験Aと同じくらいの難しさです。', 'role': 'assistant'}],\n",
      " 'target': 'grade school student',\n",
      " 'task': 'logical reasoning',\n",
      " 'topic': 'persona'}\n"
     ]
    }
   ],
   "source": [
    "run_synthesis_multi_turn_qa(\n",
    "    llm,\n",
    "    [\"logical reasoning\"],\n",
    "    [\"persona\"],\n",
    "    personas,\n",
    "    [\"grade school student\"],\n",
    "    1,\n",
    "    1,\n",
    "    \"output.jsonl\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "コーディングの問題も生成してみましょう。コーディングに特化した言語モデルを使うとより良い結果が得られるかもしれません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'item': 'A veterinarian focused on zoonotic diseases and preventative pet care, likely with a '\n",
      "         'strong interest in public health and education.',\n",
      " 'messages': [{'content': '獣医師として、あなたはペットの健康管理のための簡単なデータベースを作成したいと考えています。以下の情報を含むペットのリストを作成するプログラムを作成してください。\\n'\n",
      "                          '\\n'\n",
      "                          '1. ペットの名前\\n'\n",
      "                          '2. 種類（犬、猫など）\\n'\n",
      "                          '3. 年齢\\n'\n",
      "                          '4. 最近の健康診断の結果（合格または不合格）\\n'\n",
      "                          '\\n'\n",
      "                          'プログラムでは、ユーザーにペットの情報を入力させ、その情報をリストに追加する機能を持たせてください。また、全てのペットの情報を表示する関数も作成してください。入力が完了したら、「健康診断の結果が不合格のペットはいますか？」という質問を表示し、該当するペットの名前をリストアップする機能も追加してください。',\n",
      "               'role': 'user'},\n",
      "              {'content': '以下は、ペットの健康管理のための簡単なデータベースを作成するPythonプログラムの例です。\\n'\n",
      "                          '\\n'\n",
      "                          '```python\\n'\n",
      "                          'class Pet:\\n'\n",
      "                          '    def __init__(self, name, species, age, health_check):\\n'\n",
      "                          '        self.name = name\\n'\n",
      "                          '        self.species = species\\n'\n",
      "                          '        self.age = age\\n'\n",
      "                          '        self.health_check = health_check\\n'\n",
      "                          '\\n'\n",
      "                          'class PetDatabase:\\n'\n",
      "                          '    def __init__(self):\\n'\n",
      "                          '        self.pets = []\\n'\n",
      "                          '    \\n'\n",
      "                          '    def add_pet(self, name, species, age, health_check):\\n'\n",
      "                          '        new_pet = Pet(name, species, age, health_check)\\n'\n",
      "                          '        self.pets.append(new_pet)\\n'\n",
      "                          '    \\n'\n",
      "                          '    def display_pets(self):\\n'\n",
      "                          '        for pet in self.pets:\\n'\n",
      "                          '            print(f\"名前: {pet.name}, 種類: {pet.species}, 年齢: {pet.age}, '\n",
      "                          '健康診断: {pet.health_check}\")\\n'\n",
      "                          '\\n'\n",
      "                          '    def check_health_status(self):\\n'\n",
      "                          '        unhealthy_pets = [pet.name for pet in self.pets if '\n",
      "                          'pet.health_check == \"不合格\"]\\n'\n",
      "                          '        if unhealthy_pets:\\n'\n",
      "                          '            print(\"健康診断の結果が不合格のペット:\", \", \".join(unhealthy_pets))\\n'\n",
      "                          '        else:\\n'\n",
      "                          '            print(\"全てのペットは健康診断に合格しています。\")\\n'\n",
      "                          '\\n'\n",
      "                          'def main():\\n'\n",
      "                          '    database = PetDatabase()\\n'\n",
      "                          '    \\n'\n",
      "                          '    while True:\\n'\n",
      "                          '        name = input(\"ペットの名前を入力してください: \")\\n'\n",
      "                          '        species = input(\"ペットの種類を入力してください（犬、猫など）: \")\\n'\n",
      "                          '        age = input(\"ペットの年齢を入力してください: \")\\n'\n",
      "                          '        health_check = input(\"健康診断の結果を入力してください（合格または不合格）: \")\\n'\n",
      "                          '        \\n'\n",
      "                          '        database.add_pet(name, species, age, health_check)\\n'\n",
      "                          '        \\n'\n",
      "                          '        another = input(\"他のペットを追加しますか？ (はい/いいえ): \")\\n'\n",
      "                          '        if another.lower() != \"はい\":\\n'\n",
      "                          '            break\\n'\n",
      "                          '    \\n'\n",
      "                          '    print(\"\\\\n全てのペットの情報:\")\\n'\n",
      "                          '    database.display_pets()\\n'\n",
      "                          '    \\n'\n",
      "                          '    print(\"\\\\n健康診断の結果が不合格のペットはいますか？\")\\n'\n",
      "                          '    database.check_health_status()\\n'\n",
      "                          '\\n'\n",
      "                          'if __name__ == \"__main__\":\\n'\n",
      "                          '    main()\\n'\n",
      "                          '```\\n'\n",
      "                          '\\n'\n",
      "                          'このプログラムでは、ペットの情報を入力し、リストに追加し、全てのペットの情報を表示し、不合格のペットをリストアップする機能があります。使用者は',\n",
      "               'role': 'assistant'},\n",
      "              {'content': 'ペットの健康診断の結果が不合格の場合、次回の診断日を入力する機能を追加できますか？その場合、どのようにデータを管理しますか？',\n",
      "               'role': 'user'},\n",
      "              {'content': 'もちろん、ペットの健康診断の結果が不合格の場合に次回の診断日を入力する機能を追加できます。以下のようにデータを管理することができます。\\n'\n",
      "                          '\\n'\n",
      "                          '1. **次回の診断日**を新たな属性として`Pet`クラスに追加します。\\n'\n",
      "                          '2. 健康診断の結果が「不合格」の場合、次回の診断日を入力させ、その情報を`Pet`オブジェクトに保存します。\\n'\n",
      "                          '\\n'\n",
      "                          '具体的には、`Pet`クラスに`next_check_date`という属性を追加し、健康診断が不合格の場合のみその値を設定します。以下は、変更した部分の例です。\\n'\n",
      "                          '\\n'\n",
      "                          '```python\\n'\n",
      "                          'class Pet:\\n'\n",
      "                          '    def __init__(self, name, species, age, health_check, '\n",
      "                          'next_check_date=None):\\n'\n",
      "                          '        self.name = name\\n'\n",
      "                          '        self.species = species\\n'\n",
      "                          '        self.age = age\\n'\n",
      "                          '        self.health_check = health_check\\n'\n",
      "                          '        self.next_check_date = next_check_date\\n'\n",
      "                          '\\n'\n",
      "                          '# 省略...\\n'\n",
      "                          '\\n'\n",
      "                          'def main():\\n'\n",
      "                          '    database = PetDatabase()\\n'\n",
      "                          '    \\n'\n",
      "                          '    while True:\\n'\n",
      "                          '        name = input(\"ペットの名前を入力してください: \")\\n'\n",
      "                          '        species = input(\"ペットの種類を入力してください（犬、猫など）: \")\\n'\n",
      "                          '        age = input(\"ペットの年齢を入力してください: \")\\n'\n",
      "                          '        health_check = input(\"健康診断の結果を入力してください（合格または不合格）: \")\\n'\n",
      "                          '        \\n'\n",
      "                          '        next_check_date = None\\n'\n",
      "                          '        if health_check == \"不合格\":\\n'\n",
      "                          '            next_check_date = input(\"次回の診断日を入力してください (YYYY-MM-DD): \")\\n'\n",
      "                          '        \\n'\n",
      "                          '        database.add_pet(name, species, age, health_check, '\n",
      "                          'next_check_date)\\n'\n",
      "                          '        \\n'\n",
      "                          '        another = input(\"他のペットを追加しますか？ (はい/いいえ): \")\\n'\n",
      "                          '        if another.lower() != \"はい\":\\n'\n",
      "                          '            break\\n'\n",
      "                          '\\n'\n",
      "                          '    # 省略...\\n'\n",
      "                          '```\\n'\n",
      "                          '\\n'\n",
      "                          'これにより、ペットの健康管理がより詳細になり、不合格のペットに対して次回の診断日を管理できるようになります。',\n",
      "               'role': 'assistant'}],\n",
      " 'target': 'high school student',\n",
      " 'task': 'Python coding',\n",
      " 'topic': 'persona'}\n"
     ]
    }
   ],
   "source": [
    "run_synthesis_multi_turn_qa(\n",
    "    llm,\n",
    "    [\"Python coding\"],\n",
    "    [\"persona\"],\n",
    "    personas,\n",
    "    [\"high school student\"],\n",
    "    1,\n",
    "    1,\n",
    "    \"output.jsonl\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上のように、様々な分野の問題と解答のマルチターン対話データを生成することが確認できました。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## まとめ\n",
    "\n",
    "本ハンズオンでは、言語モデルを使って合成データを作成する方法を紹介しました。以下、本ハンズオンで紹介した内容をまとめます。\n",
    "\n",
    "- 合成データ生成の概要\n",
    "- [Persona-Hub](https://arxiv.org/abs/2406.20094) 手法の解説\n",
    "  - Web ページのテキストからペルソナを抽出\n",
    "    - Text-to-Persona\n",
    "    - Persona-to-Persona\n",
    "  - ペルソナを使って合成データを生成\n",
    "    - インストラクション\n",
    "    - 知識豊富なテキスト\n",
    "    - 数学問題\n",
    "- [FinePersonas](https://huggingface.co/datasets/argilla/FinePersonas-v0.1) データセットを使ったマルチターン事後学習データの合成\n",
    "  - Q1: ユーザが質問をする\n",
    "  - A1: アシスタントが解答する\n",
    "  - Q2: ユーザが追加質問をする\n",
    "  - A2: アシスタントが追加質問に解答する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考文献\n",
    "\n",
    "- Xin Chan et al., \"Scaling Synthetic Data Creation with 1,000,000,000 Personas”, arXiv preprint arXiv:2406.20094v1, 2024. https://arxiv.org/abs/2406.20094\n",
    "- Guilherme Penedo et al., \"The FineWeb Datasets: Decanting the Web for the Finest Text Data at Scale\", arXiv preprint arXiv:2406.17557v2, 2024. https://arxiv.org/abs/2406.17557\n",
    "- Hao Chen et al., \"On the Diversity of Synthetic Data and its Impact on Training Large Language Models\", arXiv preprint arXiv:2410.15226v2, 2024. https://arxiv.org/abs/2410.15226\n",
    "- Lozhkov et al., \"FineWeb-Edu: the Finest Collection of Educational Content\", アクセス日: 2025-01-28, https://huggingface.co/datasets/HuggingFaceFW/fineweb-edu\n",
    "- Argilla, “FinePersonas”, アクセス日: 2025-01-28, https://huggingface.co/datasets/argilla/FinePersonas-v0.1\n",
    "- Kan Hatakeyama, “大規模言語モデルTanuki-8x8Bの紹介と開発経緯など”, 9/10 松尾研LLM開発プロジェクト “Tanuki-8x8B” 開発成果報告会 Vol.1, https://www.docswell.com/s/matsuo-lab_llm/51R2L4-2024-9-10-Tanuki%E9%96%8B%E7%99%BA%E5%A0%B1%E5%91%8A%E4%BC%9A-vol1, アクセス日: 2025-01-28\n",
    "- Susumu Ota, \"Persona-Hub による合成データ生成\", 9/24 松尾研LLM開発プロジェクト “Tanuki-8x8B” 開発成果報告会 Vol. 3, https://www.docswell.com/s/matsuo-lab_llm/ZDNGR4-2024-9-24-Tanuki%E9%96%8B%E7%99%BA%E5%A0%B1%E5%91%8A%E4%BC%9A-vol3, アクセス日: 2025-01-28\n",
    "- [NEDO 採択プロジェクト] 多様な日本語能力の向上を目指した公開の基盤モデル開発, コードレポジトリ “synth_topic_multiturn.py”,アクセス日: 2025-01-28, https://github.com/matsuolab/nedo_project_code/blob/team_hatakeyama_phase2/team_hatakeyama_phase2/ota/topic-hub/synth_topic_multiturn.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
