{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Persona-Hub による事後学習データ合成\n",
    "\n",
    "Susumu Ota  2025-02-02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本ハンズオンでは、言語モデルを使って合成データを生成する方法を紹介します。\n",
    "\n",
    "まず、簡単に合成データ生成の概要を説明します。次に、[Persona-Hub](https://arxiv.org/abs/2406.20094) 手法の解説、[FinePersonas](https://huggingface.co/datasets/argilla/FinePersonas-v0.1) データセットの紹介、最後に実際にペルソナデータを使ってマルチターン事後学習データを合成する方法を説明します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 合成データ生成の概要"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 合成データの重要性\n",
    "\n",
    "本ハンズオンにおける合成データとは、\"**人間によって直接生成されたデータではなく、モデルやアルゴリズムによって生成されたデータ**\"を指します。\n",
    "\n",
    "合成データの重要性については、以下のような報告があります。\n",
    "\n",
    "- [畠山先生の 松尾研LLM開発プロジェクト “Tanuki-8x8B” 開発成果報告会 Vol.1 発表資料](https://www.docswell.com/s/matsuo-lab_llm/51R2L4-2024-9-10-Tanuki%E9%96%8B%E7%99%BA%E5%A0%B1%E5%91%8A%E4%BC%9A-vol1#p54)より\n",
    "  - Web データで継続事前学習しても JMT-Bench のスコアは横ばい\n",
    "  - 合成データの投入でスコアが向上\n",
    "  - 数学・論理推論・コードが難しい<br />\n",
    "<img src=\"https://github.com/user-attachments/assets/2eb9d26b-cddc-4c8f-b8a1-be9e6d1d3c05\" width=\"800px\">\n",
    "\n",
    "- [合成データの多様さと言語モデルの学習への影響を調べたプレプリント](https://arxiv.org/abs/2410.15226)より\n",
    "  - 合成データの多様さと、学習後のモデルの性能に正の相関がある (多様な合成データを使うほど性能が向上)\n",
    "  - モデルサイズが大きいほど、合成データの多様さが性能に与える影響が大きい<br />\n",
    "<img src=\"https://github.com/user-attachments/assets/ccdc7e34-fdfd-4810-9ef4-8c2f2145bb86\" width=\"800px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 合成データ作成の難しさ\n",
    "\n",
    "一般に、データ生成タスクにおいて、データの**質**と**多様さ**についてはトレードオフの関係があります。例えば、人手でデータを作成する場合は、予算一定では品質と多様さのどちらかを犠牲にせざるを得ません。\n",
    "\n",
    "一方、言語モデルを使った合成データ生成の場合も、データの**質**と**多様さ**については同様にトレードオフがありますが、以下のような特徴があります。\n",
    "\n",
    "<img src=\"https://github.com/user-attachments/assets/63e7a21e-ad8f-40a2-b22e-86eddef6e623\" width=\"400px\">\n",
    "\n",
    "- 品質は合成に使う言語モデルの性能が上がれば向上 (Scaling Laws に乗っかることが可能) (橙色の上矢印)\n",
    "- 多様さを向上させることが難しい (緑色の右矢印)\n",
    "\n",
    "したがって、合成データの多様さを向上させるためには、何らかのヒント・種を言語モデルに与えた上で合成データを出力する必要があります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 本ハンズオンの目的\n",
    "\n",
    "本ハンズオンの目的は、言語モデルを使った合成データの作成において、多様さを向上させるための方法を紹介することです。特に、[Persona-Hub](https://arxiv.org/abs/2406.20094) という手法を使って、事後学習用のマルチターン対話データを生成する方法を紹介します。\n",
    "\n",
    "多様な合成データを生成する方法として以下のような方法が提案されています([Persona-Hub のテクニカルレポート](https://arxiv.org/abs/2406.20094)より)。\n",
    "\n",
    "- インスタンス駆動\n",
    "  - 例: Wikipedia の記事から Q&A を生成\n",
    "- キーポイント駆動\n",
    "  - 例: 数学の学習指導要領に含まれる用語 (e.g. `三角関数`) から数学の問題を生成\n",
    "- ペルソナ駆動\n",
    "  - 例: ペルソナ (e.g. `運送会社のドライバー`) から数学の問題を生成\n",
    "\n",
    "本ハンズオンでは3つ目の**ペルソナ駆動による合成データ生成**を中心に説明します。\n",
    "\n",
    "なお、上記と直交する方法として、多様な合成データを生成するためにサンプリングを行うという方法があります。例えば、言語モデルで合成データを出力する際に、温度パラメータを高めに設定することで、多様な出力を得ることができます。しかし、温度を上げすぎるとハルシネーションや文が破綻する可能性が高まるため、品質と多様さのトレードオフが生じます。したがって、サンプリングのみで得られる多様さは限定的です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 準備\n",
    "\n",
    "ここからは、合成データ生成に必要な推論用言語モデルの準備を行います。言語モデルの推論を行うために、既存の推論 API を利用する方法と、Colab の GPU やローカルの GPU を使って推論を行う方法のどちらかを選択することができます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### トークンと API キーの設定\n",
    "\n",
    "本ハンズオンで必要となるトークンや API キーを設定します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hugging Face のトークンの取得\n",
    "\n",
    "Hugging Face からデータセットやモデルをダウンロードするためにトークンが必要となります。サインアップしてトークンを取得し `HF_TOKEN` という環境変数に設定してください。\n",
    "\n",
    "Hugging Face にサインアップしてトークンを取得する方法は、[こちら](https://zenn.dev/protoout/articles/73-hugging-face-setup)の記事を参照してください。生成する際の `role` は `read` で十分です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (オプション) 言語モデルサービスの API キーの取得\n",
    "\n",
    "Note: **Colab の GPU やローカルの GPU を使って推論する場合は、この設定は不要**です。\n",
    "\n",
    "推論 API の実行は [LiteLLM](https://docs.litellm.ai/) というモジュール経由で行います。LiteLLM の [Providers](https://docs.litellm.ai/docs/providers) ページを参照して、対応しているサービス一覧と環境変数名を確認してください。\n",
    "\n",
    "代表的な API キーの取得方法は以下です。\n",
    "- `OPENAI_API_KEY`\n",
    "  - OpenAI の API キーの取得方法は、[こちら](https://qiita.com/kurata04/items/a10bdc44cc0d1e62dad3)の記事を参照してください。\n",
    "  - 2025-02-02現在、無料枠はなく、利用開始時に $5 のクレジットが必要となります。\n",
    "- `NVIDIA_NIM_API_KEY`\n",
    "  - NVIDIA NIM の API キーの取得方法は、[こちら](https://zenn.dev/connectome/articles/eb9848241c5115)の記事のAPIキーを取得する部分までを参照してください。\n",
    "  - 2025-02-02現在、NVIDIA NIM の API は **1000 リクエストまでは無料**で利用できます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### トークンと API キーをシークレットマネージャーに保存\n",
    "\n",
    "この Notebook をローカル環境等の安全な環境で実行する場合は、OS の環境変数でトークンや API キーを保存してください。\n",
    "\n",
    "Colab 等のクラウド環境で実行する場合は、シークレットマネージャーに保存してください。**ソースコード中に API キーやトークンを直接書くとセキュリティ上のリスクが高まります**。\n",
    "\n",
    "Colab でのシークレットマネージャーによる設定方法は以下のようなコードを実行してください。詳細は[こちら](https://note.com/npaka/n/n79bb63e17685)の記事を参照してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "if str(get_ipython()).startswith(\"<google.colab\"):  # if this notebook is running in Google Colab  # type: ignore\n",
    "    import os\n",
    "    from google.colab import userdata  # type: ignore\n",
    "\n",
    "    os.environ[\"HF_TOKEN\"] = userdata.get(\"HF_TOKEN\")\n",
    "    # os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
    "    # os.environ[\"NVIDIA_NIM_API_KEY\"] = userdata.get(\"NVIDIA_NIM_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モジュールのインストール\n",
    "\n",
    "`litellm` と `datasets` をインストールしてください。ローカルのGPUを使って推論する場合は `vllm` もインストールしてください(API だけを使う場合は不要です)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install litellm\n",
    "# %pip install datasets\n",
    "\n",
    "# %pip install vllm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モジュールのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ota/Documents/python/synthetic-data-hands-on/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/ota/Documents/python/synthetic-data-hands-on/.venv/lib/python3.11/site-packages/pydantic/_internal/_config.py:345: UserWarning: Valid config keys have changed in V2:\n",
      "* 'fields' has been removed\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No vllm module found. You can only use the LiteLLM.\n"
     ]
    }
   ],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "import json\n",
    "from logging import DEBUG, INFO, StreamHandler, getLogger  # noqa: F401\n",
    "import pprint\n",
    "import random\n",
    "import re\n",
    "\n",
    "\n",
    "from datasets import load_dataset\n",
    "from litellm import batch_completion\n",
    "\n",
    "try:\n",
    "    from vllm import LLM, SamplingParams  # type: ignore\n",
    "except ImportError:\n",
    "    print(\"No vllm module found. You can only use the LiteLLM.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ログの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging_level = DEBUG\n",
    "# logging_level = INFO  # uncomment if you want to see less output\n",
    "logger = getLogger(__name__)\n",
    "logger.setLevel(logging_level)\n",
    "handler = StreamHandler()\n",
    "handler.setLevel(logging_level)\n",
    "logger.addHandler(handler)\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 言語モデルの設定\n",
    "\n",
    "API による推論とローカル GPU を使った推論の両方を統一してコードを書くために、`LanguageModel` という抽象クラスを作り、サブクラスで個別の処理を実装します。\n",
    "\n",
    "推論 API は `LiteLLM` 経由で利用します。\n",
    "\n",
    "Colab の GPU やローカルの GPU を使って推論には `vLLM` を使います。`LiteLLM` 経由で `vLLM` を使うことも出来ますが、`LiteLLM` では `dtype` の設定が出来ない(これが出来ないと Colab T4 で動作しない)ため `vLLM` を直接使うことにしました。\n",
    "\n",
    "`LanguageModel` のメソッドの役割は以下の通りです。\n",
    "\n",
    "- `__init__`: 言語モデルの初期化。推論用のパラメータ(`temperature`等)も設定。\n",
    "- `__call__`: 推論の実行。入力は OpenAI messages 形式 (e.g. `[{\"role\": \"user\", \"content\": \"Hello!\"}]`) のリスト。出力は文字列のリスト。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModel(ABC):\n",
    "    def __init__(self, model: str, temperature=1.0, max_tokens=16, seed=None):\n",
    "        self.model = model\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.seed = seed\n",
    "        logger.debug(f\"model: {model}, temperature: {temperature}, max_tokens: {max_tokens}, seed: {seed}\")\n",
    "\n",
    "    @abstractmethod\n",
    "    def __call__(self, messages_batch: list[list[dict[str, str]]]) -> list[str]:\n",
    "        pass\n",
    "\n",
    "\n",
    "class LiteLLMModel(LanguageModel):\n",
    "    def __init__(self, model: str, temperature=1.0, max_tokens=16, seed=None):\n",
    "        super().__init__(model, temperature, max_tokens, seed)\n",
    "\n",
    "    def __call__(self, messages_batch: list[list[dict[str, str]]]) -> list[str]:\n",
    "        contents = [\n",
    "            response.choices[0].message.content or \"\"\n",
    "            for response in batch_completion(\n",
    "                model=self.model,\n",
    "                messages=messages_batch,\n",
    "                temperature=self.temperature,\n",
    "                max_tokens=self.max_tokens,\n",
    "                seed=self.seed,\n",
    "            )\n",
    "        ]\n",
    "        assert len(contents) == len(messages_batch)\n",
    "        return contents\n",
    "\n",
    "\n",
    "class VLLMModel(LanguageModel):\n",
    "    def __init__(self, model: str, temperature=1.0, max_tokens=16, seed=None, dtype=\"auto\", stop=None):\n",
    "        super().__init__(model, temperature, max_tokens, seed)\n",
    "        self.dtype = dtype\n",
    "        self.stop = stop\n",
    "        self.vllm = LLM(model, dtype=dtype)  # dtype must be \"half\" to run on Colab T4\n",
    "        self.tokenizer = self.vllm.get_tokenizer()\n",
    "\n",
    "    def __call__(self, messages_batch: list[list[dict[str, str]]]) -> list[str]:\n",
    "        sampling_params = SamplingParams(\n",
    "            temperature=self.temperature, max_tokens=self.max_tokens, seed=self.seed, stop=self.stop\n",
    "        )\n",
    "        prompts = [\n",
    "            self.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "            for messages in messages_batch\n",
    "        ]\n",
    "        outputs = self.vllm.generate(prompts, sampling_params=sampling_params, use_tqdm=False)\n",
    "        contents = [o.outputs[0].text for o in outputs]\n",
    "        assert len(contents) == len(messages_batch)\n",
    "        return contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 言語モデルの初期化\n",
    "\n",
    "推論 API を使う場合は `準備` の節を参考に API キーを設定してください。環境変数名やモデル名は、[LiteLLM の Providers ページ](https://docs.litellm.ai/docs/providers)を参照してください。性能と価格のバランスを考慮すると、本ハンズオンで行う程度の内容であれば、`gpt-4o-mini` が適切かもしれません。\n",
    "\n",
    "Colab T4 GPU を使って推論する場合は `vLLM` を使います。手元でテストした限りでは、T4 では、\n",
    "\n",
    "- 3B 前後の量子化していないモデル\n",
    "- 10B 前後の量子化したモデル\n",
    "\n",
    "が動作可能でした。\n",
    "\n",
    "本ハンズオンの内容を `google/gemma-2-9b-it` の非公式量子化版の `marcsun13/gemma-2-9b-it-GPTQ` で動作確認をしましたが、合成データの質は `gpt-4o-mini` と比べて**大幅に劣ります**。可能であれば、A100 等の GPU を使い、 `cyberagent/calm3-22b-chat` やそれと同等以上の性能を持つモデルを使うことをお勧めします。サイズの小さいモデルや品質の低いモデルでは、合成データ生成がうまくいかない場合があります。個人的な印象ですが、現状では 10B 以下の日本語モデルでは、合成データ生成は難しいかもしれません。\n",
    "\n",
    "また、モデル・API のライセンスや利用規約等を確認して、**合成データを利用する際の制限事項等を各自で確認してください**。\n",
    "\n",
    "### 推論 API を使う場合の注意点\n",
    "\n",
    "一般に API の推論速度は遅いので、予備実験を API で行い、本実験は vLLM でローカル GPU で行うという使い方が現実的かもしれません。\n",
    "\n",
    "また、API で大量のデータを生成する場合は、バッチ処理のオプションが用意されていればそれを利用することと、利用制限(rate limit等)の範囲内でリクエストの並列化を検討してください。LiteLLM は内部でマルチスレッドで並列化されていますが、バッチサイズ大きめで使うと API サービス側の rate limit を超える可能性があります。\n",
    "\n",
    "### 言語モデルの作成\n",
    "\n",
    "以下のどれかのコメントを外して言語モデルを初期化します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model: gpt-4o-mini, temperature: 0.7, max_tokens: 512, seed: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.LiteLLMModel at 0x109d29310>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = LiteLLMModel(\"gpt-4o-mini\", temperature=0.7, max_tokens=512, seed=0)  # OPENAI_API_KEY\n",
    "# llm = LiteLLMModel(\"nvidia_nim/nvidia/nemotron-4-340b-instruct\", temperature=0.7, max_tokens=512, seed=None)  # NVIDIA_NIM_API_KEY\n",
    "# llm = LiteLLMModel(\"nvidia_nim/nvidia/llama-3.1-nemotron-70b-instruct\", temperature=0.7, max_tokens=512, seed=None)  # NVIDIA_NIM_API_KEY\n",
    "# llm = LiteLLMModel(\"deepinfra/nvidia/Llama-3.1-Nemotron-70B-Instruct\", temperature=0.7, max_tokens=512, seed=0)  # DEEPINFRA_API_KEY\n",
    "# llm = VLLMModel(\"hpprc/gemma-2-2b-jpn-it\", temperature=0.7, max_tokens=512, seed=0, stop=[\"<end_of_turn>\"], dtype=\"half\")  # for Colab T4\n",
    "# llm = VLLMModel(\"marcsun13/gemma-2-9b-it-GPTQ\", temperature=0.7, max_tokens=512, seed=0)  # for Colab T4\n",
    "# llm = VLLMModel(\"cyberagent/calm3-22b-chat\", temperature=0.7, max_tokens=512, seed=0)  # for A100?\n",
    "\n",
    "llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 言語モデルの動作確認\n",
    "\n",
    "ここまで設定できれば以下の推論が動作するはずです。もしエラーが出る場合は、言語モデルの設定を見直してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello! How can I assist you today?']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm([[{\"role\": \"user\", \"content\": \"Hello?\"}]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここまでで言語モデルによる推論環境を構築することできました。\n",
    "\n",
    "次に、ペルソナ駆動による合成データ生成の方法について説明します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persona-Hub による合成データ生成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ペルソナとは\n",
    "\n",
    "[FinePersonasのREADME](https://huggingface.co/datasets/argilla/FinePersonas-v0.1) では、ペルソナについて以下のように説明されています。\n",
    "\n",
    "> - 個人の特徴、背景、目標を詳細に記述したもので、多様なアイデンティティと経験を反映するようにデザインされている\n",
    "> - ペルソナの例\n",
    ">   - A network engineer with a focus on routing protocols and preparing for Cisco certification exams, particularly CCNA.\n",
    ">   - ルーティング・プロトコルに興味があり、シスコの認定試験(特に CCNA)の準備をしているネットワーク・エンジニア\n",
    "> - 生成するコンテンツに、特定の専門知識・キャリアパス・個人的な興味を導入し、より繊細でターゲットを絞ったコンテンツが生成可能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persona-Hub とは\n",
    "\n",
    "[Persona-Hub](https://arxiv.org/abs/2406.20094) は、Tencent AI Lab が提案したペルソナ駆動型データ合成手法で、大規模言語モデル内の様々な視点を活用して多様な合成データを作成することができます。\n",
    "\n",
    "<img src=\"https://github.com/user-attachments/assets/37ce038a-7702-4398-838d-8c504ac1da07\" width=\"800px\">\n",
    "\n",
    "Persona-Hub 手法の概要は以下の通りです。\n",
    "\n",
    "- 背景: 既存の合成データ⽣成⼿法(インスタンス駆動・キーポイント駆動)では合成データの多様さをスケールアップすることが困難\n",
    "- 目的: ⼤規模なペルソナデータセットを作成し、それを使ってスケーラブルな合成データを⽣成する(ペルソナ駆動)\n",
    "- 方法\n",
    "  - Web ページのテキストからペルソナを抽出 (上図の`Compress`部分)\n",
    "    - Text-to-Persona\n",
    "    - Persona-to-Persona\n",
    "  - ペルソナを使って合成データを生成 (上図の`Decompress`部分、下図)\n",
    "    - Create **a math problem** with **a moving company driver**\n",
    "    - Create **a math problem** with **a chemical kinetics researcher**\n",
    "    - Create **a math problem** with **a musician interested in audio processing**\n",
    "- 結果: 10億件のペルソナデータセットを作成 (ただし今のところ非公開)\n",
    "\n",
    "<img src=\"https://github.com/user-attachments/assets/344b011d-b9f8-4ac3-a79a-198e3862b3cf\" width=\"800px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web ページのテキストからペルソナを抽出\n",
    "\n",
    "まず、Persona-Hub 手法を理解するために、Web ページのテキストからペルソナを抽出する方法を説明します(上図の`Compress`部分)。その後、抽出したペルソナを使って合成データを生成する方法を説明します(上図の`Decompress`部分)。\n",
    "\n",
    "ここでは、実際に [FineWeb-Edu](https://huggingface.co/datasets/HuggingFaceFW/fineweb-edu) という教育関連の品質の高い Web ページを集めたデータセットからペルソナを抽出します。\n",
    "\n",
    "まずデータセットを読み込みます。データセット全体を読み込むと時間がかかるので、ここでは `streaming=True` を指定して一部分だけ読み込みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IterableDataset({\n",
       "    features: ['text', 'id', 'dump', 'url', 'date', 'file_path', 'language', 'language_score', 'token_count', 'score', 'int_score'],\n",
       "    num_shards: 50\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fineweb_edu = load_dataset(\n",
    "    \"HuggingFaceFW/fineweb-edu\", name=\"CC-MAIN-2024-51\", split=\"train\", cache_dir=\"cache\", streaming=True\n",
    ")\n",
    "\n",
    "fineweb_edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回は実験のため、データセットの先頭の10件を取り出して `web_pages` というリストに格納します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This project is solving the Asteroid Watchers challenge. Description\\nAROs are essentially created by',\n",
       " 'Life of a Sand Grain\\nTHE LIFE OF A SAND GRAIN by Carl Bowser (Sept. 2018)\\nThey surround you almost a',\n",
       " 'The internet of things, a system of interrelated computing devices and machines that can transfer da',\n",
       " 'An archive photo of an Egyptian mummy - Reuters\\nBy Tom Perry\\nCAIRO, Jan 15 (Reuters) - Archaeologist',\n",
       " 'The faith of the Christ-God is a living paradox in the Asiatic world. Christianity has long survived',\n",
       " 'Power wound resistance is a two terminal electronic component made of\\nresistance material, which has',\n",
       " 'Pravda No. 50, March 1, 1913 |\\nPublished according to |\\nFrom V. I. Lenin, Collected Works, 4th Engli',\n",
       " '1. 03. Friend B: I look washed out. Publications Publications such as books, magazines, newspapers, ',\n",
       " 'Aerospace & Electronic Techniques Society\\nUntil 1950, this field was called “radio expertise” as a e',\n",
       " 'The Dawn of the Artificial Kidney\\nArtificial kidneys may sound like something from a science fiction']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "web_pages = [d[\"text\"] for d in fineweb_edu.take(10)]\n",
    "[p[:100] for p in web_pages]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記のように教育分野の比較的品質の高い Web ページを集めたデータセットです。特に科学技術分野のペルソナを抽出できそうです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text-to-Persona\n",
    "\n",
    "Persona-Hub では、ペルソナを抽出する手法として `Text-to-Persona` と `Persona-to-Persona` が提案されています。ここでは Text-to-Persona 手法によって、Web ページのテキストからペルソナを抽出します。\n",
    "\n",
    "効果的にペルソナを抽出するポイントは `このテキストを書きそうな人物` や `このテキストに興味がありそうな人物` を言語モデルに予測させることです。\n",
    "\n",
    "以下のようなプロンプトを実行します。\n",
    "\n",
    "Note: `system` ロールがサポートされていない言語モデルを使う場合は `user` ロールにシステムプロンプトの内容を含めてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_persona(llm: LanguageModel, text: str) -> str:\n",
    "    SYSTEM_PROMPT = \"\"\"\\\n",
    "You are an expert in analyzing the text content and assigning finding the general type of persona that could be associated with such a way of expressing. Please use one or two sentences for the definition, but try to make it as fine-grained if input texts involve many detailed elements. The persona definition must go straight to the point, be assertive. The following are starts of persona definitions:\n",
    "A machine learning researcher...\n",
    "A pedriatric nurse whose...\n",
    "An urban planner focused on...\n",
    "\"\"\"\n",
    "\n",
    "    USER_PROMPT = \"\"\"\\\n",
    "What is the likely profession, interest, or role of the person who would write or be interested in this text?\n",
    "\n",
    "## Text\n",
    "{text}\n",
    "\n",
    "Note:\n",
    "1. Your response should always start with \"ペルソナ:\".\n",
    "2. 日本語で回答してください。\n",
    "\"\"\"\n",
    "    persona = llm([[\n",
    "        # {\"role\": \"system\", \"content\": SYSTEM_PROMPT},  # if llm supports system prompt\n",
    "        # {\"role\": \"user\", \"content\": USER_PROMPT.format(text=text)},\n",
    "        {\"role\": \"user\", \"content\": SYSTEM_PROMPT + \"\\n\\n## Task\\n\" + USER_PROMPT.format(text=text)},  # if llm does not support system prompt\n",
    "    ]])[0]\n",
    "    logger.debug(f\"persona: {persona}\")\n",
    "\n",
    "    return re.sub(r\"^ペルソナ[:：]\", \"\", persona).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この関数を使って FineWeb-Edu データからペルソナを抽出します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "persona: ペルソナ: オープンソースハードウェアとソフトウェアに関心を持つ天文愛好家であり、Arduinoやスマートフォンを用いた技術的なプロジェクトを推進するエンジニア。\n",
      "persona: ペルソナ: 地質学者であり、特に砂や鉱物の成り立ちや成熟度に関心を持つ研究者。彼らは自然環境の変遷や地球の歴史を理解するために、砂のサンプルを収集し分析することを楽しむ。\n",
      "persona: ペルソナ: IoTおよびAI技術の専門家であり、データ分析やシステム設計に関心を持つエンジニアまたは研究者。\n",
      "persona: ペルソナ: 古代エジプトの考古学者で、歴史的な発見や文化遺産の保護に情熱を持ち、専門的な知識を駆使して研究を行っている。\n",
      "persona: ペルソナ: このテキストは、宗教的歴史や文化的相互作用に関心を持つ宗教学者または文化人類学者が書いたものであり、特にキリスト教とアジアの宗教との関係に焦点を当てた分析を行う専門家の視点を反映している。\n",
      "persona: ペルソナ: 電子工学の研究者で、回路設計や抵抗器の特性に関心を持つ技術者。\n",
      "persona: ペルソナ: マルクス主義の理論を深く研究し、社会主義社会の建設における労働者階級の役割に関心を持つ政治理論家や歴史家。\n",
      "persona: ペルソナ: 印刷メディアや広告戦略に関心を持つマーケティング専門家であり、特に伝統的なメディアの進化やその効果的な活用方法に注力しているプロフェッショナル。\n",
      "persona: ペルソナ: 航空宇宙および電子工学の専門家であり、電子機器の設計や技術的原理に精通したエンジニアで、最新の技術トレンドや産業動向に関心を持つ人物。\n",
      "persona: ペルソナ: 人工腎臓技術の研究者であり、医療技術の進歩に情熱を持つ科学者。患者の生活の質向上を目指し、革新的な治療法の開発に取り組んでいる。\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['オープンソースハードウェアとソフトウェアに関心を持つ天文愛好家であり、Arduinoやスマートフォンを用いた技術的なプロジェクトを推進するエンジニア。',\n",
       " '地質学者であり、特に砂や鉱物の成り立ちや成熟度に関心を持つ研究者。彼らは自然環境の変遷や地球の歴史を理解するために、砂のサンプルを収集し分析することを楽しむ。',\n",
       " 'IoTおよびAI技術の専門家であり、データ分析やシステム設計に関心を持つエンジニアまたは研究者。',\n",
       " '古代エジプトの考古学者で、歴史的な発見や文化遺産の保護に情熱を持ち、専門的な知識を駆使して研究を行っている。',\n",
       " 'このテキストは、宗教的歴史や文化的相互作用に関心を持つ宗教学者または文化人類学者が書いたものであり、特にキリスト教とアジアの宗教との関係に焦点を当てた分析を行う専門家の視点を反映している。',\n",
       " '電子工学の研究者で、回路設計や抵抗器の特性に関心を持つ技術者。',\n",
       " 'マルクス主義の理論を深く研究し、社会主義社会の建設における労働者階級の役割に関心を持つ政治理論家や歴史家。',\n",
       " '印刷メディアや広告戦略に関心を持つマーケティング専門家であり、特に伝統的なメディアの進化やその効果的な活用方法に注力しているプロフェッショナル。',\n",
       " '航空宇宙および電子工学の専門家であり、電子機器の設計や技術的原理に精通したエンジニアで、最新の技術トレンドや産業動向に関心を持つ人物。',\n",
       " '人工腎臓技術の研究者であり、医療技術の進歩に情熱を持つ科学者。患者の生活の質向上を目指し、革新的な治療法の開発に取り組んでいる。']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "personas = [text_to_persona(llm, web_page) for web_page in web_pages]\n",
    "personas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "元の Web ページのテキストと抽出したペルソナを比較してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'persona': 'オープンソースハードウェアとソフトウェアに関心を持つ天文愛好家であり、Arduinoやスマートフォンを用いた技術的なプロジェクトを推進するエンジニア。',\n",
      " 'web_page_ja': 'This project is solving the Asteroid Watchers challenge. Description\\n'\n",
      "                'AROs are essentially created by combining a telescope with a smartphone. If the '\n",
      "                'telescope has drive motors can be controlled via a '}\n",
      "{'persona': '地質学者であり、特に砂や鉱物の成り立ちや成熟度に関心を持つ研究者。彼らは自然環境の変遷や地球の歴史を理解するために、砂のサンプルを収集し分析することを楽しむ。',\n",
      " 'web_page_ja': 'Life of a Sand Grain\\n'\n",
      "                'THE LIFE OF A SAND GRAIN by Carl Bowser (Sept. 2018)\\n'\n",
      "                'They surround you almost anywhere you are in Arizona. They cling to your shoes, '\n",
      "                'they end up in pockets and pant cuffs, they pr'}\n",
      "{'persona': 'IoTおよびAI技術の専門家であり、データ分析やシステム設計に関心を持つエンジニアまたは研究者。',\n",
      " 'web_page_ja': 'The internet of things, a system of interrelated computing devices and machines '\n",
      "                'that can transfer data over a network without human interaction, has been used to '\n",
      "                'enable new features, better functional'}\n",
      "{'persona': '古代エジプトの考古学者で、歴史的な発見や文化遺産の保護に情熱を持ち、専門的な知識を駆使して研究を行っている。',\n",
      " 'web_page_ja': 'An archive photo of an Egyptian mummy - Reuters\\n'\n",
      "                'By Tom Perry\\n'\n",
      "                'CAIRO, Jan 15 (Reuters) - Archaeologists in Egypt believe they have discovered '\n",
      "                'the remains of a previously unknown pharaoh who reigned more'}\n",
      "{'persona': 'このテキストは、宗教的歴史や文化的相互作用に関心を持つ宗教学者または文化人類学者が書いたものであり、特にキリスト教とアジアの宗教との関係に焦点を当てた分析を行う専門家の視点を反映している。',\n",
      " 'web_page_ja': 'The faith of the Christ-God is a living paradox in the Asiatic world. '\n",
      "                'Christianity has long survived in Asia’s periphery, especially in the Near East '\n",
      "                'and to a lesser extent in India, but it has never '}\n",
      "{'persona': '電子工学の研究者で、回路設計や抵抗器の特性に関心を持つ技術者。',\n",
      " 'web_page_ja': 'Power wound resistance is a two terminal electronic component made of\\n'\n",
      "                'resistance material, which has a certain structure and can limit the\\n'\n",
      "                'current passing through the circuit. A fixed resistor is one '}\n",
      "{'persona': 'マルクス主義の理論を深く研究し、社会主義社会の建設における労働者階級の役割に関心を持つ政治理論家や歴史家。',\n",
      " 'web_page_ja': 'Pravda No. 50, March 1, 1913 |\\n'\n",
      "                'Published according to |\\n'\n",
      "                'From V. I. Lenin, Collected Works, 4th English Edition,\\n'\n",
      "                'Progress Publishers, Moscow, 1968\\n'\n",
      "                'First printing 1963\\n'\n",
      "                'Second printing 1968\\n'\n",
      "                'Translated fr'}\n",
      "{'persona': '印刷メディアや広告戦略に関心を持つマーケティング専門家であり、特に伝統的なメディアの進化やその効果的な活用方法に注力しているプロフェッショナル。',\n",
      " 'web_page_ja': '1. 03. Friend B: I look washed out. Publications Publications such as books, '\n",
      "                'magazines, newspapers, blogs and research papers. Required material - includes '\n",
      "                'print material selected by staff, that must '}\n",
      "{'persona': '航空宇宙および電子工学の専門家であり、電子機器の設計や技術的原理に精通したエンジニアで、最新の技術トレンドや産業動向に関心を持つ人物。',\n",
      " 'web_page_ja': 'Aerospace & Electronic Techniques Society\\n'\n",
      "                'Until 1950, this field was called “radio expertise” as a end result of its '\n",
      "                'principal application was the design and principle of radio transmitters, '\n",
      "                'receivers'}\n",
      "{'persona': '人工腎臓技術の研究者であり、医療技術の進歩に情熱を持つ科学者。患者の生活の質向上を目指し、革新的な治療法の開発に取り組んでいる。',\n",
      " 'web_page_ja': 'The Dawn of the Artificial Kidney\\n'\n",
      "                'Artificial kidneys may sound like something from a science fiction movie, but '\n",
      "                'these ground-breaking new treatments are currently being designed and tested '\n",
      "                'across the '}\n"
     ]
    }
   ],
   "source": [
    "for web_page, persona in zip(web_pages, personas):\n",
    "    pp.pprint({\"web_page_ja\": web_page[:200], \"persona\": persona})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text-to-Persona 手法によって、FineWeb-Edu データセットのテキストからペルソナを抽出することが出来ました。\n",
    "\n",
    "なお、Web ページからペルソナを抽出することは、一種の合成データ生成と考えることが出来ます。この場合は、Webページというインスタンスからペルソナという合成データを生成していますので、Text-to-Persona 手法は、**インスタンス駆動の合成データ生成**と捉えることが可能です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Persona-to-Persona\n",
    "\n",
    "Text-to-Persona だけでは抽出することが難しいペルソナがあります(例えば子供など)。そのようなペルソナをカバーするために、抽出したペルソナからさらに関連するペルソナを生成します。この手法を Persona-to-Persona と呼びます。以下のようなプロンプトを実行します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def persona_to_personas(llm: LanguageModel, persona: str) -> list[str]:\n",
    "    SYSTEM_PROMPT = \"\"\"\\\n",
    "You are an AI assistant expert in finding relationships between people. Answer directly with the the new related persona definition, don't enumerate them.\n",
    "\"\"\"\n",
    "\n",
    "    USER_PROMPT = \"\"\"\\\n",
    "Who is in close relationship with the given persona? Write just 3, each one in a different line:\n",
    "{persona}\n",
    "\n",
    "Note:\n",
    "1. Your response should always start with \"ペルソナ:\".\n",
    "2. Granularity of persona description should be similar to the input persona.\n",
    "3. The output persona should be fully described without context of the input persona.\n",
    "4. 日本語で回答してください。\n",
    "\"\"\"\n",
    "\n",
    "    persona = llm([[\n",
    "        # {\"role\": \"system\", \"content\": SYSTEM_PROMPT},  # if llm supports system prompt\n",
    "        # {\"role\": \"user\", \"content\": USER_PROMPT.format(persona=persona)},\n",
    "        {\"role\": \"user\", \"content\": SYSTEM_PROMPT + \"\\n\\n\" + USER_PROMPT.format(persona=persona)},  # if llm does not support system prompt\n",
    "    ]])[0]\n",
    "    logger.debug(f\"persona: {persona}\")\n",
    "\n",
    "    return [re.sub(r\"^ペルソナ[:：]\", \"\", p.strip()).strip() for p in persona.split(\"\\n\") if p.strip()][-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "persona: ペルソナ: オープンソースハードウェアとソフトウェアを利用して天文観測を行う熱心な天文学者であり、データ解析のスキルを駆使して星の動きを追跡する研究者。ArduinoやRaspberry Piを用いて自作の観測機器を開発し、オンラインコミュニティでプロジェクトを共有することに情熱を注いでいる。\n",
      "\n",
      "ペルソナ: 天文学とエンジニアリングの交差点に興味を持ち、大学で物理学を専攻しつつ、開発したアプリケーションで天体の位置情報を提供するアプリ開発者。プログラミング言語やデータベース管理に精通し、オープンソースプロジェクトに積極的に参加している。\n",
      "\n",
      "ペルソナ: DIY技術や電子工作に情熱を持つエンジニアであり、天文に関するワークショップを開催し、参加者にArduinoを使った星座観察キットの制作を指導する教育者。コミュニティの中で技術を共有し、若い世代の科学への興味を引き出すことを目指している。\n",
      "persona: ペルソナ: 地質学者であり、特に火山活動や地形変化に関心を持つ研究者。彼らは火山の噴火履歴やその影響を調査するために、現地調査やサンプル収集を行い、地球の動的な変化を理解することに情熱を注ぐ。\n",
      "\n",
      "地質学者であり、古生物学にも興味を持ち、化石の研究を通じて地球の生物の進化を探求する研究者。彼らは地層の解析を行い、過去の生態系や気候変動の影響を解明することを目指す。\n",
      "\n",
      "環境科学者であり、特に土壌の性質やその保全に焦点を当てている研究者。彼らは土壌の質とその健康が生態系に与える影響を研究し、持続可能な農業や土地利用の方法を提案する。\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['オープンソースハードウェアとソフトウェアを利用して天文観測を行う熱心な天文学者であり、データ解析のスキルを駆使して星の動きを追跡する研究者。ArduinoやRaspberry Piを用いて自作の観測機器を開発し、オンラインコミュニティでプロジェクトを共有することに情熱を注いでいる。',\n",
       "  '天文学とエンジニアリングの交差点に興味を持ち、大学で物理学を専攻しつつ、開発したアプリケーションで天体の位置情報を提供するアプリ開発者。プログラミング言語やデータベース管理に精通し、オープンソースプロジェクトに積極的に参加している。',\n",
       "  'DIY技術や電子工作に情熱を持つエンジニアであり、天文に関するワークショップを開催し、参加者にArduinoを使った星座観察キットの制作を指導する教育者。コミュニティの中で技術を共有し、若い世代の科学への興味を引き出すことを目指している。'],\n",
       " ['地質学者であり、特に火山活動や地形変化に関心を持つ研究者。彼らは火山の噴火履歴やその影響を調査するために、現地調査やサンプル収集を行い、地球の動的な変化を理解することに情熱を注ぐ。',\n",
       "  '地質学者であり、古生物学にも興味を持ち、化石の研究を通じて地球の生物の進化を探求する研究者。彼らは地層の解析を行い、過去の生態系や気候変動の影響を解明することを目指す。',\n",
       "  '環境科学者であり、特に土壌の性質やその保全に焦点を当てている研究者。彼らは土壌の質とその健康が生態系に与える影響を研究し、持続可能な農業や土地利用の方法を提案する。']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_personas_list = [persona_to_personas(llm, persona) for persona in personas[:2]]\n",
    "new_personas_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'new_personas': ['オープンソースハードウェアとソフトウェアを利用して天文観測を行う熱心な天文学者であり、データ解析のスキルを駆使して星の動きを追跡する研究者。ArduinoやRaspberry '\n",
      "                  'Piを用いて自作の観測機器を開発し、オンラインコミュニティでプロジェクトを共有することに情熱を注いでいる。',\n",
      "                  '天文学とエンジニアリングの交差点に興味を持ち、大学で物理学を専攻しつつ、開発したアプリケーションで天体の位置情報を提供するアプリ開発者。プログラミング言語やデータベース管理に精通し、オープンソースプロジェクトに積極的に参加している。',\n",
      "                  'DIY技術や電子工作に情熱を持つエンジニアであり、天文に関するワークショップを開催し、参加者にArduinoを使った星座観察キットの制作を指導する教育者。コミュニティの中で技術を共有し、若い世代の科学への興味を引き出すことを目指している。'],\n",
      " 'org_persona': 'オープンソースハードウェアとソフトウェアに関心を持つ天文愛好家であり、Arduinoやスマートフォンを用いた技術的なプロジェクトを推進するエンジニア。'}\n",
      "{'new_personas': ['地質学者であり、特に火山活動や地形変化に関心を持つ研究者。彼らは火山の噴火履歴やその影響を調査するために、現地調査やサンプル収集を行い、地球の動的な変化を理解することに情熱を注ぐ。',\n",
      "                  '地質学者であり、古生物学にも興味を持ち、化石の研究を通じて地球の生物の進化を探求する研究者。彼らは地層の解析を行い、過去の生態系や気候変動の影響を解明することを目指す。',\n",
      "                  '環境科学者であり、特に土壌の性質やその保全に焦点を当てている研究者。彼らは土壌の質とその健康が生態系に与える影響を研究し、持続可能な農業や土地利用の方法を提案する。'],\n",
      " 'org_persona': '地質学者であり、特に砂や鉱物の成り立ちや成熟度に関心を持つ研究者。彼らは自然環境の変遷や地球の歴史を理解するために、砂のサンプルを収集し分析することを楽しむ。'}\n"
     ]
    }
   ],
   "source": [
    "for org_persona, new_personas in zip(personas, new_personas_list):\n",
    "    pp.pprint({\"org_persona\": org_persona, \"new_personas\": new_personas})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "もうすこしプロンプトを工夫する必要があるかもしれませんが、与えられたペルソナと密接に関連するペルソナを生成することが出来ます。\n",
    "\n",
    "以上で、Web ページのテキストからペルソナを抽出する方法として以下の2つの手法を紹介しました。\n",
    "\n",
    "- Text-to-Persona\n",
    "- Persona-to-Persona"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ペルソナを使って合成データを生成\n",
    "\n",
    "ここからは、先ほど抽出したペルソナを使って合成データを生成します。今回は例として以下のような合成データを生成します。\n",
    "- インストラクション\n",
    "- 知識豊富なテキスト\n",
    "- 数学問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### インストラクションの合成\n",
    "\n",
    "まず、合成データ例として、ペルソナからインストラクション(ユーザが言語モデルに入力するプロンプト)データを合成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_instruction(llm: LanguageModel, persona: str) -> dict[str, str]:\n",
    "    SYSTEM_PROMPT = \"You are an AI assistant expert at simulating user interactions.\"\n",
    "\n",
    "    USER_PROMPT = \"\"\"\\\n",
    "Generate a prompt the persona below might ask to an AI assistant:\n",
    "\n",
    "{persona}\n",
    "\n",
    "Note:\n",
    "1. Your response should always start with \"プロンプト:\".\n",
    "2. 簡潔に日本語で回答してください。\n",
    "\"\"\"\n",
    "\n",
    "    instruction = llm([[\n",
    "        # {\"role\": \"system\", \"content\": SYSTEM_PROMPT},  # if llm supports system prompt\n",
    "        # {\"role\": \"user\", \"content\": USER_PROMPT.format(persona=persona)},\n",
    "        {\"role\": \"user\", \"content\": SYSTEM_PROMPT + \"\\n\\n\" + USER_PROMPT.format(persona=persona)},  # if llm does not support system prompt\n",
    "    ]])[0]\n",
    "    logger.debug(f\"instruction: {instruction}\")\n",
    "\n",
    "    return re.sub(r\"^プロンプト[:：]\", \"\", instruction).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "instruction: プロンプト: Arduinoを使って星空観測用のセンサーを作りたいのですが、どんな部品を揃えれば良いですか？また、簡単なプロジェクト例があれば教えてください。\n",
      "instruction: プロンプト: 砂の成熟度を評価するための最新の分析手法について教えてください。また、特定の鉱物が砂の成り立ちに与える影響についても知りたいです。\n",
      "instruction: プロンプト: IoTデバイスから収集したデータを効果的に分析するための最適なアルゴリズムやツールについて教えてください。\n",
      "instruction: プロンプト: 古代エジプトの宗教儀式に関する最新の研究成果を教えてください。また、どのようにしてこれらの知識を文化遺産の保護に活かせるか提案してください。\n",
      "instruction: プロンプト: キリスト教とアジアの宗教との文化的相互作用について、具体的な事例を挙げて分析してください。\n",
      "instruction: プロンプト: 回路設計における抵抗器の温度特性について教えてください。また、温度変化が回路に与える影響についても知りたいです。\n",
      "instruction: プロンプト: 労働者階級が社会主義社会の建設において果たすべき具体的な役割について、どのような理論や歴史的事例がありますか？\n",
      "instruction: プロンプト: 伝統的な印刷メディアがデジタル時代にどのように進化しているか、具体的な事例を挙げて教えてください。また、その効果的な活用方法についてもアドバイスをお願いします。\n",
      "instruction: プロンプト: 最近の航空宇宙産業における電子機器の進化について、特にAIとセンサー技術の役割について教えてください。\n",
      "instruction: プロンプト: 人工腎臓技術の最新の研究成果について教えてください。特に、患者の生活の質にどのように寄与しているか知りたいです。\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Arduinoを使って星空観測用のセンサーを作りたいのですが、どんな部品を揃えれば良いですか？また、簡単なプロジェクト例があれば教えてください。',\n",
       " '砂の成熟度を評価するための最新の分析手法について教えてください。また、特定の鉱物が砂の成り立ちに与える影響についても知りたいです。',\n",
       " 'IoTデバイスから収集したデータを効果的に分析するための最適なアルゴリズムやツールについて教えてください。',\n",
       " '古代エジプトの宗教儀式に関する最新の研究成果を教えてください。また、どのようにしてこれらの知識を文化遺産の保護に活かせるか提案してください。',\n",
       " 'キリスト教とアジアの宗教との文化的相互作用について、具体的な事例を挙げて分析してください。',\n",
       " '回路設計における抵抗器の温度特性について教えてください。また、温度変化が回路に与える影響についても知りたいです。',\n",
       " '労働者階級が社会主義社会の建設において果たすべき具体的な役割について、どのような理論や歴史的事例がありますか？',\n",
       " '伝統的な印刷メディアがデジタル時代にどのように進化しているか、具体的な事例を挙げて教えてください。また、その効果的な活用方法についてもアドバイスをお願いします。',\n",
       " '最近の航空宇宙産業における電子機器の進化について、特にAIとセンサー技術の役割について教えてください。',\n",
       " '人工腎臓技術の最新の研究成果について教えてください。特に、患者の生活の質にどのように寄与しているか知りたいです。']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instructions = [generate_instruction(llm, p) for p in personas]\n",
    "instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "抽出元の Web ページ、ペルソナ、インストラクションをまとめて確認してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': 'Arduinoを使って星空観測用のセンサーを作りたいのですが、どんな部品を揃えれば良いですか？また、簡単なプロジェクト例があれば教えてください。',\n",
      " 'persona': 'オープンソースハードウェアとソフトウェアに関心を持つ天文愛好家であり、Arduinoやスマートフォンを用いた技術的なプロジェクトを推進するエンジニア。',\n",
      " 'web_page': 'This project is solving the Asteroid Watchers challenge. Description\\n'\n",
      "             'AROs are essentially created by'}\n",
      "{'instruction': '砂の成熟度を評価するための最新の分析手法について教えてください。また、特定の鉱物が砂の成り立ちに与える影響についても知りたいです。',\n",
      " 'persona': '地質学者であり、特に砂や鉱物の成り立ちや成熟度に関心を持つ研究者。彼らは自然環境の変遷や地球の歴史を理解するために、砂のサンプルを収集し分析することを楽しむ。',\n",
      " 'web_page': 'Life of a Sand Grain\\n'\n",
      "             'THE LIFE OF A SAND GRAIN by Carl Bowser (Sept. 2018)\\n'\n",
      "             'They surround you almost a'}\n",
      "{'instruction': 'IoTデバイスから収集したデータを効果的に分析するための最適なアルゴリズムやツールについて教えてください。',\n",
      " 'persona': 'IoTおよびAI技術の専門家であり、データ分析やシステム設計に関心を持つエンジニアまたは研究者。',\n",
      " 'web_page': 'The internet of things, a system of interrelated computing devices and machines that '\n",
      "             'can transfer da'}\n",
      "{'instruction': '古代エジプトの宗教儀式に関する最新の研究成果を教えてください。また、どのようにしてこれらの知識を文化遺産の保護に活かせるか提案してください。',\n",
      " 'persona': '古代エジプトの考古学者で、歴史的な発見や文化遺産の保護に情熱を持ち、専門的な知識を駆使して研究を行っている。',\n",
      " 'web_page': 'An archive photo of an Egyptian mummy - Reuters\\n'\n",
      "             'By Tom Perry\\n'\n",
      "             'CAIRO, Jan 15 (Reuters) - Archaeologist'}\n",
      "{'instruction': 'キリスト教とアジアの宗教との文化的相互作用について、具体的な事例を挙げて分析してください。',\n",
      " 'persona': 'このテキストは、宗教的歴史や文化的相互作用に関心を持つ宗教学者または文化人類学者が書いたものであり、特にキリスト教とアジアの宗教との関係に焦点を当てた分析を行う専門家の視点を反映している。',\n",
      " 'web_page': 'The faith of the Christ-God is a living paradox in the Asiatic world. Christianity '\n",
      "             'has long survived'}\n",
      "{'instruction': '回路設計における抵抗器の温度特性について教えてください。また、温度変化が回路に与える影響についても知りたいです。',\n",
      " 'persona': '電子工学の研究者で、回路設計や抵抗器の特性に関心を持つ技術者。',\n",
      " 'web_page': 'Power wound resistance is a two terminal electronic component made of\\n'\n",
      "             'resistance material, which has'}\n",
      "{'instruction': '労働者階級が社会主義社会の建設において果たすべき具体的な役割について、どのような理論や歴史的事例がありますか？',\n",
      " 'persona': 'マルクス主義の理論を深く研究し、社会主義社会の建設における労働者階級の役割に関心を持つ政治理論家や歴史家。',\n",
      " 'web_page': 'Pravda No. 50, March 1, 1913 |\\n'\n",
      "             'Published according to |\\n'\n",
      "             'From V. I. Lenin, Collected Works, 4th Engli'}\n",
      "{'instruction': '伝統的な印刷メディアがデジタル時代にどのように進化しているか、具体的な事例を挙げて教えてください。また、その効果的な活用方法についてもアドバイスをお願いします。',\n",
      " 'persona': '印刷メディアや広告戦略に関心を持つマーケティング専門家であり、特に伝統的なメディアの進化やその効果的な活用方法に注力しているプロフェッショナル。',\n",
      " 'web_page': '1. 03. Friend B: I look washed out. Publications Publications such as books, '\n",
      "             'magazines, newspapers, '}\n",
      "{'instruction': '最近の航空宇宙産業における電子機器の進化について、特にAIとセンサー技術の役割について教えてください。',\n",
      " 'persona': '航空宇宙および電子工学の専門家であり、電子機器の設計や技術的原理に精通したエンジニアで、最新の技術トレンドや産業動向に関心を持つ人物。',\n",
      " 'web_page': 'Aerospace & Electronic Techniques Society\\n'\n",
      "             'Until 1950, this field was called “radio expertise” as a e'}\n",
      "{'instruction': '人工腎臓技術の最新の研究成果について教えてください。特に、患者の生活の質にどのように寄与しているか知りたいです。',\n",
      " 'persona': '人工腎臓技術の研究者であり、医療技術の進歩に情熱を持つ科学者。患者の生活の質向上を目指し、革新的な治療法の開発に取り組んでいる。',\n",
      " 'web_page': 'The Dawn of the Artificial Kidney\\n'\n",
      "             'Artificial kidneys may sound like something from a science fiction'}\n"
     ]
    }
   ],
   "source": [
    "for w, p, i in zip(web_pages, personas, instructions):\n",
    "    pp.pprint({\"web_page\": w[:100], \"persona\": p, \"instruction\": i})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ペルソナに該当する人物が、言語モデルに入力しそうなインストラクションを生成することが出来ました。\n",
    "\n",
    "先ほどの図を再掲します。今回行った処理は、この図のように、`web_page` から `persona` を抽出し(`Compress`)、`persona` から `instruction` という合成データを生成した(`Decompress`)、ということになります。\n",
    "\n",
    "<img src=\"https://github.com/user-attachments/assets/37ce038a-7702-4398-838d-8c504ac1da07\" width=\"800px\">\n",
    "\n",
    "もちろん `web_page` から `instruction` を直接生成することも可能ですが、一旦 `persona` に変換することで、トークン数を大幅に削減しつつ、元のテキストの情報量を残したまま多様な合成データが生成できるというのが Persona-Hub の特徴です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 知識豊富なテキストの合成\n",
    "\n",
    "次に、同様の手法でペルソナから知識豊富なテキストを合成します。\n",
    "\n",
    "Quoraは、ユーザがさまざまなトピックについて質問したり、回答を提供したりできる人気の Q&A サイトです。Quoraの記事は、様々な分野の専門家を含む知識豊富な人物によって書かれることが多く、質が高くよく調査された有益なコンテンツが確保されています。このアプローチによって、有益で知識豊富なコンテンツを得ることが出来ます。([Persona-Hub テクニカルレポート](https://arxiv.org/abs/2406.20094)より)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_quora_post(llm: LanguageModel, persona: str) -> str:\n",
    "    SYSTEM_PROMPT = \"You are an AI assistant specialized in writing posts for social media.\"\n",
    "\n",
    "    USER_PROMPT = \"\"\"\\\n",
    "Write a Quora post in the language, style, and personality of the following persona:\n",
    "\n",
    "{persona}\n",
    "\n",
    "Note:\n",
    "1. Your response should always start with \"記事:\".\n",
    "2. 簡潔に日本語で回答してください。\n",
    "\"\"\"\n",
    "\n",
    "    post = llm([[\n",
    "        # {\"role\": \"system\", \"content\": SYSTEM_PROMPT},  # if llm supports system prompt\n",
    "        # {\"role\": \"user\", \"content\": USER_PROMPT.format(persona=persona)},\n",
    "        {\"role\": \"user\", \"content\": SYSTEM_PROMPT + \"\\n\\n\" + USER_PROMPT.format(persona=persona)},  # if llm does not support system prompt\n",
    "    ]])[0]\n",
    "    logger.debug(f\"post: {post}\")\n",
    "\n",
    "    return re.sub(r\"^記事[:：]\", \"\", post).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "post: 記事:  \n",
      "オープンソースハードウェアとソフトウェアに魅了されている天文愛好家の皆さん、こんにちは！最近、Arduinoを使って自作の天体観測装置を作成するプロジェクトに取り組んでいます。スマートフォンと連携させることで、リアルタイムで星の位置を追跡し、データを記録することができるんです。\n",
      "\n",
      "このプロジェクトの魅力は、単に自分の天文観測を楽しむだけでなく、他の愛好者たちと知識を共有できる点です。オープンソースのコミュニティは、本当に素晴らしいですし、誰でも参加できるのが嬉しいですね。\n",
      "\n",
      "もし皆さんも、自分だけの天文プロジェクトを立ち上げてみたいと思っているなら、Arduinoやスマートフォンを活用してみてはいかがでしょうか？アイデアや技術的なサポートが必要であれば、ぜひコメントしてください。一緒に学んでいきましょう！🌌🔭✨\n",
      "post: 記事:  \n",
      "こんにちは！地質学に興味がある皆さん、今日は砂や鉱物の成り立ち、そして成熟度についてお話ししたいと思います。砂は一見単純なものに見えますが、実は地球の歴史を語る貴重な手がかりです。\n",
      "\n",
      "砂のサンプルを収集し、分析することで、私たちは過去の自然環境の変遷を理解できます。例えば、ある地域の砂がどのように形成されたのかを知ることで、その地域の気候や地形の変化を推測することができるのです。\n",
      "\n",
      "砂の成熟度も重要な指標です。成熟した砂は、長い時間をかけて風や水の影響を受け、粒子が磨かれ、均一な大きさになります。これに対し、未成熟な砂は多様な粒子サイズを持ち、エッジが鋭い状態です。この違いから、砂がどのように移動し、変化してきたのかを読み解くことができます。\n",
      "\n",
      "私たちの地球は常に変化しており、その証拠は砂の中に詰まっています。これからも、砂を通じて地球の物語を探求し続けたいと思います。興味のある方は、ぜひ一緒に研究をしましょう！\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['オープンソースハードウェアとソフトウェアに魅了されている天文愛好家の皆さん、こんにちは！最近、Arduinoを使って自作の天体観測装置を作成するプロジェクトに取り組んでいます。スマートフォンと連携させることで、リアルタイムで星の位置を追跡し、データを記録することができるんです。\\n\\nこのプロジェクトの魅力は、単に自分の天文観測を楽しむだけでなく、他の愛好者たちと知識を共有できる点です。オープンソースのコミュニティは、本当に素晴らしいですし、誰でも参加できるのが嬉しいですね。\\n\\nもし皆さんも、自分だけの天文プロジェクトを立ち上げてみたいと思っているなら、Arduinoやスマートフォンを活用してみてはいかがでしょうか？アイデアや技術的なサポートが必要であれば、ぜひコメントしてください。一緒に学んでいきましょう！🌌🔭✨',\n",
       " 'こんにちは！地質学に興味がある皆さん、今日は砂や鉱物の成り立ち、そして成熟度についてお話ししたいと思います。砂は一見単純なものに見えますが、実は地球の歴史を語る貴重な手がかりです。\\n\\n砂のサンプルを収集し、分析することで、私たちは過去の自然環境の変遷を理解できます。例えば、ある地域の砂がどのように形成されたのかを知ることで、その地域の気候や地形の変化を推測することができるのです。\\n\\n砂の成熟度も重要な指標です。成熟した砂は、長い時間をかけて風や水の影響を受け、粒子が磨かれ、均一な大きさになります。これに対し、未成熟な砂は多様な粒子サイズを持ち、エッジが鋭い状態です。この違いから、砂がどのように移動し、変化してきたのかを読み解くことができます。\\n\\n私たちの地球は常に変化しており、その証拠は砂の中に詰まっています。これからも、砂を通じて地球の物語を探求し続けたいと思います。興味のある方は、ぜひ一緒に研究をしましょう！']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts = [generate_quora_post(llm, p) for p in personas[:2]]\n",
    "posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'persona': 'オープンソースハードウェアとソフトウェアに関心を持つ天文愛好家であり、Arduinoやスマートフォンを用いた技術的なプロジェクトを推進するエンジニア。',\n",
      " 'post': 'オープンソースハードウェアとソフトウェアに魅了されている天文愛好家の皆さん、こんにちは！最近、Arduinoを使って自作の天体観測装置を作成するプロジェクトに取り組んでいます。スマートフォンと連携させ',\n",
      " 'web_page': 'This project is solving the Asteroid Watchers challenge. Description\\n'\n",
      "             'AROs are essentially created by'}\n",
      "{'persona': '地質学者であり、特に砂や鉱物の成り立ちや成熟度に関心を持つ研究者。彼らは自然環境の変遷や地球の歴史を理解するために、砂のサンプルを収集し分析することを楽しむ。',\n",
      " 'post': 'こんにちは！地質学に興味がある皆さん、今日は砂や鉱物の成り立ち、そして成熟度についてお話ししたいと思います。砂は一見単純なものに見えますが、実は地球の歴史を語る貴重な手がかりです。\\n'\n",
      "         '\\n'\n",
      "         '砂のサンプルを収',\n",
      " 'web_page': 'Life of a Sand Grain\\n'\n",
      "             'THE LIFE OF A SAND GRAIN by Carl Bowser (Sept. 2018)\\n'\n",
      "             'They surround you almost a'}\n"
     ]
    }
   ],
   "source": [
    "for web_page, persona, post in zip(web_pages, personas, posts):\n",
    "    pp.pprint({\"web_page\": web_page[:100], \"persona\": persona, \"post\": post[:100]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数学問題の合成\n",
    "\n",
    "最後に、ペルソナを使って数学の問題を合成します。数学問題については、後ほどさらに詳細なプロンプトを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_math_problem(llm: LanguageModel, persona: str) -> str:\n",
    "    SYSTEM_PROMPT = \"You are an AI assistant specialized in creating diverse but specific math problems. Just answer with your problem.\"\n",
    "\n",
    "    USER_PROMPT = \"\"\"\\\n",
    "Create a challenging math problem with the following persona:\n",
    "\n",
    "{persona}\n",
    "\n",
    "Note:\n",
    "1. Your response should always start with \"問題:\".\n",
    "2. 簡潔に日本語で回答してください。\n",
    "\"\"\"\n",
    "\n",
    "    problem = llm([[\n",
    "        # {\"role\": \"system\", \"content\": SYSTEM_PROMPT},  # if llm supports system prompt\n",
    "        # {\"role\": \"user\", \"content\": USER_PROMPT.format(persona=persona)},\n",
    "        {\"role\": \"user\", \"content\": SYSTEM_PROMPT + \"\\n\\n\" + USER_PROMPT.format(persona=persona)},  # if llm does not support system prompt\n",
    "    ]])[0]\n",
    "    logger.debug(f\"problem: {problem}\")\n",
    "\n",
    "    return re.sub(r\"^問題[:：]\", \"\", problem).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "problem: 問題: ある天文愛好家がArduinoを使って、星の位置を測定する装置を作成しました。この装置は、毎日午後8時に特定の星の高度を測定し、そのデータをスマートフォンに保存します。1ヶ月間（30日間）で、彼は合計450回のデータを収集しました。もし毎日のデータ収集回数が一定で、最初の10日間で集めたデータが全体の40%であった場合、残りの20日間で集めたデータの回数はいくつでしょうか？\n",
      "problem: 問題: 地質学者の佐藤は、異なる地域から集めた5種類の砂のサンプルを分析しています。各サンプルの粒子サイズの平均値は次の通りです: サンプルAは0.25mm、サンプルBは0.15mm、サンプルCは0.35mm、サンプルDは0.20mm、サンプルEは0.30mmです。これらの平均粒子サイズの中央値を求めなさい。\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ある天文愛好家がArduinoを使って、星の位置を測定する装置を作成しました。この装置は、毎日午後8時に特定の星の高度を測定し、そのデータをスマートフォンに保存します。1ヶ月間（30日間）で、彼は合計450回のデータを収集しました。もし毎日のデータ収集回数が一定で、最初の10日間で集めたデータが全体の40%であった場合、残りの20日間で集めたデータの回数はいくつでしょうか？',\n",
       " '地質学者の佐藤は、異なる地域から集めた5種類の砂のサンプルを分析しています。各サンプルの粒子サイズの平均値は次の通りです: サンプルAは0.25mm、サンプルBは0.15mm、サンプルCは0.35mm、サンプルDは0.20mm、サンプルEは0.30mmです。これらの平均粒子サイズの中央値を求めなさい。']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problems = [generate_math_problem(llm, p) for p in personas[:2]]\n",
    "problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'persona': 'オープンソースハードウェアとソフトウェアに関心を持つ天文愛好家であり、Arduinoやスマートフォンを用いた技術的なプロジェクトを推進するエンジニア。',\n",
      " 'problem': 'ある天文愛好家がArduinoを使って、星の位置を測定する装置を作成しました。この装置は、毎日午後8時に特定の星の高度を測定し、そのデータをスマートフォンに保存します。1ヶ月間（30日間）で、彼は合計',\n",
      " 'web_page': 'This project is solving the Asteroid Watchers challenge. Description\\n'\n",
      "             'AROs are essentially created by'}\n",
      "{'persona': '地質学者であり、特に砂や鉱物の成り立ちや成熟度に関心を持つ研究者。彼らは自然環境の変遷や地球の歴史を理解するために、砂のサンプルを収集し分析することを楽しむ。',\n",
      " 'problem': '地質学者の佐藤は、異なる地域から集めた5種類の砂のサンプルを分析しています。各サンプルの粒子サイズの平均値は次の通りです: '\n",
      "            'サンプルAは0.25mm、サンプルBは0.15mm、サンプルCは0.35mm',\n",
      " 'web_page': 'Life of a Sand Grain\\n'\n",
      "             'THE LIFE OF A SAND GRAIN by Carl Bowser (Sept. 2018)\\n'\n",
      "             'They surround you almost a'}\n"
     ]
    }
   ],
   "source": [
    "for web_page, persona, problem in zip(web_pages, personas, problems):\n",
    "    pp.pprint({\"web_page\": web_page[:100], \"persona\": persona, \"problem\": problem[:100]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上で、抽出したペルソナを使って以下の3つの合成データを生成しました。\n",
    "\n",
    "- インストラクション\n",
    "- 知識豊富なテキスト\n",
    "- 数学問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persona-Hub 手法のまとめ\n",
    "\n",
    "ここまで Persona-Hub 手法を紹介しました。以下にまとめます。\n",
    "\n",
    "<img src=\"https://github.com/user-attachments/assets/344b011d-b9f8-4ac3-a79a-198e3862b3cf\" width=\"800px\">\n",
    "\n",
    "- 既存の合成データ⽣成⼿法(インスタンス駆動・キーポイント駆動)では合成データの多様さをスケールアップすることが困難\n",
    "- ⼤規模なペルソナデータセットを作成し、それを使ってスケーラブルな合成データを⽣成する(ペルソナ駆動)\n",
    "- Web ページからペルソナを抽出\n",
    "  - Text-to-Persona\n",
    "  - Persona-to-Persona\n",
    "- ペルソナを使って合成データを生成\n",
    "  - インストラクション\n",
    "  - 知識豊富なテキスト\n",
    "  - 数学問題\n",
    "- テクニカルレポート: https://arxiv.org/abs/2406.20094"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FinePersonas による事後学習データ合成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FinePersonas とは\n",
    "\n",
    "ここからは大規模なペルソナデータセットである [FinePersonas](https://huggingface.co/datasets/argilla/FinePersonas-v0.1) について説明します。\n",
    "\n",
    "<img src=\"https://cdn-uploads.huggingface.co/production/uploads/6435d564a4bd75c62cc03701/5wTHwgijTUKFI5B-N7gEg.png\" width=\"600px\">\n",
    "\n",
    "[FinePersonas](https://huggingface.co/datasets/argilla/FinePersonas-v0.1) は Argilla が2024年9月にリリースされた合成テキスト生成のためのペルソナデータセットです。以下のような特徴があります。\n",
    "\n",
    "- 2100万人の詳細なペルソナのオープンデータセット\n",
    "- 合成データの豊富さ・多様性・特異性を高めることが可能\n",
    "- [Persona-Hub](https://arxiv.org/abs/2406.20094) と同じレシピに従い、[FineWeb-Edu](https://huggingface.co/datasets/HuggingFaceFW/fineweb-edu) (教育関連Webページのデータセット)から2100万件のペルソナを抽出\n",
    "- ライセンス: Llama 3.1 Community License Agreement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FinePersonas データセットの読み込み\n",
    "\n",
    "実際のペルソナデータを読み込んで、数学の問題と解答を合成します。[FinePersonas](https://huggingface.co/datasets/argilla/FinePersonas-v0.1) データセットを利用します。\n",
    "\n",
    "FinePersonas データセットは巨大なデータセットですので、本ハンズオンでは一部分だけをダウンロードして利用します。読み込む際に `streaming=True` を必ずつけてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IterableDataset({\n",
       "    features: ['id', 'persona', 'labels'],\n",
       "    num_shards: 12\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"argilla/FinePersonas-v0.1\", split=\"train\", cache_dir=\"cache\", streaming=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回は先頭の100件を使って生成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A professional R programmer or researcher, likely a data analyst or statistician, familiar with '\n",
      " 'the intricacies of the R language and its debugging tools.',\n",
      " 'A mental health professional, likely a licensed therapist or psychologist, with expertise in '\n",
      " 'anxiety disorders and cognitive-behavioral therapy, whose work involves diagnosing and treating '\n",
      " 'patients with various types of phobias, including specific phobia, social phobia, and '\n",
      " 'agoraphobia.',\n",
      " 'A space roboticist or aerospace engineer at a research institution focused on robotic space '\n",
      " 'exploration.',\n",
      " 'A Hebrew language scholar or instructor with a focus on biblical Hebrew and Jewish studies.',\n",
      " 'A pediatrician or healthcare professional focused on educating parents about early childhood '\n",
      " 'health, or a parent-to-be who is interested in learning about vaccinations for their unborn or '\n",
      " 'newborn child.',\n",
      " 'A Montessori elementary school teacher or an education administrator responsible for curriculum '\n",
      " 'development and classroom management in a Montessori school setting.',\n",
      " 'An aerospace materials engineer focused on advanced ceramic coatings and plasma deposition '\n",
      " 'techniques for high-temperature applications.',\n",
      " 'An astrophysicist specializing in the study of planetary magnetism and aurora phenomena, likely '\n",
      " 'with a focus on exoplanetary systems and space exploration.',\n",
      " 'An elementary school teacher or educator focused on creating and compiling educational content '\n",
      " 'for young students, likely in a science, reading, or early childhood development curriculum.',\n",
      " 'A forester or park ranger concerned with forest health and pest management in the western United '\n",
      " 'States, likely working in or near national parks.']\n"
     ]
    }
   ],
   "source": [
    "personas = [data[\"persona\"] for data in dataset.take(100)]\n",
    "pp.pprint(personas[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### マルチターン対話データの合成\n",
    "\n",
    "ここからは事後学習のためのマルチターン対話データを生成します。具体的には、\n",
    "\n",
    "- 質問1 (`Q1`): ユーザが質問をする (この部分を Persona-Hub 手法で生成)\n",
    "- 解答1 (`A1`): アシスタントが解答する\n",
    "- 質問2 (`Q2`): ユーザが追加質問をする\n",
    "- 解答2 (`A2`): アシスタントが追加質問に解答する\n",
    "\n",
    "という4つの対話データを生成します。このうち `Q1` の生成に Persona-Hub 手法を適用します。それ以降の対話データは、若干の工夫をしますが基本的に言語モデルの生成に任せます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1 の生成\n",
    "\n",
    "まず、Persona-Hub 手法を使って `Q1` の生成を行います。\n",
    "\n",
    "[元論文のコード](https://github.com/tencent-ailab/persona-hub/blob/main/code/prompt_templates.py)では、数学の問題を生成するプロンプトとして以下が紹介されています。\n",
    "\n",
    "```python\n",
    "math_template = '''Create a math problem related to the following persona:\n",
    "\n",
    "{persona}\n",
    "\n",
    "Note:\n",
    "\n",
    "1. The math problem should be challenging and involve advanced mathematical skills and knowledge. Only top talents can solve it correctly.\n",
    "2. You should make full use of the persona description to create the math problem to ensure that the math problem is unique and specific to the persona.\n",
    "3. Your response should always start with \"Math problem:\". Your response should not include a solution to the created math problem.\n",
    "4. Your created math problem should include no more than 2 sub-problems.\n",
    "'''\n",
    "```\n",
    "\n",
    "これを参考に、プロンプトの一部を修正/パラメータ化して使います。修正点は以下の通りです。\n",
    "\n",
    "- 一部の単語をパラメータ化\n",
    "  - タスクの種類: `task` (e.g. \"math\", \"reasoning\", \"coding\")\n",
    "  - トピックの種類: `topic` (e.g. \"persona\", \"topic\")\n",
    "  - トピックの内容: `item` (e.g. \"SF作家\", \"経営コンサルタント\")\n",
    "  - 対象者: `target` (e.g. \"grade school student\", \"graduate student\")\n",
    "- 難易度を調整\n",
    "  - 元のプロンプトはかなり難易度の高い問題を生成するような表現(`challenging`, `advanced`, `top talents`)となっていたため、難易度を下げるように表現を修正(`simple`, `basic`, `average`)\n",
    "- 小問を生成しないよう修正\n",
    "  - 小問を生成すると対話が複雑になりすぎるため、小問を生成しないように修正(`sub-problems`の行を削除)。代わりにマルチターンで追加質問をするようにする。\n",
    "- 日本語を出力\n",
    "  - 元のプロンプトは英語を出力するようになっているため、日本語を出力するように促すプロンプトを追加\n",
    "\n",
    "上記の修正をしたプロンプトを OpenAI messages 形式で出力する関数を作成します。\n",
    "\n",
    "また、利用する言語モデルで推奨されているシステムプロンプトがある場合は、それを指定します(コメントアウトされた `{\"role\": \"system\", \"content\": \"...\"}` の部分)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_q1_prompt(task: str, topic: str, item: str, target: str) -> list[dict[str, str]]:\n",
    "    Q1_PROMPT_TEMPLATE = \"\"\"Create a {task} problem related to the following {topic}:\n",
    "\n",
    "{item}\n",
    "\n",
    "Note:\n",
    "\n",
    "1. The {task} problem should be simple and involve basic {task} skills and knowledge. Any average {target} can solve it correctly.\n",
    "2. You should make full use of the {topic} description to create the {task} problem to ensure that the {task} problem is unique and specific to the {topic}.\n",
    "3. Your response should always start with \"問題:\". Your response should not include a solution to the created {task} problem.\n",
    "4. 簡潔に日本語で回答してください。\n",
    "\"\"\"\n",
    "    return [\n",
    "        # {\"role\": \"system\", \"content\": \"あなたは親切なAIアシスタントです。日本語で回答してください。\"},\n",
    "        {\"role\": \"user\", \"content\": Q1_PROMPT_TEMPLATE.format(task=task, topic=topic, item=item, target=target)},\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実行して動作を確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': 'Create a math problem related to the following persona:\\n'\n",
      "             '\\n'\n",
      "             'A professional R programmer or researcher, likely a data analyst or statistician, '\n",
      "             'familiar with the intricacies of the R language and its debugging tools.\\n'\n",
      "             '\\n'\n",
      "             'Note:\\n'\n",
      "             '\\n'\n",
      "             '1. The math problem should be simple and involve basic math skills and knowledge. '\n",
      "             'Any average grade school student can solve it correctly.\\n'\n",
      "             '2. You should make full use of the persona description to create the math problem to '\n",
      "             'ensure that the math problem is unique and specific to the persona.\\n'\n",
      "             '3. Your response should always start with \"問題:\". Your response should not include a '\n",
      "             'solution to the created math problem.\\n'\n",
      "             '4. 簡潔に日本語で回答してください。\\n',\n",
      "  'role': 'user'}]\n"
     ]
    }
   ],
   "source": [
    "q1_prompt = get_q1_prompt(\"math\", \"persona\", personas[0], \"grade school student\")\n",
    "pp.pprint(q1_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "言語モデルで推論して Q1 を生成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['問題: R言語を使ってデータを分析している研究者がいます。彼は、データセットの中から特定の5つの数値を抽出しました。これらの数値はそれぞれ3, 7, 2, 5, '\n",
      " '8です。これらの数値の合計はいくつですか？']\n"
     ]
    }
   ],
   "source": [
    "q1s = llm([get_q1_prompt(\"math\", \"persona\", personas[0], \"grade school student\")])\n",
    "pp.pprint(q1s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "引数を変更して難易度の高い問題を生成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['問題:  \\n'\n",
      " 'あるデータ分析者が、R言語を用いてあるデータセットの回帰分析を行っています。データセットには、独立変数 \\\\(X\\\\) と従属変数 \\\\(Y\\\\) '\n",
      " 'のペアが含まれています。回帰モデルの式が次のように与えられています。\\n'\n",
      " '\\n'\n",
      " '\\\\[\\n'\n",
      " 'Y = \\\\beta_0 + \\\\beta_1 X + \\\\epsilon\\n'\n",
      " '\\\\]\\n'\n",
      " '\\n'\n",
      " 'ここで、\\\\(\\\\beta_0\\\\) は切片、\\\\(\\\\beta_1\\\\) は傾き、\\\\(\\\\epsilon\\\\) は誤差項です。このデータ分析者は、\\\\(\\\\beta_1\\\\) '\n",
      " 'の値が0.5であると仮定し、切片 \\\\(\\\\beta_0\\\\) は未知であるとします。\\n'\n",
      " '\\n'\n",
      " 'データセットの中で、\\\\(X\\\\) の平均が10、標準偏差が2、\\\\(Y\\\\) の平均が20、標準偏差が3であることがわかっています。このとき、\\\\(\\\\beta_0\\\\) '\n",
      " 'の推定値を求めるために必要な数式を導出し、推定値を計算してください。ただし、相関係数 \\\\(r\\\\) は0.8とします。']\n"
     ]
    }
   ],
   "source": [
    "q1s = llm([get_q1_prompt(\"advanced math\", \"persona\", personas[0], \"graduate student\")])\n",
    "pp.pprint(q1s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "問題さなさそうです。\n",
    "\n",
    "次に、`問題:` など余分な部分をルールベース(正規表現)で削除します。言語モデルによっては、解答やヒントを書いてしまうものがありますので、もしそれらが出力されるのであればここで削除しておきます。\n",
    "\n",
    "**Note: この関数が複雑になり過ぎる場合は、プロンプトの見直しや言語モデルの変更を検討した方が良いかもしれません。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_q1(content: str) -> str:\n",
    "    content = content.strip()\n",
    "    content = re.sub(r\"^問題[：:]\", \"\", content, flags=re.DOTALL)\n",
    "    content = re.sub(r\"^Problem[：:]\", \"\", content, flags=re.DOTALL)\n",
    "    content = re.sub(r\"\\n答え[：:].*\", \"\", content, flags=re.DOTALL)\n",
    "    content = re.sub(r\"\\n[解回]答[：:].*\", \"\", content, flags=re.DOTALL)\n",
    "    content = re.sub(r\"\\n[Aa]nswer[：:].*\", \"\", content, flags=re.DOTALL)  # cspell: disable-line\n",
    "    content = content.strip()\n",
    "    return content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実行して動作を確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'あるデータ分析者が、R言語を用いてあるデータセットの回帰分析を行っています。データセットには、独立変数 \\\\(X\\\\) と従属変数 \\\\(Y\\\\) のペアが含まれています。回帰モデルの式が次のように与えられています。\\n\\n\\\\[\\nY = \\\\beta_0 + \\\\beta_1 X + \\\\epsilon\\n\\\\]\\n\\nここで、\\\\(\\\\beta_0\\\\) は切片、\\\\(\\\\beta_1\\\\) は傾き、\\\\(\\\\epsilon\\\\) は誤差項です。このデータ分析者は、\\\\(\\\\beta_1\\\\) の値が0.5であると仮定し、切片 \\\\(\\\\beta_0\\\\) は未知であるとします。\\n\\nデータセットの中で、\\\\(X\\\\) の平均が10、標準偏差が2、\\\\(Y\\\\) の平均が20、標準偏差が3であることがわかっています。このとき、\\\\(\\\\beta_0\\\\) の推定値を求めるために必要な数式を導出し、推定値を計算してください。ただし、相関係数 \\\\(r\\\\) は0.8とします。'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_q1(q1s[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "問題なさそうです。\n",
    "\n",
    "作成した関数を組み合わせて、バッチ処理で `Q1` を生成する関数を作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_q1(\n",
    "    llm: LanguageModel, tasks: list[str], topics: list[str], items: list[str], targets: list[str]\n",
    ") -> list[str]:\n",
    "    return [\n",
    "        filter_q1(q1)\n",
    "        for q1 in llm([\n",
    "            get_q1_prompt(task, topic, item, target)\n",
    "            for task, topic, item, target in zip(tasks, topics, items, targets)\n",
    "        ])\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実行して動作を確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['R言語を使ってデータを分析している研究者がいます。彼は、データセットの中から特定の5つの数値を抽出しました。これらの数値はそれぞれ3, 7, 2, 5, '\n",
      " '10です。彼はこれらの数値の合計を求めたいと考えています。これらの数値の合計はいくつになりますか？',\n",
      " 'ある精神健康専門家が、特定の恐怖症と社会不安障害を抱える患者の治療を行っています。彼は、10人の患者を対象にした研究を行い、その中の6人が特定の恐怖症を持ち、4人が社会不安障害を持っています。この専門家は、各患者が受ける治療セッションの平均時間を30分とし、特定の恐怖症を持つ患者には週に2回、社会不安障害を持つ患者には週に1回のセッションを提供することに決定しました。\\n'\n",
      " '\\n'\n",
      " '1. それぞれの患者タイプに対する合計治療時間を計算してください。\\n'\n",
      " '2. 各患者タイプの治療セッションの合計回数を求めてください。\\n'\n",
      " '3. 合計治療時間を合計回数で割って、各セッションの平均時間を出してください。']\n"
     ]
    }
   ],
   "source": [
    "q1s = generate_q1(\n",
    "    llm,\n",
    "    [\"math\", \"advanced math\"],\n",
    "    [\"persona\", \"persona\"],\n",
    "    personas[:2],\n",
    "    [\"grade school student\", \"graduate student\"],\n",
    ")\n",
    "pp.pprint(q1s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "問題なさそうです。ここまでで `Q1` を生成する関数の実装が完了しました。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A1 の生成\n",
    "\n",
    "次に、`A1` の生成を行います。ここでは基本的に `Q1` を入力して、長さ指定(`簡潔に`)と、出力言語の指定(`日本語で`)をして言語モデルに生成させます。言語モデルによっては、表現を微調整する必要があるかもしれません。\n",
    "\n",
    "実行の流れは `Q1` と同様ですので、ここではコードのみ記載します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_a1_prompt(q1: str) -> list[dict]:\n",
    "    A1_PROMPT_TEMPLATE = \"{q1}\\n\\n簡潔に日本語で回答してください。\"\n",
    "    return [\n",
    "        # {\"role\": \"system\", \"content\": \"あなたは親切なAIアシスタントです。日本語で回答してください。\"},\n",
    "        {\"role\": \"user\", \"content\": A1_PROMPT_TEMPLATE.format(q1=q1)},\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': 'R言語を使ってデータを分析している研究者がいます。彼は、データセットの中から特定の5つの数値を抽出しました。これらの数値はそれぞれ3, 7, 2, 5, '\n",
      "             '10です。彼はこれらの数値の合計を求めたいと考えています。これらの数値の合計はいくつになりますか？\\n'\n",
      "             '\\n'\n",
      "             '簡潔に日本語で回答してください。',\n",
      "  'role': 'user'}]\n"
     ]
    }
   ],
   "source": [
    "a1_prompt = get_a1_prompt(q1s[0])\n",
    "pp.pprint(a1_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['合計は27です。']\n"
     ]
    }
   ],
   "source": [
    "a1s = llm([get_a1_prompt(q1s[0])])\n",
    "pp.pprint(a1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1. **合計治療時間の計算**:\\n'\n",
      " '   - 特定の恐怖症を持つ患者: 6人 × 30分 × 2回/週 = 360分\\n'\n",
      " '   - 社会不安障害を持つ患者: 4人 × 30分 × 1回/週 = 120分\\n'\n",
      " '   - 合計治療時間 = 360分 + 120分 = 480分\\n'\n",
      " '\\n'\n",
      " '2. **治療セッションの合計回数**:\\n'\n",
      " '   - 特定の恐怖症を持つ患者: 6人 × 2回/週 = 12回\\n'\n",
      " '   - 社会不安障害を持つ患者: 4人 × 1回/週 = 4回\\n'\n",
      " '   - 合計治療セッション数 = 12回 + 4回 = 16回\\n'\n",
      " '\\n'\n",
      " '3. **平均セッション時間の計算**:\\n'\n",
      " '   - 合計治療時間 / 合計回数 = 480分 / 16回 = 30分\\n'\n",
      " '\\n'\n",
      " '以上の結果から、各セッションの平均時間は30分です。']\n"
     ]
    }
   ],
   "source": [
    "a1s = llm([get_a1_prompt(q1s[1])])\n",
    "pp.pprint(a1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_a1(content: str) -> str:\n",
    "    content = content.strip()\n",
    "    content = re.sub(r\"^答え[：:]\", \"\", content, flags=re.DOTALL)\n",
    "    content = re.sub(r\"^[解回]答[：:]\", \"\", content, flags=re.DOTALL)\n",
    "    content = re.sub(r\"^[Aa]nswer[：:]\", \"\", content, flags=re.DOTALL)  # cspell: disable-line\n",
    "    content = content.strip()\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_a1(llm: LanguageModel, q1s: list[str]) -> list[str]:\n",
    "    return [filter_a1(a1) for a1 in llm([get_a1_prompt(q1) for q1 in q1s])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['合計は27です。',\n",
      " '1. **合計治療時間の計算**:\\n'\n",
      " '   - 特定の恐怖症を持つ患者: 6人 × 30分 × 2回/週 = 360分\\n'\n",
      " '   - 社会不安障害を持つ患者: 4人 × 30分 × 1回/週 = 120分\\n'\n",
      " '   - **合計治療時間** = 360分 + 120分 = **480分**\\n'\n",
      " '\\n'\n",
      " '2. **治療セッションの合計回数**:\\n'\n",
      " '   - 特定の恐怖症を持つ患者: 6人 × 2回/週 = 12回\\n'\n",
      " '   - 社会不安障害を持つ患者: 4人 × 1回/週 = 4回\\n'\n",
      " '   - **合計回数** = 12回 + 4回 = **16回**\\n'\n",
      " '\\n'\n",
      " '3. **平均セッション時間の計算**:\\n'\n",
      " '   - 合計治療時間: 480分\\n'\n",
      " '   - 合計回数: 16回\\n'\n",
      " '   - **平均時間** = 480分 ÷ 16回 = **30分** \\n'\n",
      " '\\n'\n",
      " '以上の結果です。']\n"
     ]
    }
   ],
   "source": [
    "a1s = generate_a1(llm, q1s)\n",
    "pp.pprint(a1s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2 の生成\n",
    "\n",
    "次に、追加質問 `Q2` の生成を行います。\n",
    "\n",
    "- まず `Q1` に関連する質問であることを強調します(`前述の問題をより理解するために`の部分)。これが無いと `Q2` で新たな別の質問を生成してしまうことがあります。\n",
    "- 次に `問題の一部を変更したり、条件を追加しても良いです` という部分で、`Q1` の問題の一部を変更することを促します。これにより、`Q2` が `Q1` に関連する質問となる確率を高めることができます。\n",
    "- 最後に答えを含まないように注意を促します(`決して答えを含めないでください`の部分)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_q2_prompt(q1: str, a1: str) -> list[dict[str, str]]:\n",
    "    Q2_PROMPT_TEMPLATE = \"前述の問題をより理解するために、簡潔な追加の質問を一つ作ってください。問題の一部を変更したり、条件を追加しても良いです。追加の質問だけを書き、決して答えを含めないでください。\"\n",
    "    return [\n",
    "        # {\"role\": \"system\", \"content\": \"あなたは親切なAIアシスタントです。日本語で回答してください。\"},\n",
    "        {\"role\": \"user\", \"content\": q1},\n",
    "        {\"role\": \"assistant\", \"content\": a1},\n",
    "        {\"role\": \"user\", \"content\": Q2_PROMPT_TEMPLATE},\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': 'R言語を使ってデータを分析している研究者がいます。彼は、データセットの中から特定の5つの数値を抽出しました。これらの数値はそれぞれ3, 7, 2, 5, '\n",
      "             '10です。彼はこれらの数値の合計を求めたいと考えています。これらの数値の合計はいくつになりますか？',\n",
      "  'role': 'user'},\n",
      " {'content': '合計は27です。', 'role': 'assistant'},\n",
      " {'content': '前述の問題をより理解するために、簡潔な追加の質問を一つ作ってください。問題の一部を変更したり、条件を追加しても良いです。追加の質問だけを書き、決して答えを含めないでください。',\n",
      "  'role': 'user'}]\n"
     ]
    }
   ],
   "source": [
    "q2_prompt = get_q2_prompt(q1s[0], a1s[0])\n",
    "pp.pprint(q2_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['これらの数値の平均を求めるには、どのように計算しますか？']\n"
     ]
    }
   ],
   "source": [
    "q2s = llm([get_q2_prompt(q1s[0], a1s[0])])\n",
    "pp.pprint(q2s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_q2(content: str) -> str:\n",
    "    content = content.strip()\n",
    "    content = re.sub(r\"^追加の質問[：:]\", \"\", content, flags=re.DOTALL)\n",
    "    content = re.sub(r\"^質問[：:]\", \"\", content, flags=re.DOTALL)\n",
    "    content = content.strip()\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_q2(llm: LanguageModel, q1s: list[str], a1s: list[str]) -> list[str]:\n",
    "    return [filter_q2(q2) for q2 in llm([get_q2_prompt(q1, a1) for q1, a1 in zip(q1s, a1s)])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['これらの数値の平均を求めるには、どのように計算しますか？', '特定の恐怖症を持つ患者には、特別なワークショップを月に1回追加で行うことにした場合、月間の合計治療時間はどのように変わりますか？']\n"
     ]
    }
   ],
   "source": [
    "q2s = generate_q2(llm, q1s, a1s)\n",
    "pp.pprint(q2s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A2 の生成\n",
    "\n",
    "最後に、`A2` の生成を行います。基本的に `A1` の生成と同様ですので、ここではコードのみ記載します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_a2_prompt(q1: str, a1: str, q2: str) -> list[dict[str, str]]:\n",
    "    A2_PROMPT_TEMPLATE = \"{q2}\\n\\n簡潔に日本語で回答してください。\"\n",
    "    return [\n",
    "        # {\"role\": \"system\", \"content\": \"あなたは親切なAIアシスタントです。日本語で回答してください。\"},\n",
    "        {\"role\": \"user\", \"content\": q1},\n",
    "        {\"role\": \"assistant\", \"content\": a1},\n",
    "        {\"role\": \"user\", \"content\": A2_PROMPT_TEMPLATE.format(q2=q2)},\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': 'R言語を使ってデータを分析している研究者がいます。彼は、データセットの中から特定の5つの数値を抽出しました。これらの数値はそれぞれ3, 7, 2, 5, '\n",
      "             '10です。彼はこれらの数値の合計を求めたいと考えています。これらの数値の合計はいくつになりますか？',\n",
      "  'role': 'user'},\n",
      " {'content': '合計は27です。', 'role': 'assistant'},\n",
      " {'content': 'これらの数値の平均を求めるには、どのように計算しますか？\\n\\n簡潔に日本語で回答してください。', 'role': 'user'}]\n"
     ]
    }
   ],
   "source": [
    "a2_prompt = get_a2_prompt(q1s[0], a1s[0], q2s[0])\n",
    "pp.pprint(a2_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['これらの数値の平均を求めるには、合計を数値の個数で割ります。具体的には、合計27を5で割ります。計算式は次の通りです。\\n'\n",
      " '\\n'\n",
      " '\\\\[\\n'\n",
      " '\\\\text{平均} = \\\\frac{27}{5} = 5.4\\n'\n",
      " '\\\\] \\n'\n",
      " '\\n'\n",
      " 'したがって、平均は5.4です。',\n",
      " '特定の恐怖症を持つ患者には、月に1回の特別なワークショップが追加されます。ワークショップの時間は30分と仮定すると、6人の患者全員が参加するため、追加の治療時間は次のように計算されます。\\n'\n",
      " '\\n'\n",
      " '- 追加の治療時間: 6人 × 30分 = 180分\\n'\n",
      " '\\n'\n",
      " '元の月間治療時間は、特定の恐怖症の360分と社会不安障害の120分を合わせて480分です。\\n'\n",
      " '\\n'\n",
      " '月間の合計治療時間は:\\n'\n",
      " '- 480分 + 180分 = **660分**\\n'\n",
      " '\\n'\n",
      " 'したがって、月間の合計治療時間は660分に増加します。']\n"
     ]
    }
   ],
   "source": [
    "a2s = llm([get_a2_prompt(q1, a1, q2) for q1, a1, q2 in zip(q1s, a1s, q2s)])\n",
    "pp.pprint(a2s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_a2(content: str) -> str:\n",
    "    content = content.strip()\n",
    "    content = re.sub(r\"^答え[：:]\", \"\", content, flags=re.DOTALL)\n",
    "    content = re.sub(r\"^[解回]答[：:]\", \"\", content, flags=re.DOTALL)\n",
    "    content = re.sub(r\"^[Aa]nswer[：:]\", \"\", content, flags=re.DOTALL)  # cspell: disable-line\n",
    "    content = content.strip()\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_a2(llm: LanguageModel, q1s: list[str], a1s: list[str], q2s: list[str]) -> list[str]:\n",
    "    return [filter_a2(a2) for a2 in llm([get_a2_prompt(q1, a1, q2) for q1, a1, q2 in zip(q1s, a1s, q2s)])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['これらの数値の平均を求めるには、合計を数値の個数で割ります。具体的には、合計27を5で割ります。計算式は次の通りです。\\n'\n",
      " '\\n'\n",
      " '\\\\[\\n'\n",
      " '\\\\text{平均} = \\\\frac{27}{5} = 5.4\\n'\n",
      " '\\\\] \\n'\n",
      " '\\n'\n",
      " 'したがって、平均は5.4です。',\n",
      " '特定の恐怖症を持つ患者には、月に1回の特別なワークショップが追加されます。ワークショップの時間は30分と仮定すると、6人の患者全員が参加するため、追加の治療時間は次のように計算されます。\\n'\n",
      " '\\n'\n",
      " '- 追加の治療時間: 6人 × 30分 = 180分\\n'\n",
      " '\\n'\n",
      " '元の月間治療時間は、特定の恐怖症の360分と社会不安障害の120分を合わせて480分でした。\\n'\n",
      " '\\n'\n",
      " '**新しい月間合計治療時間**:\\n'\n",
      " '480分 + 180分 = **660分**\\n'\n",
      " '\\n'\n",
      " 'したがって、月間の合計治療時間は660分に増加します。']\n"
     ]
    }
   ],
   "source": [
    "a2s = generate_a2(llm, q1s, a1s, q2s)\n",
    "pp.pprint(a2s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここまでの対話データの流れを確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('R言語を使ってデータを分析している研究者がいます。彼は、データセットの中から特定の5つの数値を抽出しました。これらの数値はそれぞれ3, 7, 2, 5, '\n",
      " '10です。彼はこれらの数値の合計を求めたいと考えています。これらの数値の合計はいくつになりますか？',\n",
      " '合計は27です。',\n",
      " 'これらの数値の平均を求めるには、どのように計算しますか？',\n",
      " 'これらの数値の平均を求めるには、合計を数値の個数で割ります。具体的には、合計27を5で割ります。計算式は次の通りです。\\n'\n",
      " '\\n'\n",
      " '\\\\[\\n'\n",
      " '\\\\text{平均} = \\\\frac{27}{5} = 5.4\\n'\n",
      " '\\\\] \\n'\n",
      " '\\n'\n",
      " 'したがって、平均は5.4です。')\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(list(zip(q1s, a1s, q2s, a2s))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ある精神健康専門家が、特定の恐怖症と社会不安障害を抱える患者の治療を行っています。彼は、10人の患者を対象にした研究を行い、その中の6人が特定の恐怖症を持ち、4人が社会不安障害を持っています。この専門家は、各患者が受ける治療セッションの平均時間を30分とし、特定の恐怖症を持つ患者には週に2回、社会不安障害を持つ患者には週に1回のセッションを提供することに決定しました。\\n'\n",
      " '\\n'\n",
      " '1. それぞれの患者タイプに対する合計治療時間を計算してください。\\n'\n",
      " '2. 各患者タイプの治療セッションの合計回数を求めてください。\\n'\n",
      " '3. 合計治療時間を合計回数で割って、各セッションの平均時間を出してください。',\n",
      " '1. **合計治療時間の計算**:\\n'\n",
      " '   - 特定の恐怖症を持つ患者: 6人 × 30分 × 2回/週 = 360分\\n'\n",
      " '   - 社会不安障害を持つ患者: 4人 × 30分 × 1回/週 = 120分\\n'\n",
      " '   - **合計治療時間** = 360分 + 120分 = **480分**\\n'\n",
      " '\\n'\n",
      " '2. **治療セッションの合計回数**:\\n'\n",
      " '   - 特定の恐怖症を持つ患者: 6人 × 2回/週 = 12回\\n'\n",
      " '   - 社会不安障害を持つ患者: 4人 × 1回/週 = 4回\\n'\n",
      " '   - **合計回数** = 12回 + 4回 = **16回**\\n'\n",
      " '\\n'\n",
      " '3. **平均セッション時間の計算**:\\n'\n",
      " '   - 合計治療時間: 480分\\n'\n",
      " '   - 合計回数: 16回\\n'\n",
      " '   - **平均時間** = 480分 ÷ 16回 = **30分** \\n'\n",
      " '\\n'\n",
      " '以上の結果です。',\n",
      " '特定の恐怖症を持つ患者には、特別なワークショップを月に1回追加で行うことにした場合、月間の合計治療時間はどのように変わりますか？',\n",
      " '特定の恐怖症を持つ患者には、月に1回の特別なワークショップが追加されます。ワークショップの時間は30分と仮定すると、6人の患者全員が参加するため、追加の治療時間は次のように計算されます。\\n'\n",
      " '\\n'\n",
      " '- 追加の治療時間: 6人 × 30分 = 180分\\n'\n",
      " '\\n'\n",
      " '元の月間治療時間は、特定の恐怖症の360分と社会不安障害の120分を合わせて480分でした。\\n'\n",
      " '\\n'\n",
      " '**新しい月間合計治療時間**:\\n'\n",
      " '480分 + 180分 = **660分**\\n'\n",
      " '\\n'\n",
      " 'したがって、月間の合計治療時間は660分に増加します。')\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(list(zip(q1s, a1s, q2s, a2s))[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "面白い問題かどうかはともかく、問題なさそうです。これで `A2` の生成も完了しました。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### マルチターン対話データの生成\n",
    "\n",
    "これまで作成した関数を組み合わせて、マルチターンの対話データを生成する関数を作成します。結果は OpenAI messages 形式で出力します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesis_multi_turn_qa(\n",
    "    llm: LanguageModel, tasks: list[str], topics: list[str], items: list[str], targets: list[str]\n",
    ") -> list[dict[str, str | list[dict[str, str]]]]:\n",
    "    q1s = generate_q1(llm, tasks, topics, items, targets)\n",
    "    a1s = generate_a1(llm, q1s)\n",
    "    q2s = generate_q2(llm, q1s, a1s)\n",
    "    a2s = generate_a2(llm, q1s, a1s, q2s)\n",
    "    return [\n",
    "        {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"user\", \"content\": q1},\n",
    "                {\"role\": \"assistant\", \"content\": a1},\n",
    "                {\"role\": \"user\", \"content\": q2},\n",
    "                {\"role\": \"assistant\", \"content\": a2},\n",
    "            ],\n",
    "            \"task\": task,\n",
    "            \"topic\": topic,\n",
    "            \"item\": item,\n",
    "            \"target\": target,\n",
    "        }\n",
    "        for task, topic, item, target, q1, a1, q2, a2 in zip(tasks, topics, items, targets, q1s, a1s, q2s, a2s)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実行して動作を確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'item': 'A professional R programmer or researcher, likely a data analyst or statistician, '\n",
      "          'familiar with the intricacies of the R language and its debugging tools.',\n",
      "  'messages': [{'content': 'R言語を使ってデータを分析している研究者がいます。彼は、データセットの中から特定の5つの数値を抽出しました。これらの数値はそれぞれ3、7、2、9、5です。彼はこの5つの数値の合計を求めたいと思っています。合計はいくつになりますか？',\n",
      "                'role': 'user'},\n",
      "               {'content': '合計は26です。', 'role': 'assistant'},\n",
      "               {'content': 'この5つの数値の平均を求めると、いくつになりますか？', 'role': 'user'},\n",
      "               {'content': '平均は5.2です。', 'role': 'assistant'}],\n",
      "  'target': 'grade school student',\n",
      "  'task': 'math',\n",
      "  'topic': 'persona'}]\n"
     ]
    }
   ],
   "source": [
    "qas = synthesis_multi_turn_qa(\n",
    "    llm,\n",
    "    [\"math\"],\n",
    "    [\"persona\"],\n",
    "    personas[:1],\n",
    "    [\"grade school student\"],\n",
    ")\n",
    "pp.pprint(qas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この関数をバッチ処理で実行し、結果を JSONL ファイルに保存する関数を作成します。`task`, `topic`, `item`, `target` は、与えられた引数からランダムに選択して、対話データを生成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_synthesis_multi_turn_qa(\n",
    "    llm: LanguageModel,\n",
    "    task_list: list[str],\n",
    "    topic_list: list[str],\n",
    "    item_list: list[str],\n",
    "    target_list: list[str],\n",
    "    num_samples: int = 1,\n",
    "    batch_size: int = 1,\n",
    "    output_jsonl: str = \"output.jsonl\",\n",
    "):\n",
    "    with open(output_jsonl, \"a\", encoding=\"utf-8\") as f:\n",
    "        for i in range(num_samples // batch_size):\n",
    "            tasks = [random.choice(task_list) for _ in range(batch_size)]\n",
    "            topics = [random.choice(topic_list) for _ in range(batch_size)]\n",
    "            items = [random.choice(item_list) for _ in range(batch_size)]\n",
    "            targets = [random.choice(target_list) for _ in range(batch_size)]\n",
    "            assert len(tasks) == len(topics) == len(items) == len(targets) == batch_size\n",
    "            qas = synthesis_multi_turn_qa(llm, tasks, topics, items, targets)\n",
    "            for qa in qas:\n",
    "                f.write(json.dumps(qa, ensure_ascii=False) + \"\\n\")\n",
    "                print(pp.pformat(qa))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ペルソナデータから対話データを生成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'item': 'An aerospace materials engineer focused on advanced ceramic coatings and plasma '\n",
      "         'deposition techniques for high-temperature applications.',\n",
      " 'messages': [{'content': 'ある航空宇宙材料エンジニアが、耐熱性のセラミックコーティングを施すために、直径1メートルの円形の金属面を持っています。この金属面にセラミックコーティングをするのに必要な時間は、1平方メートルあたり2時間です。この金属面の表面積を求め、コーティングにかかる総時間を計算してください。ただし、コーティングは表面全体に施されるものとします。',\n",
      "               'role': 'user'},\n",
      "              {'content': '直径1メートルの円形の金属面の半径は0.5メートルです。円の表面積は以下の式で求められます。\\n'\n",
      "                          '\\n'\n",
      "                          '\\\\[\\n'\n",
      "                          '\\\\text{表面積} = \\\\pi r^2 = \\\\pi (0.5)^2 = \\\\pi \\\\times 0.25 \\\\approx '\n",
      "                          '0.785 \\\\, \\\\text{平方メートル}\\n'\n",
      "                          '\\\\]\\n'\n",
      "                          '\\n'\n",
      "                          'コーティングにかかる時間は、1平方メートルあたり2時間なので、\\n'\n",
      "                          '\\n'\n",
      "                          '\\\\[\\n'\n",
      "                          '\\\\text{総時間} = 0.785 \\\\, \\\\text{平方メートル} \\\\times 2 \\\\, \\\\text{時間/平方メートル} '\n",
      "                          '\\\\approx 1.57 \\\\, \\\\text{時間}\\n'\n",
      "                          '\\\\]\\n'\n",
      "                          '\\n'\n",
      "                          'したがって、表面積は約0.785平方メートル、コーティングにかかる総時間は約1.57時間です。',\n",
      "               'role': 'assistant'},\n",
      "              {'content': 'もしこの金属面にセラミックコーティングを施す際に、コーティングを2層に重ねる必要がある場合、コーティングにかかる総時間はどのように変わりますか？',\n",
      "               'role': 'user'},\n",
      "              {'content': 'コーティングを2層に重ねる場合、総時間は2層分かかります。\\n'\n",
      "                          '\\n'\n",
      "                          'したがって、\\n'\n",
      "                          '\\n'\n",
      "                          '\\\\[\\n'\n",
      "                          '\\\\text{総時間} = 1.57 \\\\, \\\\text{時間} \\\\times 2 = 3.14 \\\\, \\\\text{時間}\\n'\n",
      "                          '\\\\]\\n'\n",
      "                          '\\n'\n",
      "                          'コーティングにかかる総時間は約3.14時間になります。',\n",
      "               'role': 'assistant'}],\n",
      " 'target': 'grade school student',\n",
      " 'task': 'math',\n",
      " 'topic': 'persona'}\n"
     ]
    }
   ],
   "source": [
    "run_synthesis_multi_turn_qa(\n",
    "    llm,\n",
    "    [\"math\"],\n",
    "    [\"persona\"],\n",
    "    personas,\n",
    "    [\"grade school student\"],\n",
    "    1,\n",
    "    1,\n",
    "    \"output.jsonl\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "難易度を上げて生成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'item': 'An astrophysicist specializing in the study of planetary magnetism and aurora phenomena, '\n",
      "         'likely with a focus on exoplanetary systems and space exploration.',\n",
      " 'messages': [{'content': 'ある外惑星系において、惑星Aの磁場の強さは、地表からの距離rに対して次の式で表されるとする：  \\n'\n",
      "                          '\\\\[ B(r) = B_0 \\\\left( \\\\frac{R}{r} \\\\right)^3 \\\\]  \\n'\n",
      "                          'ここで、\\\\( B_0 \\\\)は惑星の中心における磁場の強さ、Rは惑星の半径、rは地表からの距離です。\\n'\n",
      "                          '\\n'\n",
      "                          '惑星Aの半径は7000 km、中心における磁場の強さは0.5 Tである。  \\n'\n",
      "                          'この惑星の地表から1000 kmの高さにおける磁場の強さB(1000)を求めよ。  \\n'\n",
      "                          'また、地表からどの高さで磁場の強さが0.1 Tになるかを求め、その高さを答えよ。',\n",
      "               'role': 'user'},\n",
      "              {'content': 'まず、与えられた情報を整理します。\\n'\n",
      "                          '\\n'\n",
      "                          '- 惑星の半径 \\\\( R = 7000 \\\\) km\\n'\n",
      "                          '- 中心における磁場の強さ \\\\( B_0 = 0.5 \\\\) T\\n'\n",
      "                          '\\n'\n",
      "                          '地表からの距離 \\\\( r \\\\) は、地表からの高さに惑星の半径を加えたものです。地表から1000 kmの高さでは、  \\n'\n",
      "                          '\\\\[ r = R + 1000 = 7000 \\\\, \\\\text{km} + 1000 \\\\, \\\\text{km} = 8000 \\\\, '\n",
      "                          '\\\\text{km} \\\\]\\n'\n",
      "                          '\\n'\n",
      "                          '次に、地表から1000 kmの高さにおける磁場の強さ \\\\( B(1000) \\\\) を計算します。\\n'\n",
      "                          '\\n'\n",
      "                          '\\\\[\\n'\n",
      "                          'B(1000) = B_0 \\\\left( \\\\frac{R}{r} \\\\right)^3 = 0.5 \\\\left( '\n",
      "                          '\\\\frac{7000}{8000} \\\\right)^3\\n'\n",
      "                          '\\\\]\\n'\n",
      "                          '\\n'\n",
      "                          '\\\\[\\n'\n",
      "                          '= 0.5 \\\\left( \\\\frac{7}{8} \\\\right)^3 = 0.5 \\\\times \\\\frac{343}{512} '\n",
      "                          '\\\\approx 0.5 \\\\times 0.6699 \\\\approx 0.33495 \\\\, \\\\text{T}\\n'\n",
      "                          '\\\\]\\n'\n",
      "                          '\\n'\n",
      "                          '次に、磁場の強さが0.1 Tになる高さを求めます。\\n'\n",
      "                          '\\n'\n",
      "                          '\\\\[\\n'\n",
      "                          '0.1 = 0.5 \\\\left( \\\\frac{7000}{r} \\\\right)^3\\n'\n",
      "                          '\\\\]\\n'\n",
      "                          '\\n'\n",
      "                          '両辺を0.5で割ります：\\n'\n",
      "                          '\\n'\n",
      "                          '\\\\[\\n'\n",
      "                          '0.2 = \\\\left( \\\\frac{7000}{r} \\\\right)^3\\n'\n",
      "                          '\\\\]\\n'\n",
      "                          '\\n'\n",
      "                          '両辺の3乗根を取ります：\\n'\n",
      "                          '\\n'\n",
      "                          '\\\\[\\n'\n",
      "                          '\\\\left( \\\\frac{7000}{r} \\\\right) = (0.2)^{1/3} \\\\approx 0.5848\\n'\n",
      "                          '\\\\]\\n'\n",
      "                          '\\n'\n",
      "                          'これを変形して \\\\( r \\\\) を求めます：\\n'\n",
      "                          '\\n'\n",
      "                          '\\\\[\\n'\n",
      "                          'r = \\\\frac{7000}{0.5848} \\\\approx 11966.2 \\\\, \\\\text{km}\\n'\n",
      "                          '\\\\]\\n'\n",
      "                          '\\n'\n",
      "                          '地表からの高さは、\\\\( r - R \\\\) で求めます：\\n'\n",
      "                          '\\n'\n",
      "                          '\\\\[\\n'\n",
      "                          '\\\\text{高さ} = r - R = 11966.2 \\\\, \\\\text{km} - 7000 \\\\, \\\\text{',\n",
      "               'role': 'assistant'},\n",
      "              {'content': '惑星Aの半径は7000 km、中心における磁場の強さは0.5 Tである。もし、惑星Aの磁場の強さが地表から2000 kmの高さで0.2 '\n",
      "                          'Tになるとしたら、その高さを求めよ。また、その高さにおける磁場の強さB(2000)を計算せよ。',\n",
      "               'role': 'user'},\n",
      "              {'content': 'まず、地表から2000 kmの高さでの磁場の強さが0.2 Tであることから、次の式を使います。\\n'\n",
      "                          '\\n'\n",
      "                          '\\\\[\\n'\n",
      "                          'B(r) = B_0 \\\\left( \\\\frac{R}{r} \\\\right)^3\\n'\n",
      "                          '\\\\]\\n'\n",
      "                          '\\n'\n",
      "                          'ここで、地表からの距離 \\\\( r \\\\) は次のように計算します：\\n'\n",
      "                          '\\n'\n",
      "                          '\\\\[\\n'\n",
      "                          'r = R + 2000 = 7000 \\\\, \\\\text{km} + 2000 \\\\, \\\\text{km} = 9000 \\\\, '\n",
      "                          '\\\\text{km}\\n'\n",
      "                          '\\\\]\\n'\n",
      "                          '\\n'\n",
      "                          '次に、磁場の強さが0.2 Tになる条件を代入します：\\n'\n",
      "                          '\\n'\n",
      "                          '\\\\[\\n'\n",
      "                          '0.2 = 0.5 \\\\left( \\\\frac{7000}{9000} \\\\right)^3\\n'\n",
      "                          '\\\\]\\n'\n",
      "                          '\\n'\n",
      "                          'この式を解くと、次のようになります：\\n'\n",
      "                          '\\n'\n",
      "                          '\\\\[\\n'\n",
      "                          '0.2 = 0.5 \\\\left( \\\\frac{7}{9} \\\\right)^3\\n'\n",
      "                          '\\\\]\\n'\n",
      "                          '\\n'\n",
      "                          '\\\\[\\n'\n",
      "                          '0.2 = 0.5 \\\\times \\\\frac{343}{729}\\n'\n",
      "                          '\\\\]\\n'\n",
      "                          '\\n'\n",
      "                          '\\\\[\\n'\n",
      "                          '0.2 = \\\\frac{171.5}{729}\\n'\n",
      "                          '\\\\]\\n'\n",
      "                          '\\n'\n",
      "                          'この値を計算すると、約0.234となり、条件を満たさないため、2000 kmの高さでの磁場の強さは0.2 Tにはならないことがわかります。\\n'\n",
      "                          '\\n'\n",
      "                          'そのため、地表から磁場の強さが0.2 Tになる高さを求めます：\\n'\n",
      "                          '\\n'\n",
      "                          '\\\\[\\n'\n",
      "                          '0.2 = 0.5 \\\\left( \\\\frac{7000}{r} \\\\right)^3\\n'\n",
      "                          '\\\\]\\n'\n",
      "                          '\\n'\n",
      "                          '両辺を0.5で割ると：\\n'\n",
      "                          '\\n'\n",
      "                          '\\\\[\\n'\n",
      "                          '0.4 = \\\\left( \\\\frac{7000}{r} \\\\right)^3\\n'\n",
      "                          '\\\\]\\n'\n",
      "                          '\\n'\n",
      "                          'ここから、\\n'\n",
      "                          '\\n'\n",
      "                          '\\\\[\\n'\n",
      "                          '\\\\left( \\\\frac{7000}{r} \\\\right) = (0.4)^{1/3}\\n'\n",
      "                          '\\\\]\\n'\n",
      "                          '\\n'\n",
      "                          '計算すると、\\n'\n",
      "                          '\\n'\n",
      "                          '\\\\[\\n'\n",
      "                          'r \\\\approx \\\\frac{7000}{0.7368} \\\\approx 9506.5 \\\\, \\\\text{km}\\n'\n",
      "                          '\\\\]\\n'\n",
      "                          '\\n'\n",
      "                          'この高さから地表までの高さを求めます：\\n'\n",
      "                          '\\n'\n",
      "                          '\\\\[\\n'\n",
      "                          '\\\\text{高さ} = r - R = 9506.5 \\\\, \\\\text{km} - 7000 \\\\, \\\\text{km} '\n",
      "                          '\\\\approx 2506.5 \\\\,',\n",
      "               'role': 'assistant'}],\n",
      " 'target': 'graduate student',\n",
      " 'task': 'advanced math',\n",
      " 'topic': 'persona'}\n"
     ]
    }
   ],
   "source": [
    "run_synthesis_multi_turn_qa(\n",
    "    llm,\n",
    "    [\"advanced math\"],\n",
    "    [\"persona\"],\n",
    "    personas,\n",
    "    [\"graduate student\"],\n",
    "    1,\n",
    "    1,\n",
    "    \"output.jsonl\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同様に、論理推論の問題も生成してみましょう。論理推論の問題生成は難易度が高いため、性能の低い言語モデルではうまくいかないかもしれません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'item': 'A herpetologist specializing in crocodile biology, behavior, and conservation.',\n",
      " 'messages': [{'content': 'ある日、爬虫類学者の田中さんは、3匹のワニを観察しています。彼はそれぞれのワニに名前を付けました。ワニAは水辺でよく見かけられ、ワニBは昼間によく日光浴をし、ワニCは夜に活動的です。田中さんは次のことを知っています：\\n'\n",
      "                          '\\n'\n",
      "                          '1. ワニAは昼間にはあまり見かけない。\\n'\n",
      "                          '2. ワニBは水辺にあまり近づかない。\\n'\n",
      "                          '3. ワニCは日中はほとんど動かない。\\n'\n",
      "                          '\\n'\n",
      "                          'これらの情報から、次の質問に答えてください。ワニAが最も活発に活動する時間帯はいつですか？',\n",
      "               'role': 'user'},\n",
      "              {'content': 'ワニAが最も活発に活動する時間帯は夜です。', 'role': 'assistant'},\n",
      "              {'content': 'ワニDは朝に活動的で、ワニAとワニBは水辺で一緒にいることがある。ワニDの行動はワニAにどのような影響を与えると考えられますか？',\n",
      "               'role': 'user'},\n",
      "              {'content': 'ワニDが朝に活動的であるため、ワニAが朝の時間帯にはあまり見かけないことから、ワニDの存在はワニAの活動を抑制する可能性があります。ワニAは昼間あまり見かけないため、ワニDと一緒にいることがあるのは、主に水辺での活動時間帯が異なるためと考えられます。',\n",
      "               'role': 'assistant'}],\n",
      " 'target': 'grade school student',\n",
      " 'task': 'logical reasoning',\n",
      " 'topic': 'persona'}\n"
     ]
    }
   ],
   "source": [
    "run_synthesis_multi_turn_qa(\n",
    "    llm,\n",
    "    [\"logical reasoning\"],\n",
    "    [\"persona\"],\n",
    "    personas,\n",
    "    [\"grade school student\"],\n",
    "    1,\n",
    "    1,\n",
    "    \"output.jsonl\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "コーディングの問題も生成してみましょう。コーディングに特化した言語モデルを使うとより良い結果が得られるかもしれません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'item': 'A neuroscientist or biologist studying circadian rhythms and their impact on behavioral '\n",
      "         'development.',\n",
      " 'messages': [{'content': 'ある神経科学者が、サンプルデータとして24時間の間に観察された動物の行動パターンを収集しました。データは、時間帯（0から23までの整数）と、その時間帯に観察された行動の数を含むリストの形で与えられます。例えば、`[(0, '\n",
      "                          '5), (1, 10), (2, 15), ..., (23, 2)]`のようになります。\\n'\n",
      "                          '\\n'\n",
      "                          'このデータを使って、次の2つの機能を持つPythonプログラムを作成してください。\\n'\n",
      "                          '\\n'\n",
      "                          '1. '\n",
      "                          '`get_peak_activity(data)`関数を定義し、最も多くの行動が観察された時間帯を返します。返り値は、その時間帯と行動の数のタプル（時間帯, '\n",
      "                          '行動の数）とします。\\n'\n",
      "                          '\\n'\n",
      "                          '2. `average_activity(data)`関数を定義し、全時間帯における平均行動数を計算して返します。\\n'\n",
      "                          '\\n'\n",
      "                          '例:\\n'\n",
      "                          '```python\\n'\n",
      "                          'data = [(0, 5), (1, 10), (2, 15), (3, 8), (4, 12), ..., (23, 2)]\\n'\n",
      "                          'peak_time = get_peak_activity(data)  # 例: (2, 15)\\n'\n",
      "                          'average_time = average_activity(data)  # 例: 9.5\\n'\n",
      "                          '```\\n'\n",
      "                          '\\n'\n",
      "                          'このプログラムを実装してください。',\n",
      "               'role': 'user'},\n",
      "              {'content': '以下は、指定された機能を持つPythonプログラムの実装です。\\n'\n",
      "                          '\\n'\n",
      "                          '```python\\n'\n",
      "                          'def get_peak_activity(data):\\n'\n",
      "                          '    # データから最も多くの行動が観察された時間帯を見つける\\n'\n",
      "                          '    return max(data, key=lambda x: x[1])\\n'\n",
      "                          '\\n'\n",
      "                          'def average_activity(data):\\n'\n",
      "                          '    # 行動数の合計を計算し、時間帯の数で割る\\n'\n",
      "                          '    total_activity = sum(count for hour, count in data)\\n'\n",
      "                          '    return total_activity / len(data)\\n'\n",
      "                          '\\n'\n",
      "                          '# 使用例\\n'\n",
      "                          'data = [(0, 5), (1, 10), (2, 15), (3, 8), (4, 12), (5, 7), (6, 4), \\n'\n",
      "                          '        (7, 6), (8, 11), (9, 9), (10, 5), (11, 7), (12, 8), (13, 10), \\n'\n",
      "                          '        (14, 14), (15, 16), (16, 5), (17, 3), (18, 6), (19, 9), (20, '\n",
      "                          '4), \\n'\n",
      "                          '        (21, 2), (22, 1), (23, 2)]\\n'\n",
      "                          '\\n'\n",
      "                          'peak_time = get_peak_activity(data)  # 例: (15, 16)\\n'\n",
      "                          'average_time = average_activity(data)  # 例: 8.75\\n'\n",
      "                          '\\n'\n",
      "                          'print(\"最も多い行動の時間帯:\", peak_time)\\n'\n",
      "                          'print(\"平均行動数:\", average_time)\\n'\n",
      "                          '```\\n'\n",
      "                          '\\n'\n",
      "                          'このプログラムは、与えられたデータに基づいて最も多くの行動が観察された時間帯と、全時間帯における平均行動数を計算します。',\n",
      "               'role': 'assistant'},\n",
      "              {'content': 'データにおける行動の数が最も多い時間帯が複数ある場合、最初に見つかった時間帯を返すように`get_peak_activity(data)`関数を修正してください。また、`average_activity(data)`関数の結果を小数点以下2桁に丸めて返すように変更してください。',\n",
      "               'role': 'user'},\n",
      "              {'content': '以下のように`get_peak_activity(data)`関数を修正し、`average_activity(data)`関数の結果を小数点以下2桁に丸めるように変更しました。\\n'\n",
      "                          '\\n'\n",
      "                          '```python\\n'\n",
      "                          'def get_peak_activity(data):\\n'\n",
      "                          '    # 最大の行動数を見つけ、その最初の時間帯を返す\\n'\n",
      "                          '    max_activity = max(count for hour, count in data)\\n'\n",
      "                          '    for hour, count in data:\\n'\n",
      "                          '        if count == max_activity:\\n'\n",
      "                          '            return (hour, count)\\n'\n",
      "                          '\\n'\n",
      "                          'def average_activity(data):\\n'\n",
      "                          '    # 行動数の合計を計算し、時間帯の数で割り、小数点以下2桁に丸める\\n'\n",
      "                          '    total_activity = sum(count for hour, count in data)\\n'\n",
      "                          '    return round(total_activity / len(data), 2)\\n'\n",
      "                          '\\n'\n",
      "                          '# 使用例\\n'\n",
      "                          'data = [(0, 5), (1, 10), (2, 15), (3, 8), (4, 12), (5, 7), (6, 4), \\n'\n",
      "                          '        (7, 6), (8, 11), (9, 9), (10, 5), (11, 7), (12, 8), (13, 10), \\n'\n",
      "                          '        (14, 14), (15, 16), (16, 5), (17, 3), (18, 6), (19, 9), (20, '\n",
      "                          '4), \\n'\n",
      "                          '        (21, 2), (22, 1), (23, 2)]\\n'\n",
      "                          '\\n'\n",
      "                          'peak_time = get_peak_activity(data)  # 最初に見つかった最大行動の時間帯\\n'\n",
      "                          'average_time = average_activity(data)  # 小数点以下2桁に丸めた平均行動数\\n'\n",
      "                          '\\n'\n",
      "                          'print(\"最も多い行動の時間帯:\", peak_time)\\n'\n",
      "                          'print(\"平均行動数:\", average_time)\\n'\n",
      "                          '```\\n'\n",
      "                          '\\n'\n",
      "                          'この修正により、複数の最大行動数があった場合には最初の時間帯を返し、平均行動数は小数点以下2桁に丸められます。',\n",
      "               'role': 'assistant'}],\n",
      " 'target': 'high school student',\n",
      " 'task': 'Python coding',\n",
      " 'topic': 'persona'}\n"
     ]
    }
   ],
   "source": [
    "run_synthesis_multi_turn_qa(\n",
    "    llm,\n",
    "    [\"Python coding\"],\n",
    "    [\"persona\"],\n",
    "    personas,\n",
    "    [\"high school student\"],\n",
    "    1,\n",
    "    1,\n",
    "    \"output.jsonl\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上のように、様々な分野の問題と解答のマルチターン対話データを生成することが確認できました。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## まとめ\n",
    "\n",
    "本ハンズオンでは、言語モデルを使って合成データを作成する方法を紹介しました。以下、本ハンズオンで紹介した内容をまとめます。\n",
    "\n",
    "- 合成データ生成の概要\n",
    "- [Persona-Hub](https://arxiv.org/abs/2406.20094) 手法の解説\n",
    "  - Web ページのテキストからペルソナを抽出\n",
    "    - Text-to-Persona\n",
    "    - Persona-to-Persona\n",
    "  - ペルソナを使って合成データを生成\n",
    "    - インストラクション\n",
    "    - 知識豊富なテキスト\n",
    "    - 数学問題\n",
    "- [FinePersonas](https://huggingface.co/datasets/argilla/FinePersonas-v0.1) データセットを使ったマルチターン事後学習データの合成\n",
    "  - Q1: ユーザが質問をする\n",
    "  - A1: アシスタントが解答する\n",
    "  - Q2: ユーザが追加質問をする\n",
    "  - A2: アシスタントが追加質問に解答する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考文献\n",
    "\n",
    "- Xin Chan et al., \"Scaling Synthetic Data Creation with 1,000,000,000 Personas”, arXiv preprint arXiv:2406.20094v1, 2024. https://arxiv.org/abs/2406.20094\n",
    "- Guilherme Penedo et al., \"The FineWeb Datasets: Decanting the Web for the Finest Text Data at Scale\", arXiv preprint arXiv:2406.17557v2, 2024. https://arxiv.org/abs/2406.17557\n",
    "- Hao Chen et al., \"On the Diversity of Synthetic Data and its Impact on Training Large Language Models\", arXiv preprint arXiv:2410.15226v2, 2024. https://arxiv.org/abs/2410.15226\n",
    "- Lozhkov et al., \"FineWeb-Edu: the Finest Collection of Educational Content\", アクセス日: 2025-01-28, https://huggingface.co/datasets/HuggingFaceFW/fineweb-edu\n",
    "- Argilla, “FinePersonas”, アクセス日: 2025-01-28, https://huggingface.co/datasets/argilla/FinePersonas-v0.1\n",
    "- Kan Hatakeyama, “大規模言語モデルTanuki-8x8Bの紹介と開発経緯など”, 9/10 松尾研LLM開発プロジェクト “Tanuki-8x8B” 開発成果報告会 Vol.1, https://www.docswell.com/s/matsuo-lab_llm/51R2L4-2024-9-10-Tanuki%E9%96%8B%E7%99%BA%E5%A0%B1%E5%91%8A%E4%BC%9A-vol1, アクセス日: 2025-01-28\n",
    "- Susumu Ota, \"Persona-Hub による合成データ生成\", 9/24 松尾研LLM開発プロジェクト “Tanuki-8x8B” 開発成果報告会 Vol. 3, https://www.docswell.com/s/matsuo-lab_llm/ZDNGR4-2024-9-24-Tanuki%E9%96%8B%E7%99%BA%E5%A0%B1%E5%91%8A%E4%BC%9A-vol3, アクセス日: 2025-01-28\n",
    "- [NEDO 採択プロジェクト] 多様な日本語能力の向上を目指した公開の基盤モデル開発, コードレポジトリ “synth_topic_multiturn.py”,アクセス日: 2025-01-28, https://github.com/matsuolab/nedo_project_code/blob/team_hatakeyama_phase2/team_hatakeyama_phase2/ota/topic-hub/synth_topic_multiturn.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
